{
 "playlist_1": {
  "docs_data": [
   {
    "section_name": "5 AI Trends You Must Be Prepared for by 2025_j4prKu3MvrQ_Part_1",
    "content": "{ \"section_name\": \"5 AI Trends You Must Be Prepared for by 2025\", \"content\": \"2025 will change our lives as we know it,\\nbut it will be a quiet transformation.\\nWe won't reach the AGI and robots\\nwill not be walking on the streets.\\nWhat will happen, however, is\\nthat every AI technology that has\\nbeen developed so far will slowly\\nmerge into something much greater.\\nIt will bring a ton of opportunities,\\nbut only for those who are well\\npositioned before it begins.\\nSo in this video, I'll dive deep\\ninto the five key AI trends that\\nyou need to prepare for by 2025.\\nI'll explain what those trends are,\\nhow they will impact the industry,\\nand how you can prepare to take full\\nadvantage of the opportunities Okay,\\nbefore we get started, am I the\\nright person to talk about all this?\\nWell, I'm certainly not a\\nresearcher and I don't have a PhD.\\nBut I do have something different.\\nI have four years of practical\\nexperience Implementing AI models in\\nvarious industries I also run an AI\\nagency and my own AI agent framework\\non github with more than 2, 000\\nstars Now, let's get to the trends.\\nTrend number one specialized AI agents\\nAI agents are models that can take\\nactions on our behalf, and there are two\\ntypes of AI agents that you can make.\\nYou can make either custom AI agents\\nor you can make specialized AI agents.\\nCustom AI agents are agents that are\\nfine tuned on a specific business\\nprocess because they know your or your\\nclient's procedures inside and out.\\nThey can automate incredibly complex\\ntasks, tasks where there's some\\ndecision making involved in the\\nprocess or where things can go wrong\\nand where the AI needs to adapt based\\non circumstances rather than just\\nfollow a set of predefined steps.\\nThink about roles like research,\\nmarketing, or management.\\nNone of these functions could\\nbe fully automated before\\nwith simple AI automations.\\nHowever, sometimes what we found in\\nour agency is that some businesses\\nsimply don't have the standard\\noperating procedures to automate.\\nThey just want to automate a very\\ngeneral process for a given role.\\nThat's where our second approach comes in.\\nSpecialized AI agents.\\nThese are pre made agents that\\nhave already been trained on the\\ngeneral process for a specific role.\\nSo although they're called\\nspecialized agents, they're not\\nThey're actually specialized for\\na given role, not for a business.\\nSo in fact, they are more\\ngeneral than custom agents.\\nAnd the primary benefit of having\\nthese pre made AI agents fine\\ntuned on a general process is that\\nyou can deploy them much faster.\\nYou can have them up and\\nrunning in a matter of hours.\\nSo while these agents might not provide\\nas much value as completely custom AI\\nagents, They are incredibly useful for\\nbusinesses that need quick solutions\\nor don't have the necessary resources.\\nHere are some examples.\\nCassine's Genie AI agent is a software\\ndevelopment agent that outperforms\\nthe famous Devon by cognition\\nalmost three times compared to the\\nscore that they initially claimed.\\nAnd 10 times compared to the actual score.\\nWe've designed new techniques to derive\\nhuman reasoning from real examples of\\nsoftware engineers doing their jobs.\\nOur data represents perfect information\\nlineage, incremental knowledge\\ndiscovery, and step by step decision\\nmaking, representing everything\\na human engineer does logically.\\nIt is backed by OpenAI and it\\nis using their fine tuned GPT 4.\\n0 model to That was trained\\non the reasoning steps typical\\nof software developers.\\nBy actually training Genie on this\\nunique data set, rather than simply\\nprompting base models, which is what\\neveryone else is doing, we've seen\\nthat we're no longer simply generating\\nrandom code until some works.\\nIt's tackling problems like a human.\\nIt also has a user interface\\nfor streamlined onboarding.\\nand setup.\\nYou'll notice you can prompt Genie\\nwith a natural language prompt,\\nticket, or in our case, a github issue.\\nSo I'll go ahead and start.\\nThere we go, all the tests have\\nnow passing, Genie has successfully\\nsolved this",
    "file_path": "playlist_1\\5 AI Trends You Must Be Prepared for by 2025_j4prKu3MvrQ.json",
    "file_size": 24531,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "5 ai trends you must be prepared for by 2025_j4prku3mvrq",
     "agents",
     "and",
     "are",
     "can",
     "have",
     "json",
     "lang:pt",
     "model",
     "nand",
     "not",
     "nso",
     "nyou",
     "that",
     "the",
     "they",
     "trends",
     "will",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "df60a5de46a5d5de9198cb8cb9a4df07",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 7,
     "processing_time": 0.01700282096862793
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "5 AI Trends You Must Be Prepared for by 2025_j4prKu3MvrQ_Part_2",
    "content": "problem, and it\\nsolved it in just 84 seconds.\\nNext, we got Harvey AI.\\nThis specialized agent has been trained\\non a vast amount of tax and legal data.\\nIt can perform various legal\\nprocesses like filings, due\\ndiligence, terms of service, and\\nmore fun stuff that we all enjoy.\\nIt's significantly outperforms\\nthe base models on legal data.\\nAnd finally, we have Sakana AI, which\\nis a specialized AI scientist agent.\\nIt was fine tuned on a general research\\nprocess that includes generating ideas,\\nconducting experiments, reviewing\\nscientific papers, and peer reviews.\\nTo support this trend, OpenAI's model\\ncustomization program is even offering\\nyou 1 million training tokens for GPT 4.\\n0 per day.\\nYes, it means that until September\\n23, you can now train GPT 4.\\n0 up to a million tokens\\nper day completely for free.\\nSo how do you prepare for this trend?\\nWell, first, obviously use the free\\ntokens if you can and try to develop\\na specialized AI agent for another\\nrole like marketing or sales yourself.\\nHowever, keep in mind that all of\\nthe companies I mentioned before\\nare funded multi million startups\\nbecause creating an agent that can\\nbe reused across multiple businesses\\ntypically requires more resources.\\nSo feel free to use my framework\\nto get started faster and find\\nadditional help in our discord.\\nBut keep in mind that you might\\nwant to seek funding later.\\nThe second way is to utilize\\nthese systems yourself.\\nIn my opinion, by combining multiple\\nspecialized agents together, you could\\nachieve significantly more leverage\\nthan just by using one of them.\\nYou could potentially even start a\\nbusiness without any employees at all.\\nSo test them frequently as they come out\\nand see how you can use them in your work.\\nIn summary, specialized AI agents\\nwill significantly lower the barriers\\nto entry in the AI agent space.\\nMuch like how Netflix popularized\\nmovie streaming in the 90s.\\nWith its subscription based model,\\nspecialized AI agent platforms will\\nmake AI agents more accessible.\\nWhile they are less customizable,\\nthese agents will serve as an\\nexcellent starting point for most\\nsmall and medium sized businesses.\\nTrend number two, natural language APIs.\\nNatural language APIs are APIs\\nthat are designed specifically\\nfor large language models.\\nIf you think about it, any product\\nthat exists in the cloud, like a\\nSaaS platform, is literally just\\na bunch of API endpoints connected\\ntogether through a user interface.\\nUser interface itself is not the product.\\nThe product is the backend, because\\nthis is where the main functionality is.\\nUser interface just allows\\nus to use that functionality.\\nAnd not that user interfaces aren't\\nimportant, you know, I firmly believe that\\nthe user interface was the reason GPT 3.\\n5 blew up.\\nIt wasn't the RLHF technique, it was\\nthe fact that the RLHF technique allowed\\nfor chat based interactions that were\\na lot more natural for a common user.\\nAnd now that we have something even\\nmore natural, specifically this.\\nHey, I want you to count from\\n1 to 10 really, really fast.\\nAs fast as you can.\\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10.\\nYes, I mean omni models that allow\\nfor literally real time voice\\nand video based interactions.\\nYes.\\nThere is no longer a need for any\\nclicking, scrolling, and typing.\\nThese models can now perform\\nany actions on your behalf.\\nAnd companies like Microsoft with\\ntheir own copilot and Apple with Siri\\nare recognizing the potential here.\\nFirst, Siri can now sound more\\nnatural as it speaks to you.\\nSecond, Siri is now more contextually\\nrelevant and more personal to you.\\nApple intelligence will provide Siri\\nwith on screen awareness, so it'll\\nbe able to understand what you're\\nlooking at and take action on it.\\nAnd third, thanks to richer\\nlanguage understanding, you can\\nnow speak to Siri more naturally.\\nEven if you stumble over",
    "file_path": "playlist_1\\5 AI Trends You Must Be Prepared for by 2025_j4prKu3MvrQ.json",
    "file_size": 24531,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "5 ai trends you must be prepared for by 2025_j4prku3mvrq",
     "agent",
     "and",
     "api",
     "can",
     "json",
     "just",
     "lang:pt",
     "like",
     "more",
     "nand",
     "nit",
     "now",
     "nthe",
     "siri",
     "specialized",
     "test",
     "that",
     "the",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "df60a5de46a5d5de9198cb8cb9a4df07",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 7,
     "processing_time": 0.017996549606323242
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "5 AI Trends You Must Be Prepared for by 2025_j4prKu3MvrQ_Part_3",
    "content": "your words, Siri\\nwill understand what you're getting at.\\nSoon, if you want to order Uber Eats,\\nyou won't even have to open an app.\\nYou will just chat with the model on your\\ndevice about what you want to get, confirm\\nthe payment, and it will order it for you.\\nOr, maybe you won't even have to do\\nanything at all, because it knows\\neverything about your habits, and it\\nmight even order it for you just in time.\\nAnd the way it will all work is\\nthrough natural language APIs.\\nThe name might be different depending\\non the operating system, but yeah,\\nin Apple, you can already do this\\nwith app intent domains or with what\\nthey call it, assistant schemas.\\nApple intelligence is powered\\nby foundation models that give\\nSiri new capabilities in the\\ndomains we just talked about.\\nThese models are trained to expect\\nan intent with a particular shape.\\nThe shape is what we call a schema and\\nassistant schemas is what we call the API.\\nIf you build an app intent\\nwith the right shape.\\nYou'll benefit from our training\\nand don't need to worry about the\\ncomplexities of natural language.\\nAll you need to do is write\\na perform method and let the\\nplatform take care of the rest.\\nIt's funny because in my framework\\nit works the exact same way except\\nthe perform method is called run.\\nThis year we've built schemas for\\nover 100 kinds of intents, like\\ncreating a photo or sending an email.\\nThey each define a set of inputs\\nand outputs that are common for\\nall adopters of that intent.\\nThis is what I mean by shape.\\nIn the middle of all this geometry\\nsits your perform method, with\\nfull creative freedom to define an\\nexperience that is right for your app.\\nNow, let me walk you through the lifecycle\\nof a Siri request with Apple Intelligence.\\nto demonstrate assistant\\nschemas in action.\\nEverything starts with a user request.\\nThis request is routed\\nto Apple intelligence for\\nprocessing through our models.\\nOur models are specifically trained\\nto reason over schemas, allowing\\nApple intelligence, the ability to\\npredict one based on user request.\\nOnce an appropriate schema is selected,\\nthe request is routed to a toolbox.\\nThis toolbox contains a collection\\nof app intents from all the apps on\\nyour device, grouped by their schema.\\nBy conforming your intent to\\na schema, you give the model\\nthe ability to reason over it.\\nFinally, the action is performed\\nby invoking your app intent.\\nThe result is presented\\nand the output is returned.\\nBut it's not just Apple.\\nAI providers also want you to\\nconnect your apps to their LLMs.\\nwhich is evident by new features\\nlike structured outputs by OpenAI.\\nSo if you want to learn more about\\nhow these models can now reason\\nreliably over those schemas, make\\nsure to check out my previous\\nvideo on structured outputs later.\\nHowever, with this new trend, there are\\neven more opportunities on the horizon.\\nSome of you might be familiar\\nwith API as a service products.\\nThese products provide API endpoints\\nwithout a user interface at all.\\nFor example, there are URL Shortener\\nAPIs, Weather Information APIs,\\nText to Speech APIs, Currency\\nConversion APIs, and others.\\nSome people are secretly\\nmaking big money on this.\\nNow, with the release of Omni\\nModels, imagine a product that users\\ninteract with solely through an LLM.\\nYou can create an API based service that\\nusers subscribe to and then simply plug\\ninto their LLMs on their own devices.\\nZapier was one of the first movers\\nin this space with AI Actions API.\\nThis is exactly what I'm talking about\\nhere, a natural language API designed\\nspecifically for large language models.\\nAnd although it's not quite there\\nyet, I'm confident that in 2025, we'll\\nsee even more products like this.\\nSo if you're a developer, start\\nlearning about App Intents\\nand how to integrate apps.\\nWith large language models,\\ndepending on your operating",
    "file_path": "playlist_1\\5 AI Trends You Must Be Prepared for by 2025_j4prKu3MvrQ.json",
    "file_size": 24531,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "5 ai trends you must be prepared for by 2025_j4prku3mvrq",
     "about",
     "all",
     "and",
     "api",
     "app",
     "are",
     "intent",
     "json",
     "lang:pt",
     "model",
     "models",
     "nand",
     "nthe",
     "that",
     "the",
     "this",
     "what",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "df60a5de46a5d5de9198cb8cb9a4df07",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 7,
     "processing_time": 0.017996549606323242
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "5 AI Trends You Must Be Prepared for by 2025_j4prKu3MvrQ_Part_4",
    "content": "systems.\\nIf you want to build a SAS, think\\nabout developing a natural language\\nAPI, whether it's a new product or an\\nexisting one, this trend will be huge\\nfor all developers because it will\\ncompletely transform how we create apps\\nand how we use them on our devices.\\nTrend number three,\\nemerging architectures.\\nAnd I am not talking about\\nnew model architectures.\\nThis is probably also coming soon, but\\nhere I am talking about something much\\nbigger so far, the research suggests\\nthat intelligence scales proportionally\\nwith the number of parameters.\\nHowever, while we can likely accommodate\\nfor the rising demand and compute with\\n100 billion data centers like this.\\nby OpenAI and Microsoft, there's another\\nproblem that money alone can't solve.\\nOne chat GPT query takes nearly 10\\ntimes as much energy as a typical Google\\nsearch, and as much energy as keeping\\na 5 watt LED bulb on for an hour.\\nGenerating an AI image can use as much\\npower as charging your smartphone.\\nGenerating an AI image can consume as\\nmuch energy as charging your smartphone.\\nSo, as you might guess, the\\nglobal electricity demand\\nalso skyrocketed in 2022.\\nAnd unless there is a breakthrough\\nin AI architectures, we might hit a\\nplateau, not because of the technological\\nlimitations, but simply because\\nwe don't have enough electricity.\\nYou see, the fact that we're running our\\ncurrent AI models on existing hardware\\nis essentially just a coincidence.\\nCPUs and GPUs are designed for a different\\ntype of computing, where the outcome of\\nan operation is always either 0 or 1.\\nAI models, on the other hand,\\nwork in a probabilistic fashion,\\nmeaning that AI models assign\\nprobabilities for certain outputs\\nand then select the most likely one.\\nThis is why companies like IBM and Google\\nhave their own quantum AI divisions.\\nHowever, it's now evident that quantum\\ncomputing is still not ideal for AI,\\nwhich is why we're starting to see\\nthe rise of new computing paradigms\\nlike thermodynamic computing.\\nAnd the company leading this\\ninnovation is called Xtropic,\\nfunded by Guillaume Verdon.\\nWhat we're building at Xtropic, our\\nmission essentially is to build the\\nultimate substrate for AI compute, right?\\nHit the ultimate limits of physics in\\nterms of density, especially In terms\\nof energy efficiency and speed for AI.\\nSo how do we do that?\\nWe embed AI algorithms into the physics\\nof the world as tightly as possible.\\nExtropic takes a completely\\ndifferent approach by embedding\\nAI algorithms directly into the\\nphysics of thermal processes.\\nThey use natural noise to perform\\ncomputations, which is perfect\\nfor generative AI tasks because\\nit aligns with the probabilistic\\nnature of how AI models work.\\nTake a look at this video, right?\\nSo tokens per second divided by\\nWatts is a hundred million times\\nmore energy efficient, which\\nagain, ballpark of the brain.\\nAgain, this is not a machine we've built.\\nIt's in simulations.\\nSo it's a projection.\\nI'll show you in a second, the machine\\nwe've actually built, but this is\\nextrapolated from the data we got and\\nare as accurate as we could simulations.\\nIn terms of speed, it's about\\na thousand to 10, 000 times\\nfaster in GPU for inference of\\ndeterministic neural networks.\\nSo for sampling of Monte Carlo, it's about\\na million to 10 million times faster.\\nOf course, right now, this is just\\na simulation, but I mean, 1000 to\\n10, 000 times faster inference.\\nCompare this to grok, which is only 12 to\\n18 times faster than GPU, and it's also\\n100 million times more energy efficient.\\nSo, how do you prepare for this trend?\\nWell, definitely keep an eye on\\ncompanies like Extropic, their testing\\nbegins in early 2025, and they should\\nhave a white paper coming out soon.\\nIf their vision becomes a\\nreality, you might want to\\nscale up your dreams as well.\\nFor example, if right now running a\\n400B",
    "file_path": "playlist_1\\5 AI Trends You Must Be Prepared for by 2025_j4prKu3MvrQ.json",
    "file_size": 24531,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "5 ai trends you must be prepared for by 2025_j4prku3mvrq",
     "about",
     "and",
     "because",
     "but",
     "energy",
     "how",
     "json",
     "lang:pt",
     "model",
     "nand",
     "nfor",
     "not",
     "nso",
     "that",
     "the",
     "this",
     "times",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "df60a5de46a5d5de9198cb8cb9a4df07",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 3,
     "total_chunks": 7,
     "processing_time": 0.01900768280029297
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 3,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "5 AI Trends You Must Be Prepared for by 2025_j4prKu3MvrQ_Part_5",
    "content": "model is too expensive for your\\nuse case, imagine what it would be\\nlike if you could run a thousand times\\nbigger model a hundred times cheaper.\\nIn summary, emerging architectures\\nmight just be the key to unlocking AGI.\\nIf companies like Extropic succeed,\\nthis will ultimately bring the cost\\nof intelligence to zero, leading\\nus to abundance and prosperity.\\nTrend number four, humanoid robots.\\nTranscribed Remember that movie with\\nWill Smith where by 2035 there was\\none robot for every three humans?\\nWell, what if I told you that it could\\nbe more like one robot for every human?\\nYes, we're talking billions by 2040.\\nAnd this is already here.\\nFigure the leading robotics\\ncompany in this field valued at 2.\\n6 billion with investors like\\nOpenAI, Microsoft, NVIDIA, and\\nJeff Bezos recently released figure\\ntwo with a ton of new features.\\nAnd they are starting their\\nproduction line next year.\\nDo you already have first customer signed?\\nLike BMW manufacturing.\\nAnd by the way, these robots will also\\nbe quite affordable somewhere only around\\n20, 000, which is equivalent to a low\\nlevel car, except it will be able to\\nwork for you 24 hours a day for years.\\nAt the moment, it seems like Figure\\nis the most advanced company, however,\\nthey are far from being the only one.\\nIn total, there are around 20 other\\ncompanies that are trying to accomplish\\nthe exact same thing around the world.\\nFor example, there is Tesla, of course,\\nin United States and Boston Dynamics, and\\nthere are AGIBOT and Unitree in China.\\nNow, the difference that makes\\nFigure unique is how they are\\nutilizing large language models.\\nAt the top, they've partnered with OpenAI\\nto integrate their reasoning model.\\nThis is ideal for humanoid\\nrobots because of the real\\ntime voice and audio processing\\ncapabilities we discussed before.\\nThis model then integrates\\nwith neural network policies.\\nI assume this is similar to how agents\\nuse tools through natural language APIs.\\nThese policies process requests\\nfrom the main agent, translating\\nthem into specific behaviors.\\nThe system then repeats this\\nprocess in a feedback loop\\nuntil the task is accomplished.\\nWhile this is just my interpretation,\\nit's clear that Figures partnership\\nwith OpenAI will be instrumental\\nto their success in this market.\\nSo, how do you prepare for this?\\nWell, although these robots will\\nbe general, I assume they'll\\nstill need some specific training,\\nmuch like digital AI agents.\\nFor instance, if you want to employ one\\nin your cafe or at a manufacturing plant,\\nyou'll most likely at least have to tell\\nthis agent about your business procedures,\\nyour company policies, and specific tasks.\\nSo, knowing how to train digital\\nagents could evolve into one of the\\nmost unique job opportunities yet.\\nTraining humanoid robots\\nto operate effectively in\\ndifferent physical environments.\\nIn summary, humanoid robots are no\\nlonger a distant future concept.\\nThey are here and they will\\nstart transforming the way\\nwe work as soon as next year.\\nAlthough they will of course eliminate\\na ton of jobs, I'm sure about that, they\\nwill also create a whole new job market.\\nFor those who are prepared.\\nTrend number five, government regulation.\\nSo, so far all the trends I mentioned are\\npositive, and I truly believe that they\\nwill bring immense benefits to humanity.\\nHowever, there is one trend that\\ncould significantly delay everything\\nwe've discussed far beyond 2025.\\nSo, recently there have been new\\ndevelopments both in In the United\\nStates and in Europe, California\\nrecently issued a new controversial\\nAI safety bill and both OpenAI and\\nAnthropic executives responded with\\nformal letters expressing their opinions.\\nWe are going to go over that bill\\nof course, in a bit, but first let's\\ntake a look at broader AI acts.\\nSpecifically the EU AI act and the\\nresponsible advanced AI",
    "file_path": "playlist_1\\5 AI Trends You Must Be Prepared for by 2025_j4prKu3MvrQ.json",
    "file_size": 24531,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "5 ai trends you must be prepared for by 2025_j4prku3mvrq",
     "and",
     "are",
     "humanoid",
     "json",
     "lang:pt",
     "like",
     "model",
     "nin",
     "nthis",
     "one",
     "robots",
     "that",
     "the",
     "there",
     "they",
     "this",
     "will",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "df60a5de46a5d5de9198cb8cb9a4df07",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 4,
     "total_chunks": 7,
     "processing_time": 0.02100849151611328
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 4,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "5 AI Trends You Must Be Prepared for by 2025_j4prKu3MvrQ_Part_6",
    "content": "act in United\\nStates, the general consensus is\\nthat both the EU and us are going to\\nregulate models above a certain number\\nof flops, which is the computing power\\nthat goes into training such a model.\\nThis is exactly what Sam Altman\\nproposed a few months ago in May\\nand the responsible EIA act even\\nquotes him directly in a summary.\\nIn the United States this\\nnumber equates to 10 to 26 flops\\nwhile in Europe it's 10 to 25.\\nIf more than this amount of compute\\ngoes into training your model, You\\nwill have to go through extensive\\nrisk assessment, model valuation,\\ntransparency requirements, and reporting.\\nFor reference to train 405B model, you\\nneed around three times more compute\\nthan the requirement in Europe and\\nthree times less compute than the\\ntop requirement in the United States.\\nThis is the only objective metric\\nthat I found in both of these acts.\\nOther criteria include, like if you\\ncan use this AI in the development of\\nchemical or Nuclear weapons, or if you\\ncan use it in high impact areas like law\\nenforcement, education, and employment.\\nBut, here is the thing.\\nIt has already been proven many times\\nthat CHAT GPT can greatly assist college\\nstudents in developing bioweapons.\\nAdditionally, scientists use CHAT\\nGPT all the time to assist them with\\nresearch, which is evident by an\\nincreasing frequency of LLM related\\nkeywords in scientific publications.\\nSo, no one still really knows under\\nwhich category CHAT GPT falls.\\nAnd the legislators probably don't\\neven know themselves because both\\nacts also include clauses like\\nAdministrator has the freedom to make\\nrules stricter without any evidence.\\nThis last clause is specifically\\nproblematic because I want to emphasize\\nthat there is absolutely no real evidence\\nright now that there is something\\nnefarious living inside ChatsGPT.\\nI also want to be clear that in\\nthe United States this act has not\\nbeen passed yet, unlike in Europe,\\nbut it has already been used.\\nAs a guide for other legislation.\\nSo for example, in the new SB 1 0\\n4 7 bill in California, which is on\\ntrack to start taking effect by the\\nnext month, instead of using flops,\\nit simply uses costs as the metric.\\nSo now all models that cost\\nover 100 million train in\\nCalifornia must be regulated.\\nThey must provide extensive proof of\\nsafety, implement mandatory safeguards,\\nlike a kill switch, undergo annual\\naudits by third parties, maintain safety\\nprotocols, and submit regular reports.\\nHowever, the most concerning aspect of\\nthis bill is that it holds developers\\nresponsible for any misuse of their\\nmodels, even if the model was later fine\\ntuned or modified after its creation.\\nThis is completely absurd, and I have no\\nidea how could this even be discussed,\\nbut OpenAI's chief strategy officer\\nalready expressed concerns and stated\\nthat this bill could halt all model\\nreleases and AI development in California.\\nAnthropic, on the other hand, surprisingly\\nsaid that this bill provides more\\nbenefits and likely outweighs the costs.\\nSo how will this affect the AI industry?\\nObviously, it benefits major players\\nlike Anthropic and OpenAI the most.\\nBecause very few companies will have the\\nresources to meet those safety checks.\\nThe open source community in California\\nwill most likely be completely\\ndestroyed because it's much easier\\nto create a derivative of the model\\nand misuse it from an open source\\nproject rather than a closed one.\\nSecondly, it will slow the AI\\ndevelopment in the United States\\nand in Europe, potentially allowing\\ncountries like China to catch up.\\nWhich could be a lot more dangerous\\nthan someone misusing chat GPT.\\nAnd third, this might actually\\ndecrease the amount of money that\\ngoes into the safety research.\\nBecause as you might guess, all\\nof those model evaluations, kill\\nswitches, and audits will not be\\nfinanced from the company's",
    "file_path": "playlist_1\\5 AI Trends You Must Be Prepared for by 2025_j4prKu3MvrQ.json",
    "file_size": 24531,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "5 ai trends you must be prepared for by 2025_j4prku3mvrq",
     "and",
     "chat",
     "europe",
     "guide",
     "has",
     "json",
     "lang:pt",
     "like",
     "model",
     "more",
     "nand",
     "nthat",
     "nthis",
     "states",
     "that",
     "the",
     "this",
     "united",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "df60a5de46a5d5de9198cb8cb9a4df07",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 5,
     "total_chunks": 7,
     "processing_time": 0.02100849151611328
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 5,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "5 AI Trends You Must Be Prepared for by 2025_j4prKu3MvrQ_Part_7",
    "content": "profits.\\nThey will be financed from the same safety\\nbudget that OpenAI and other companies\\ndevoted to super alignment and research.\\nSo to prepare for this, we have to\\nmonitor how this whole story unfolds.\\nThe bill should start taking\\nforce gradually over the\\nnext year in California.\\nHowever, keep in mind that even if\\nwe completely stopped AI development\\ntoday, it will still take us years to\\nfully realize the full potential of\\neverything that has been created so far.\\nSo the best thing that you can do\\nright now is learn how to develop\\nuseful AI applications for good.\\nTo get started, I recommend\\nwatching this video next.\\nThank you and don't forget to subscribe.\", \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\5 AI Trends You Must Be Prepared for by 2025_j4prKu3MvrQ.json\", \"tags\": [ \"5 AI Trends You Must Be Prepared for by 2025\" ], \"source\": \"https://www.youtube.com/watch?v=j4prKu3MvrQ\" }",
    "file_path": "playlist_1\\5 AI Trends You Must Be Prepared for by 2025_j4prKu3MvrQ.json",
    "file_size": 24531,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "5 ai trends you must be prepared for by 2025_j4prku3mvrq",
     "and",
     "how",
     "json",
     "lang:pt",
     "must",
     "nso",
     "prepared",
     "that",
     "the",
     "this",
     "trends",
     "will",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "df60a5de46a5d5de9198cb8cb9a4df07",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 6,
     "total_chunks": 7,
     "processing_time": 0.02200770378112793
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 6,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Agency Swarm Can Now Create Your Agent Swarms for You_qXxO7SvbGs8_Part_1",
    "content": "{\n    \"section_name\": \"Agency Swarm Can Now Create Your Agent Swarms for You\",\n    \"content\": \"Today I'm introducing the new Genesys Swarm that \\ntakes us a step closer towards self-expanding  \\nartificial intelligence. With my framework Agency \\nSwarm, you can now create your own agents without  \\nwriting a single line of code. But here's \\nthe best part. The more agents we create,  \\nthe more powerful our library becomes. Every \\nagent that you contribute on GitHub can now  \\nbe instantly imported by the Genesys Swarm, \\nallowing others to benefit from it too. Towards  \\nthe end of this video, I'll show you exactly \\nhow to contribute, but for now, let's just  \\nsee this incredible demo where I create a Bitcoin \\ninvesting agency with just a couple of prompts.\\n \\nLet's dive in. If you're new here, welcome to \\nthis channel. My name is Arsen, and my goal is  \\nto automate my entire AI agency with AI. To \\nachieve this, I've developed an open-source  \\nframework called Agency Swarm, which allows you to \\neasily orchestrate AI agents built on top of the  \\nlatest OpenAI Assistance API. So let's dive in and \\nsee how this Genesis agency works. Okay, I'm going  \\nto request a Bitcoin investing agency and just \\nsee what happens. First, the CEO wants to know  \\nabout my mission, goals, and which APIs I want to \\nuse. All right, my goal is to provide up-to-date  \\nanalysis and focus on achieving high returns.\\nI also want to utilize the Binance API and browse  \\nthe web for the latest news. Now, the CEO agent \\nimmediately proposes the initial structure  \\nfor my agency, which actually looks pretty \\ngood. Sometimes you might want to adjust it,  \\nbut I'm pretty content with this, so I'm just \\ngoing to tell it to proceed. After the Genesys CEO creates\\nour agency folder, it tells the \\nAgent Creator agent to create the first agent,  \\nwhich is the Market Analyzer.\\nThe Agent Creator first checks if there  \\nare any available agents in our framework using \\nthe Get Available Agents tool. As I said before,  \\nall agents that you contribute on GitHub will \\nautomatically be available via this tool. However,  \\nsince there are no agents available for \\ninteracting with the Binance API just yet,  \\nit proceeds with creating it manually using \\nthe Create Agent Template tool. Then it tells  \\nthe browsing agent to find the most relevant \\nAPIs for this agent to use. The browsing agent  \\nfrom my previous video immediately pulls up \\nthe browsing window and starts searching for  \\nthe Binance API in Google. It navigates to the \\ncorrect documentation page, exports it using  \\nthe new export file tool, and then communicates \\nthis file ID to the agent creator agent.\\n \\nWith this new groundbreaking tool, the \\nbrowsing agent can now export whole web  \\npages as PDFs and then instantly upload them to \\nOpenAI for further analysis with the retrieval  \\ntool. This means that you no longer have to \\nworry about missing out on any information or  \\nhitting the context window. Additionally, your \\nagents can now communicate these files to one  \\nanother via the send message tool. But more \\non this later. Okay, next the agent creator  \\nagent sends this file via the message files \\nparameter to the open API creator agent.\\n \\nAfter that, the OpenAPI creator extracts all \\nthe necessary information from this web page  \\nand creates an OpenAPI schema using the Create \\nTools from Schema tool. You can see this new  \\nOpenAPI schema in a Schemas folder of the Market \\nAnalyzer agent. This folder is also a new addition  \\nto my framework. Essentially, all schemas that you \\nput in this folder will automatically be processed  \\nand then converted into tools for your agents to \\nuse. Next, the Genesys CEO sends the next agent,  \\nwhich is the News Harvester agent. The browsing \\nagent again initiates a search using Google and  \\nlocates a link to the CryptoNews API. \\nHowever, this time, the page does not  \\ncontain the actual API documentation.\\nNevertheless, seems like it hallucinated a  \\nbit and still exported the file.",
    "file_path": "playlist_1\\Agency Swarm Can Now Create Your Agent Swarms for You_qXxO7SvbGs8.json",
    "file_size": 13100,
    "last_modified": "2025-04-18 15:34:02",
    "tags": [
     "agency",
     "agency swarm can now create your agent swarms for you_qxxo7svbgs8",
     "agent",
     "agents",
     "and",
     "api",
     "can",
     "create",
     "creator",
     "documentation",
     "json",
     "lang:pt",
     "new",
     "now",
     "nthe",
     "that",
     "the",
     "this",
     "tool",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "d393dc18aebb7f999579c6697fabdf37",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 4,
     "processing_time": 0.02298903465270996
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Agency Swarm Can Now Create Your Agent Swarms for You_qXxO7SvbGs8_Part_2",
    "content": "So let's see \\nwhat happens next. Upon receiving this file,  \\nthe OpenAPI creator notifies the agent creator \\nthat this file in fact does not contain the actual  \\nAPI documentation. Then the agent creator tells \\nthis to the browsing agent so it can continue  \\nsearching. This is another cool advantage of using \\nagent swarms because a single agent would never be  \\nable to recover from a hallucination like this. \\nThe browsing agent then browses through a few  \\nmore windows and finally navigates to the correct \\nlink. Then it exports the file and sends it back  \\nto the agent creator who then sends it to the \\nOpenAPI creator. Now the OpenAPI creator agent  \\nOpenAPI Creator. Now the OpenAPI Creator agent \\nsuccessfully analyzes this page with the retrieval  \\ntool and then creates a valid OpenAPI schema.\\nTo finalize the agency, a special tool is executed  \\nby the Genesys CEO, which essentially adds \\nall the imports for all new agents and then  \\nformats the agency file. After this step, \\nthe Genesys CEO informs me that the agency  \\ncreation process is complete and I can run it \\nwith the python-agency.py command. Awesome! So,  \\nlet's check this out. You can check out the \\ncomplete agency folder with all the agents and  \\ntheir respective OpenAPI schemas locally. However, \\nbefore we can use this agency, there is one more  \\nstep involved. We need to obtain the actual API \\nkeys because our agents will be interacting with  \\nreal APIs. For Binance, I simply navigate to \\nthe API management page and then create a system  \\ngenerated key. To add your API keys, you can now \\nspecify them in the new API headers or API params  \\nproperties of your agent, depending on where your \\nkeys are required. Keep in mind that you have to  \\nspecify the file name from your schemas folder \\nas well. So the structure of these properties  \\nis a dictionary where keys are file names and \\nvalues are other dictionaries containing API  \\nparameters or API headers for your API.\\nNow, let's repeat the same process for the  \\nCryptoNews API. The API key for CryptoNews \\nis located under the Accounts tab,  \\nand I use API params property this time, \\nbecause according to their documentation,  \\nit needs to be in the query parameters rather than \\nin headers. To test our new BitInvest agent swarm,  \\nI navigate into the agency folder and run the \\nPython agency.py command. Then, I simply copy and  \\npaste the link into the browser. Now let's find \\nout if it's a good time to buy Bitcoin. After I  \\nsend the question, the CEO instructs the market \\nanalyzer to assess the latest market data.\\n \\nThe market analyzer then utilizes the Get Average \\nPrices API endpoint and sends back today's live  \\nBitcoin prices. After that, the CEO requests \\nthe News Harvester agent to gather the most  \\nrecent news. The News Harvester employs the Get \\nTrending News API endpoint and then sends back a  \\ncomplete report. With all this information, our \\nCEO finally compiles a thorough analysis of the  \\ncurrent Bitcoin market. This analysis includes the \\nlatest prices and trending articles categorized by  \\nsentiments. The market is liquid with normal \\ntrading volume and it seems like Elon Musk is  \\nback in the crypto game, so an NCO concludes \\nthat if I'm willing to take risks, investing  \\nin Bitcoin might be worth considering.\\nSo yeah, not an investing advice. It's kind  \\nof incredible, honestly, the first time I ran \\nthis, I couldn't believe that it actually worked  \\nand I still have plenty of ideas for improvement \\nlike automating testing APIs as well. However,  \\nfor complete transparency, the API schema for \\nthe crypto news API wasn't exactly correct. The  \\nOpenAPI creator used the incorrect server URL, \\nmost likely because the actual API endpoints were  \\nhidden on an exported page.",
    "file_path": "playlist_1\\Agency Swarm Can Now Create Your Agent Swarms for You_qXxO7SvbGs8.json",
    "file_size": 13100,
    "last_modified": "2025-04-18 15:34:02",
    "tags": [
     "agency",
     "agency swarm can now create your agent swarms for you_qxxo7svbgs8",
     "agent",
     "and",
     "api",
     "can",
     "creator",
     "file",
     "json",
     "lang:pt",
     "market",
     "news",
     "nthe",
     "openapi",
     "sends",
     "server",
     "test",
     "the",
     "then",
     "this",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "d393dc18aebb7f999579c6697fabdf37",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 4,
     "processing_time": 0.023988962173461914
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Agency Swarm Can Now Create Your Agent Swarms for You_qXxO7SvbGs8_Part_3",
    "content": "If this happens, \\nyou can simply adjust your schemas manually  \\nor communicate this information to the CEO. \\nNow, before I show you how to test and run  \\nthis yourself, let me walk you through \\nall of these groundbreaking updates.\\n \\nFirst first and foremost, we finally have proper tests\\nwe now have a working \\nci pipeline on GitHub, so you can  \\nexpect a more stable experience.\\nSecond, here's the exciting news:  \\nagents can now communicate files between each \\nother using the message files parameter. \\n \\nThis opens up a world of new use cases. \\nFor example, you can create a report agent  \\nthat compiles a complete report based on your sources, and \\nthen connect it with a report analyzer agent that  \\nextracts meaningful insights from this file.\\nThird, ToolFactory has leveled up as well.\\n \\nCreating tools from OpenAPI schemas can \\nnow be done in just one line of code. \\n \\nOr you can simply drop your schemas as i say'd before\\nin a schemas folder and specify this  \\nfolder path when initializing your agent.\\nAnd last but not least, introducing the Genesis  \\nAgency, a collection of four agents: the Genesis \\nCEO, the Agent Creator, the OpenAPI Creator,  \\nand a Browsing Agent from my previous video.\\nThe real game-changer is how these agents are  \\ncombined together, each one supporting \\nthe function of another, like for example\\nThe  browsing  agent searching for docs, the OpenAPICreator agent \\ncreating schemas from from docs, while the agent  \\ncreator providing instructions and \\nthe CEO sets the whole agency manifesto.\\nNow, let's dive in and see how you \\ncan test it all out yourself.\\nTo get started, follow these steps:\\n1. Clone the repo from GitHub or ensure  \\nyou have the latest changes by using \\nthe command [git pull origin main].\\n \\n2. Create and activate a virtual \\nenvironment using conda or venv. \\n3. Install Jupyter with the \\ncommand [pip install jupyter]\\n4. Run the Jupyter Notebook command \\ninside the [notebooks] folder and open  \\njupyter in your browser.\\n5. Then run all the cells, from the Genesis Agency Notebook\\nmaking sure to add your OpenAI key.\\n6. Open the URL under the demo Gradio  \\ncommand and you should now be good to go.\\nAs you chat with Genesis CEO, you will see  \\nall the agent fields being created \\nin the same [notebooks] folder.\\n \\nIf you create something cool, dont \\nforget to contribute it on GitHub. \\n \\nTo do so, please refer to the new \\n[contributing.md] file, which contains all  \\nthe necessary steps and folder structures. \\nOur goal is to organize these agents and  \\ntools by specific categories such as \\ncoding, browsing, and investing. \\n \\nEach agent folder and tool should \\nfollow a predefined structure  \\noutlined in the contributing.md file. \\nOnce you have made the necessary changes,  \\ncreate a pull request with a description, and \\nif possible, include tests for your tools. \\n \\nOnce your tools are reviewed and merged, \\nthey will be instantly accessible by the  \\nGenesis Swarm, so other users wont \\nhave to create them from scratch.\\n \\nAlso, don't forget to add agent \\ndescriptions, because this is  \\nhow the Agent Creator Agent will determine if \\nyour agent is suitable for the task.\\n \\nIn conclusion, just a few months ago, I would have \\nnever imagined that AGI would be open-sourced. \\n \\nHowever, after collaborating with all of you on this framework \\nwith all of you, my perspective has shifted.\\n \\nWhile I still believe that the most advanced \\nAI models will forever be close-sourse'd,  \\nI now have faith that the Open Source \\ncommunity will still be the one to  \\ncreate AGI using these models.",
    "file_path": "playlist_1\\Agency Swarm Can Now Create Your Agent Swarms for You_qXxO7SvbGs8.json",
    "file_size": 13100,
    "last_modified": "2025-04-18 15:34:02",
    "tags": [
     "agency swarm can now create your agent swarms for you_qxxo7svbgs8",
     "agent",
     "all",
     "and",
     "can",
     "folder",
     "have",
     "json",
     "lang:pt",
     "now",
     "nthe",
     "schemas",
     "test",
     "the",
     "these",
     "this",
     "will",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "d393dc18aebb7f999579c6697fabdf37",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 4,
     "processing_time": 0.023988962173461914
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Agency Swarm Can Now Create Your Agent Swarms for You_qXxO7SvbGs8_Part_4",
    "content": "\\nI believe that OpenAI itself has yet  \\nto fully grasp the full potential of \\nthe models that they had just released.\\n \\nAnd with the agency swarm being built\\non top of their latest assistants api,  \\nwe might as well be the ones to build it.\\nSeriously, just take a look at this tweet  \\nwhere Greg Brockman recently confirmed that \\nmemory is indeed coming to ChatGPT. Which API  \\ndo you think will be used for this feature?\\nSo imagine if every one of us contributes their  \\nagents to this project, and we keep improving on them \\nuntil each agent is an expert in its own role. \\n \\nSoon enough, we could potentially cover \\nnearly every single job on earth.\\nAnd if you still  don't think it's possible, \\nplease take a look at my previous video, \\nwhere the browsing agent literally \\ncracks captchas better than myself.\\n \\nThank you for watching and \\ndon t forget to subscribe.\",\n    \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\Agency Swarm Can Now Create Your Agent Swarms for You_qXxO7SvbGs8.json\",\n    \"tags\": [\n        \"Agency Swarm Can Now Create Your Agent Swarms for You\"\n    ],\n    \"source\": \"https://www.youtube.com/watch?v=qXxO7SvbGs8\"\n}",
    "file_path": "playlist_1\\Agency Swarm Can Now Create Your Agent Swarms for You_qXxO7SvbGs8.json",
    "file_size": 13100,
    "last_modified": "2025-04-18 15:34:02",
    "tags": [
     "agency",
     "agency swarm can now create your agent swarms for you_qxxo7svbgs8",
     "agent",
     "api",
     "json",
     "just",
     "lang:pt",
     "look",
     "nand",
     "nwhere",
     "swarm",
     "take",
     "that",
     "the",
     "their",
     "think",
     "this",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "d393dc18aebb7f999579c6697fabdf37",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 3,
     "total_chunks": 4,
     "processing_time": 0.02486896514892578
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 3,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "5 Craziest AI Agents We've Ever Built_hb0j9Qn-KjM_Part_1",
    "content": "{ \"section_name\": \"5 Craziest AI Agents We've Ever Built\", \"content\": \"Let's dive in.\\nOkay,\\nso the first demo\\nis a state of the art\\nfigma to HTML generation agent.\\nIt was created for a company\\nthat creates newsletters\\nfor some of the biggest brands\\nin the world.\\nSo basically what this agent does\\nis it creates\\nHTML files\\ndirectly from figma design mockups.\\nAll you have to do\\nis provide it with the necessary assets,\\nthe figma mockup,\\nand then it proceeds to work.\\nSo as you can see here,\\nit uses one special function\\nthat is extremely complex\\nand uses a lot of other,\\nAPI calls to OpenAI under the hood\\nand then it generates\\nthis newsletter\\nthat looks almost exactly\\nas the target design mockup.\\nThis process is obviously extremely time\\nconsuming\\nand it used to take a lot longer,\\nbut you might be wondering,\\nyou know,\\nwhat's the reason for using\\nan the agent here\\nsince the agent just uses one function\\nand then provides us with the HTML file\\nSo the answer is that because often times\\nafter generating an initial HTML\\nyou have to iterate with the developer\\nand adjust it based either on your or\\nyour client's feedback.\\nAnd the same can be done here\\ninstead of you just\\ngetting that\\nfinal HTML file,\\nwhich would happen with the AI automation\\nAnd then\\nyou would have to adjust it manually.\\nHere you can say to the agent\\nthe specific adjustments\\nthat need to be done.\\nAs you can see here, Nick enters\\nsome specific instructions\\nfor which sections to adjust and how.\\nAnd then the agent proceeds with aligning\\nthese sections better\\naccording to the feedback.\\nAnd as you can see, the generated HTML\\nclosely resembles the design mockup,\\nwhich is amazing.\\nA key takeaway from this project\\nis that you must always ensure\\nthat the agents are flexible\\nenough with the provided tools\\nso they can adjust according to feedback.\\nIf you are new to this channel\\nall of our agents\\nare developed\\nusing my own agentic framework\\ncalled Agency Swarm on GITHUB\\nIf you wanna learn it\\nmake sure to check out my previous videos later\\nOkay, so the next project is a unit test\\ngenerating agency developed for an I.T.\\nconsulting firm called “Mobiik”\\nthat specializes in software\\ndevelopment data.\\nAI and cloud services.\\nThe problem\\nwas that the process for generating unit\\ntests was relatively simple,\\nbut at the same time\\nextremely time consuming.\\nAnd it couldn't be automated\\nwith a basic automation\\nbecause obviously\\neach report is different.\\nThat requires\\ndifferent instructions and again,\\nit requires iteration based on feedback.\\nSo here\\nwe decided to integrate\\nthis agent directly\\ninto the same Azure\\nDevOps environment,\\nwhich their developers use daily.\\nAs you can see\\nhere,\\nwe have a board with different statuses,\\nand this is exactly how this company used\\nto perform this process manually.\\nYou know,\\nonce you have an item\\nin specific column,\\nit means that certain tasks\\nneed to be completed.\\nSo here's the first issue.\\nYou know, developing tests\\nfor .MP3 files just as an example.\\nAnd on the right, we can\\nwe can also see the Docker containers\\nto monitor this process.\\nSo let's now drop\\nthis task into the Create\\nTechnical Report column.\\nOkay.\\nAs you\\ncan see now in the Docker\\ncontainer, the task has been received\\nand the processing has started.\\nThe system then searches and analyzes\\nthe code base\\nbased on the status of the item,\\njust like a normal developer would.\\nAnd soon as you can see,\\na comment will appear here\\nwith the revised user story\\nand the generated technical report.\\nSo the technical report\\nincludes introduction\\nand code\\nanalysis with code snippets,\\nuser story analysis and the conclusion.\\nSo next\\nwe create the test plan\\nby dropping it into the next column.\\nAnd again,\\nthe benefit here\\nis that\\nyou can also adjust\\nthose generated stories and generated\\ntest plans before proceeding to generating\\nthe unit test.\\nThis allows you to control\\nyour agent much better.\\nAnd finally,\\nwe drop this item\\ninto the unit test column.\\nSo the system will now",
    "file_path": "playlist_1\\5 Craziest AI Agents We've Ever Built_hb0j9Qn-KjM.json",
    "file_size": 11423,
    "last_modified": "2025-04-18 15:34:00",
    "tags": [
     "5 craziest ai agents we've ever built_hb0j9qn-kjm",
     "agent",
     "and",
     "can",
     "here",
     "json",
     "lang:pt",
     "nand",
     "nso",
     "nthat",
     "nthe",
     "nyou",
     "see",
     "test",
     "that",
     "the",
     "then",
     "this",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "d1a7ae8e2ff61aab6c2353e2ffb96ec3",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 3,
     "processing_time": 0.03139972686767578
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 3,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "5 Craziest AI Agents We've Ever Built_hb0j9Qn-KjM_Part_2",
    "content": "create unit tests.\\nIt will create a new branch of the Azure\\nDevOps environment,\\nand then it will create the pull request\\nwith the generated unit test for review.\\nSo you can see these unit tests\\nbeing created here\\nand then the new branch is made\\nand now you can review\\nthe commits in the repository\\nshowing the new files created\\nby the unit test agent.\\nIn summary,\\nthis simplifies\\nthe whole unit's generation\\nworkflow and seamlessly integrates\\ninto the client's business\\nbecause we're using\\nthe exact same systems\\nthat this client's developers use daily.\\nSo the key takeaway\\nis that you have to integrate your agents\\ninto the exact same systems\\nthat your clients use daily\\nand the cost\\nfor all of those user stories.\\ntest plans\\nand unit tests\\nHowever, keep in mind\\nthat is a very basic example.\\nIt's not a real production repo.\\nAnd in a real production repo\\ntypically there is a lot more code\\nand a lot more complex\\nunit tests that need to be generated.\\nAll right.\\nThe next project is a very common data\\nanalytics use case\\nthat we developed for an online\\npayment processing company.\\nThe problem here\\nis that\\nthey have a lot of different tables\\nand data sets.\\nAnd I mean, like,\\nyou know, not 10 or 20 tables,\\nbut 100 of tables\\nand extracting insights from\\nthose tables\\nis not only time consuming,\\nbut an extremely challenging task.\\nSo all we have to do to use this\\nagent is simply to send it what query\\nfor what we are looking for.\\nIt can include, you know, dates,\\nspecific metrics\\nand maybe even aggregations.\\nSo let's try another query\\nand think I can show it to you here.\\nBut as you can see,\\nthe agent can perform those queries\\nfor any metrics that you want.\\nYeah, and the costs were only a few cents\\ndepending on the amount of context\\nthat the agent needs to retrieve\\nin order to perform the query.\\nAs I said in my previous video,\\nthose data sharing and data\\nanalytics use cases\\nare typically my favorite\\nto get started with\\nbecause it's\\nfirst of all, extremely easy\\nto implement it.\\nAnd secondly, it's\\nextremely easy to build upon.\\nSo once the agent has access\\nto all of that data and their data sets,\\nwe can not only allow it to query\\nthat data\\nand provide us with the insights,\\nbut also take certain actions\\non our behalf.\\nSo this would be\\nthe next step in this project.\\nIt would be making sure\\nthat the agent can actually perform\\ncertain actions,\\nlike for example,\\ndetect fraud\\nand then block certain user accounts.\\nOkay.\\nThe next agent that I wanted to show\\nyou is a Tare Sheet Agent\\nThis agent was developed\\nfor a marketing agency\\ncalled ESM that helps brands to run\\nsuccessful marketing campaigns\\nand visualize the results.\\nTare Sheets in marketing are essentially\\na special PowerPoint presentations\\nwhere you can see\\nhow different ads\\nwill look like on different websites.\\nSo to test this agent,\\nwe first have to upload the ad creatives\\nand then insert into the message\\nall of the websites\\nwhere we want to preview them.\\nThe agent will then proceed\\nwith scraping the website\\nand converting it into an image\\nusing Flash API.\\nI always do\\nrecommend using third party APIs\\nwhenever you can\\nbecause even though\\nwe could implement this tool\\nwith selenium using\\na third party\\nAPI is easier\\nbecause first of all, it simplifies\\nthe deployment\\nand second of all\\nit significantly simplifies\\nthe management of this agent.\\nSo whenever you can create a tool\\nusing the third party API,\\nalways opt out for that.",
    "file_path": "playlist_1\\5 Craziest AI Agents We've Ever Built_hb0j9Qn-KjM.json",
    "file_size": 11423,
    "last_modified": "2025-04-18 15:34:00",
    "tags": [
     "5 craziest ai agents we've ever built_hb0j9qn-kjm",
     "agent",
     "all",
     "can",
     "data",
     "json",
     "lang:pt",
     "nand",
     "nit",
     "nso",
     "nthat",
     "nthe",
     "test",
     "that",
     "the",
     "then",
     "this",
     "unit",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "d1a7ae8e2ff61aab6c2353e2ffb96ec3",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 3,
     "processing_time": 0.03239774703979492
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 3,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "5 Craziest AI Agents We've Ever Built_hb0j9Qn-KjM_Part_3",
    "content": "Okay.\\nSo then as you can see,\\nthe agent replaces\\nthose ads on the web pages\\nthat we just scraped\\nand finally provides us\\nwith a downloadable\\nlink to the PowerPoint.\\nLet's see what it looks like.\\nAwesome.\\nSo as you can see here,\\nwe got the first New York Times\\nwebsite with the ad Creative.\\nClearly replaced on top.\\nAnd we also have Forbes\\nbut since like Forbes\\ndidn't have any ads.\\nAnd finally we have TechCrunch\\nalso with those ad creatives\\ncorrectly placed\\ninstead of the current ads\\non this website.\\nThe way this ad replacement tool\\nworks is actually quite interesting\\nbecause it uses another custom AI model\\nunder the hood.\\nSo as you can see here,\\nwe're calling YOLO\\nthat is deployed\\non the same infrastructure\\nfor the client.\\nAnd then this tool performs\\nobject detection\\nand then replaces it\\nwith the ad creatives\\nprovided by the client.\\nA key takeaway from this project\\nis that you should always use\\npremade solutions\\nfor the tools if possible.\\nSo you know,\\nif there is a pre-made ad detection\\nmodel like the one we use here\\nor an API available\\nthat performs the exact same task,\\nalways just wrap those API’s\\nor external code bases into a tool\\nso that you can save\\non development efforts.\\nAnd the cost for this agent are quite low\\nbecause again,\\nit runs\\na custom model on its own infrastructure\\nand doesn't even use tokens for that.\\nOkay.\\nAnd the final agent\\nthat I wanted to show you\\nis an AMD sheet agent\\nthat is made for a business that owns\\nmultiple e-commerce brands like this one.\\nAnd essentially\\nthey needed an agent\\nthat would fill out\\nessentially special product sheets\\nthat are then\\ninserted into marketplaces like Zalando\\nin order to post the product.\\nSo let's try to upload some product\\ninformation required\\nto fill out this sheet, like,\\nfor example,\\npackaging materials and other product\\ninfo in .CSV files.\\nOkay, So now\\nI'm just going to copy the product name\\nand then hit send.\\nThe agent\\nthen asks me which fields\\ndo I want to fill out.\\nSo I'm just going to say, “all”\\nso then the agent is gonna\\ncheck this product\\nfrom one of the sheets\\nand then proceed\\nwith filling out the AMD sheet\\nSo finally the agent finished\\nprocessing all the fields\\nin the .CSV files,\\nand then it tells us\\nthat there were some errors.\\nSo the user can again\\nprovide some feedback and correct them.\\nHowever,\\nthe real benefit of using AI agents here\\nis that after we have\\nthis fully filled out\\nAMD sheet here\\nwith all the necessary\\nproduct information,\\nas you can see right here,\\nin all of those fields,\\nbasically the client\\nthen sends this AMD sheet to the retailer\\nand the retailer then checks it and sends\\nanother sheet back\\nwhich the client also has to fill out.\\nSo basically\\nwhat happens next is, you know,\\nthe client can take this new sheet\\nand then select another agent\\nthat is specialized\\nfor a processing this next\\nflexible AMD sheet.\\nSo then the client can re-upload the file\\nand again\\nstart the processing for the next sheet\\nwith another agent.\\nIn conclusion,\\nI wanted to provide you\\nThere wasn't a single agent\\nthat didn't demand some coding experience.\\nNow, keep in mind\\nthat there are a lot more caveats\\nthat you have to consider\\nwhen deploying such agents in production,\\nwhich is why I recommend\\nwatching my previous video now,\\nwhere I discussed a lot\\nmore of those insights\\nand answered the top 12 common questions\\nabout where\\nand how to deploy AI agents in businesses.\",\n    \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\5 Craziest AI Agents We've Ever Built_hb0j9Qn-KjM.json\",\n    \"tags\": [\n        \"5 Craziest AI Agents We've Ever Built\"\n    ],\n    \"source\": \"https://www.youtube.com/watch?v=hb0j9Qn-KjM\"\n}",
    "file_path": "playlist_1\\5 Craziest AI Agents We've Ever Built_hb0j9Qn-KjM.json",
    "file_size": 11423,
    "last_modified": "2025-04-18 15:34:00",
    "tags": [
     "5 craziest ai agents we've ever built_hb0j9qn-kjm",
     "agent",
     "api",
     "can",
     "client",
     "here",
     "json",
     "lang:pt",
     "like",
     "model",
     "nand",
     "nso",
     "nthat",
     "out",
     "product",
     "see",
     "sheet",
     "the",
     "then",
     "this",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "d1a7ae8e2ff61aab6c2353e2ffb96ec3",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 3,
     "processing_time": 0.033409833908081055
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 3,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How I 10X'd My AI Agents With Structured Outputs_28_bzuHj4bk_Part_1",
    "content": "{ \"section_name\": \"How I 10X'd My AI Agents With Structured Outputs\", \"content\": \"in this video we're going to\\nsignificantly enhance my AI web\\ndevelopment agency with structured\\noutputs by open AI it will now literally\\nconvert Json schemas into react\\ncomponents that you can use in your\\napplications it will be a live long form\\ntutorial where I will walk you through\\nmy entire process from start to finish\\nso get comfortable and let's dive\\nin so from my PR previous video it seems\\nsome viewers didn't fully understand why\\nwe need to use this feature at all for\\ninstance some people were asking you\\nknow why should we use this if we can\\njust always break down a super complex\\nschema into multiple sub schemas right\\nand the answer is because sometimes it\\njust doesn't make sense to do that so if\\nyou look at their example here on open\\neii they show a way for us to create\\nHTML files and as you know HTML is a\\nvery n structure\\nwhere each component has a type it has a\\nlabel and it has children but the kicker\\nis that children are also components\\nthat have the exact same structure and\\nthe structure itself can go on forever\\nso you can add as many nested components\\nas you want and as you might guess on\\nlike a level 20 most likely your agent\\nis going to hallucinate so what we're\\ngoing to do in this video is we're going\\nto take it a step further and use a\\nmodern library for developing web\\napplications like react react is\\ndesigned in the same way where they have\\na tree of components that make up your\\nuser interface and each component also\\nhas the exact same structure and may\\ncontain other\\nsubcomponents so let's go to our agency\\nform lab repository and here as some of\\nyou might remember we have the def\\nCrafters Agency for developing\\nresponsive web applications so what\\nwe're going to do in this video is we're\\ngoing to significantly enhance this\\nagency specifically by creating new\\ntools for the web developer agent that\\nwill allow it to create react\\napplications from those schemas so it\\nwill take Json parameters as we have\\nseen on the example from openi and then\\nit will convert the schema into a nested\\ncomponent structure let's get started so\\nopen this repo in your code editor and\\nmake sure to install the requirements by\\nfollowing the instructions in a readme\\nfile let's start from the web developer\\nagent as I said and create the first new\\nfile that I'm going to call models.py so\\nthe reason I want to create models.py\\nfile first rather than the tool itself\\nis because first I want to really Define\\nwhat a react component looks like Okay\\nso let's ask cursor to generate a simple\\nreact\\ncomponent awesome now let's try to break\\nit down so as you can see each rack\\ncomponent has inputs on top and then we\\ngot the component itself and inside the\\ncomponent we have props which are\\nessentially the arguments for your\\ncomponent then we have the logic and\\nfinally we got the return statement\\nwhich returns other subcomponents so\\nthis is the basic structure for any\\nreact component and now what we need to\\ndo first is converted into a base model\\nwith\\npenic so let me add some imports and\\nthen let's add the first property of our\\ncomponent which is going to be the\\ncomponent type so the component type is\\nthe type of the component itself for\\nexample it can be the text if it's just\\ntext component it can be empty if it's\\nlike empty component like this or it can\\nbe like a button header footer div span\\nor any other component that you've\\ndefined before now let's create the next\\nproperty which is the props so these are\\nthe arguments that the component will\\ntake and props is essentially just a\\ndictionary with values that are the\\narguments themselves and finally let's\\nadd the children and here's the keyer\\nchildren can be either string because\\nsometimes you know the children of a\\ncomponent it can be just a string like\\nfor example here you know you can add\\njust some text like hello world like\\nthis and this is also considered\\nchildren even though it doesn't have\\nlike a specific type",
    "file_path": "playlist_1\\How I 10X'd My AI Agents With Structured Outputs_28_bzuHj4bk.json",
    "file_size": 18824,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "and",
     "can",
     "component",
     "example",
     "going",
     "have",
     "how i 10x'd my ai agents with structured outputs_28_bzuhj4bk",
     "json",
     "lang:pt",
     "like",
     "ncomponent",
     "react",
     "structure",
     "that",
     "the",
     "this",
     "web",
     "will",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "3347415cc5af68a7885065b1cd135de5",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 6,
     "processing_time": 0.018389463424682617
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 6,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How I 10X'd My AI Agents With Structured Outputs_28_bzuHj4bk_Part_2",
    "content": "of a component so\\nit can be text but otherwise most of the\\ntime it's another react component so as\\nyou can see here inside children we have\\na union type which means that the\\nchildren can be either string or it can\\nbe a list of other react components\\nawesome so this gives us something to\\nwork with so what I'm going to do is\\njust add another file called component\\nCreator\\ntool and inside this component Creator\\ntool we're now going to create a base\\ntool class so let's first add some\\nimports that we're going to need later\\non don't mind the squiggles because I'm\\nin a development mode and now let's\\ncreate our base tool class so in the\\nlatest release there are actually some\\nbreaking changes I'm sorry to introduce\\nbreaking changes but I had to do that\\nbecause right now I'm working on an\\nagency swarm tools repository where we\\nwill collect some of the best pre-made\\ntools that you can reuse in your\\nprojects out of the box I'll show you\\nexactly how to migrate later on but the\\nreason I decided to introduce these\\nchanges now is because agency form no\\nlonger depends on instructor yes guys so\\nagency SW no longer depends on\\ninstructor I removed it from the B tool\\nclass now it's only 78 lines of code and\\nthe rest of the logic will stay exactly\\nthe same you can still create your tools\\nobviously using penic add any properties\\nvalidation logic dock strings and so on\\nso the whole process for creating tools\\nis going to stay exactly the same and\\nthe breaking changes that I introduced\\nare that the one call at a time which is\\na pretty Advanced parameter is now\\nlocated under tool config instead of\\nbeing a global attribute and the shared\\nstate is now a private attribute so I'll\\nshow you exactly how to migrate right\\nnow it takes only 5 Seconds all you need\\nto do is just basically search for\\nshared state in your project and then\\nreplace it with underscore shared State\\nactually you can even search for self.\\nShar state to be sure so use self.",
    "file_path": "playlist_1\\How I 10X'd My AI Agents With Structured Outputs_28_bzuHj4bk.json",
    "file_size": 18824,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "add",
     "and",
     "but",
     "can",
     "changes",
     "component",
     "config",
     "going",
     "how i 10x'd my ai agents with structured outputs_28_bzuhj4bk",
     "json",
     "lang:pt",
     "now",
     "ntool",
     "some",
     "that",
     "the",
     "tool",
     "tools",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "3347415cc5af68a7885065b1cd135de5",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 6,
     "processing_time": 0.018897294998168945
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 6,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How I 10X'd My AI Agents With Structured Outputs_28_bzuHj4bk_Part_3",
    "content": "Shar\\nState and then replace it with self\\nuncore Shar state so simply click\\nreplace all and that's it okay awesome\\nso now let's go ahead and finish our\\ncomponent Creator tool so let's add the\\ndescription first that the tool is going\\nto be generating react components from a\\nJson structure and then let's proceed\\nwith creating the parameters themselves\\nso first we're going to need the file\\npath which is the file path to the react\\ncomponent code then we're going to need\\nImports because as I said those\\ncomponents they have Imports first on\\ntop so the agent needs to provide the\\nImports which will be used in that\\ncomponent after that we might have some\\nlogic like for example handling\\ndifferent buttons or submitting forms so\\nlet's add a logic parameter and finally\\nwe're also going to have the return\\ncomponent however one property I think I\\nforgot is the name of the component\\nbecause the name of the component can\\nsometimes be different so now let's add\\nour tool config and inside that tool\\nconfig let's set the strict mode to true\\nso this will now enable the structured\\noutputs in your\\nprogram and next what we need to do is\\nwe need to implement the run method\\nitself so the run method will generate\\nthe react component code and save it\\ninto a file and the way I approach\\ncreating tools like this is you can use\\nour agency swarm tool GPT so you can\\nfind the link to this GPT on our Discord\\nthis GPT essentially just allows you to\\ncreate tools with agency swarm much\\nfaster so what I'm going to do is I'm\\ngoing to get our react component model\\nI'm just going to copy it here or by the\\nway we're probably going to need a\\nmethod inside that react component model\\nand it's going to be called something\\nlike render this render method is going\\nto render component as a string this way\\nwe can just keep our code a little bit\\ncleaner because later on we can just\\niterate through all of those components\\nrender them and then combine them\\ntogether inside the component Creator\\ntool so what I'm going to do now is I'm\\ngoing to just copy both of those models\\nand I'm going to paste them here into\\nthe component Creator GPT and inside\\nthat GPT I'm just going to add a prompt\\nplease\\nImplement these models with the run\\nmethod so we can generate structured\\nreact components from those base tool\\nclasses it really helps if you define\\nall the parameters in advance for this\\ncustom GPT but yeah feel free to use it\\nin any way you\\nwant awesome so this looks really good\\nin fact I think it's extremely close as\\nyou can see it did generate exactly what\\nI wanted and by the way if your tool\\ndoesn't require internet connection you\\ncan even test it directly inside this\\ntool Creator GPT so let me show you how\\nto do that simply say create some test\\ncases and then test it with the python\\ntool awesome so then it uses the\\nanalysis tool and as you can see it can\\nnow run this file in the remote\\nenvironment however seems like model\\nvalidators not defined because it didn't\\nadd all of the inputs so if it runs into\\nan issue like uh base tool is not\\ndefined simply tell it to replace base\\ntool with the base\\nmodel cool so now as you can see it add\\nsome test cases and runs them for me so\\nI don't even have to do anything it\\nliterally just tested it by itself and\\nas you can see it tells me that the\\noutputs were correct but to ensure that\\nit is in fact correct we also might want\\nto test it with more complex components\\nso let's say please create like two\\nthree more complex test\\ncases nice so now we have more complex\\ntest cases with a form component and\\nwith a layout component awesome so it\\nsays that both test cases were\\nsuccessful so let's copy the code and\\nproceed to creating the other\\ntool so the next tool that we're going\\nto need is going to be called component\\ninjector tool the reason we need the\\ncomponent injector is because sometimes\\nyou might not want to rewrite the entire\\ncomponent and instead you might want to\\ninclude an additional component into the\\nexisting layout so let's create a",
    "file_path": "playlist_1\\How I 10X'd My AI Agents With Structured Outputs_28_bzuHj4bk.json",
    "file_size": 18824,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "and",
     "can",
     "component",
     "config",
     "example",
     "going",
     "gpt",
     "how i 10x'd my ai agents with structured outputs_28_bzuhj4bk",
     "json",
     "just",
     "lang:pt",
     "ncomponent",
     "need",
     "now",
     "test",
     "that",
     "the",
     "then",
     "this",
     "tool",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "3347415cc5af68a7885065b1cd135de5",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 6,
     "processing_time": 0.018897294998168945
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 6,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How I 10X'd My AI Agents With Structured Outputs_28_bzuHj4bk_Part_4",
    "content": "new\\nfile and call it the same way so now\\nagain I'm going to follow the same\\napproach and by the way in this tool we\\ncan already reuse a lot of code that\\nwe've written before so as you can see\\nhere I'm planning to actually reuse the\\ncomponent Creator tool and just render\\nthe component again so here's the\\ndefinition as you can see it's also\\ngoing to take a file path for the\\ncomponent to rewrite then it's going to\\ntake additional Imports in case the\\nagent wants to add some additional\\npackages the component to inject itself\\nthe target component which is the\\nexisting component where we will inject\\nthe new component the index in case of\\nthere are multiple Target components and\\nthe insert index in case if it wants to\\ninsert it at a specific position in the\\nchildren so what this function\\nessentially does is it first it reads\\nthe file it converts it into Json then\\nit injects the new component and then it\\nreenders it so the render to Json\\nfunction can actually use our previous\\nmodel that we've already created so\\nlet's add those functions here okay now\\nlet's take this code and send it to this\\ntool Creator gbt and again tell it to\\ntest it out until it works as expected\\ncool so it did write most of the code\\nhowever it said that the code is\\nsimplified for demonstration purposes so\\nif that happens just make sure to\\nprovide it with some documentation on\\nhow to use for example this third party\\npackage or just give it some idea you\\nknow on how you want to implement this\\nso yeah because this tool uses a third\\nparty package unfortunately it can test\\nit here but what we can do is just tell\\nit to add some test cases at the\\nend cool so let's copy this code and now\\nwe can test it\\nmanually so I didn't really implement\\nthe par j6 tojson function so let me\\njust do it manually basically my idea\\nwas to run like not just script inside\\nthis function so we'll create like a\\nscript inside that function and then\\nwe'll run it using Python and then get\\nthe output back which is going to be our\\npass Json model so if you do want to\\ntest this you do have to install npm and\\nnodejs cool so now we got this new\\npackage and node modules installed which\\nmeans that we can test this script so\\nthen what you can do is simply run this\\nfile like this and this will give you an\\nidea if there are any errors or if the\\ntool is working correctly so here I got\\nsome error with pbl so let me just check\\ntry to correct it and then get back to\\nyou so it seems like the aror was\\nbecause I didn't install some of the\\nother necessary mpm packages so you can\\njust ask cursor like this what packages\\ndo I need to install to run this and\\nit's going to give me the commands now I\\ncan just copy this and run this again\\nokay so finally I finished the component\\ninjector tool it took me much longer\\nthan I expected but as I always say\\ntools are the most important part of the\\nsystem and tools is where you really can\\nget creative When developing AI agents I\\ndon't think it will ever be possible to\\ncompletely avoid coding When developing\\ncustom tools just because of the\\nextremely complex processes that we\\nsometimes encounter in our agency I\\nthink that coding will always be\\nrequired so let's take a look at this\\nincredibly complex tool it's basically\\nwhat it does is it takes the code of the\\nreact component then it deconstructs it\\ninto separate modules like for example\\nit extracts all the if statements all\\nthe logic and it also extracts the\\nreturn component itself and then it\\nreenders this component using our\\nprevious tool back into code so this a\\nvery interesting system where it kind of\\ndeconstructs the component injects the\\nnew component and then assembles it\\nagain so let me show you how this works\\nso this is our app.js file as you can\\nsee right now we have just div button\\nand a spin and we want to insert",
    "file_path": "playlist_1\\How I 10X'd My AI Agents With Structured Outputs_28_bzuHj4bk.json",
    "file_size": 18824,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "and",
     "can",
     "code",
     "component",
     "documentation",
     "example",
     "how i 10x'd my ai agents with structured outputs_28_bzuhj4bk",
     "json",
     "just",
     "lang:pt",
     "like",
     "model",
     "now",
     "nthe",
     "some",
     "test",
     "that",
     "the",
     "then",
     "this",
     "tool",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "3347415cc5af68a7885065b1cd135de5",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 3,
     "total_chunks": 6,
     "processing_time": 0.020109891891479492
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 3,
    "total_chunks": 6,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How I 10X'd My AI Agents With Structured Outputs_28_bzuHj4bk_Part_5",
    "content": "another\\nbutton with a spin and a text hello word\\ntogether so let's run this file and now\\nas you can see our component is indeed\\nchanged so now we do have this new\\nbutton inserted this new span and the\\nhello world text directly inside the\\ncomponent and it reduces the any chances\\nof errors that the agent can make\\nbecause again the agent is not writing\\nopen-ended code the agent follows the\\npredefined Json structure that we\\ncreated so now let's finally proceed\\nwith actually developing the agent\\nitself because after adding tools you\\nalways do have to modify the\\ninstructions so let me now work on the\\ninstructions and then I'll get back to\\nyou okay so here are my instructions\\nwhen writing the instructions always\\nthink about how you would perform or how\\nwould somebody else perform that process\\nso when for example developing websites\\nwhat we typically do is you know we\\ncheck the current directory then we\\ncreate the application boiler plate code\\nthen we start creating the components\\nthen we inject the components in the\\nwebsite then we test the website to see\\nif it's built correctly and then we\\nImplement any adjustments based on the\\nbuild and then we repeat this process\\nuntil finally the website is completed\\nand we can send it to the client so what\\nI also want to do now is I want to uh\\nmodify our previous web designer agent\\nbecause for those who watched my\\nprevious video you know that the\\ndesigner agent right now just provides\\nthe layout as a text but in the another\\nagency that we developed before we\\nactually had the image generator tool\\nthat uses Del again I'll add some of\\nthese predefined tools into the agency\\nSW tools repository soon and share it\\nwith you guys but for now I'm just going\\nto copy this tool and also add it into\\nthe designer agent tools folder so I\\ndecided to play with this agency a\\nlittle bit more I was basically just\\nadjusting instructions and tools and\\nthen testing it on a simple prompt like\\nbuild me a website please until it\\nperformed consistently well so a cool\\nfeature I added is a response validator\\nfunction inside the designer agent that\\nnow allows it to check the current\\nprogress of the website so as you can\\nsee here the agent can now actually get\\nthe screenshot of the Local Host URL so\\nit can see what's currently being done\\non the website and then point out\\nspecific issues to the developer okay so\\nnow let's run this file and do a\\ncomplete demo so for this demo let me\\njust say that I need a new lending for\\nmy EI agency VRC just like I did in my\\nprevious\\nvideo so first the co sends the\\ninstructions to the designer agent and\\nthe designer agent then communicates\\nwith the copywriter who returns the copy\\nfor my website next the designer agent\\ngenerates images using the new image\\ngenerator tool that we added and\\nnotifies the web developer agent to\\nstart the work the web developer agent\\nthen creates a nextjs application using\\nthe Run command tool it inspects the\\ncurrent folder checks all the files and\\nthen it uses our new component Creator\\ntool to generate those new\\ncomponents okay so after as you can see\\nthe generation is completed it's starts\\nthe development server which allows the\\ndesigner agent to review the website as\\nit's being developed as I mentioned\\nbefore so the designer agent then checks\\nthe website it checks the screenshot of\\nthe current web page and then it\\ninstructs the web developer agent to\\naddress any missing components it also\\neven generates additional missing images\\nfor the testimonial sections because the\\ndeveloper agent requested them earlier\\nso it's really cool how those agents can\\nnow collaborate with one another because\\nthe designer can actually check the work\\nprovided by the web developer\\nagent finally the website is completed\\nso let's check it out yeah definitely it\\nlooks much better than the",
    "file_path": "playlist_1\\How I 10X'd My AI Agents With Structured Outputs_28_bzuHj4bk.json",
    "file_size": 18824,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "agent",
     "and",
     "can",
     "client",
     "designer",
     "example",
     "how i 10x'd my ai agents with structured outputs_28_bzuhj4bk",
     "json",
     "lang:pt",
     "new",
     "now",
     "nthe",
     "server",
     "test",
     "that",
     "the",
     "then",
     "this",
     "tools",
     "web",
     "website",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "3347415cc5af68a7885065b1cd135de5",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 4,
     "total_chunks": 6,
     "processing_time": 0.020616531372070312
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 4,
    "total_chunks": 6,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How I 10X'd My AI Agents With Structured Outputs_28_bzuHj4bk_Part_6",
    "content": "version from\\nmy previous video there are still of\\ncourse some minor formating issues um\\nbut the fact that this entire website\\nwas created completely from scratch by\\nthis agent without any templates from a\\nsingle prompt is pretty impressive so\\nfeel free to play with these agents\\nyourself you can either tell them to\\nrefine the website even further or you\\ncan provide some specific instructions\\nfor your own process so that's it for\\nthis video thank you for watching and\\ndon't forget to subscribe because a lot\\nof exciting updates are coming up soon\", \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\How I 10X'd My AI Agents With Structured Outputs_28_bzuHj4bk.json\", \"tags\": [ \"How I 10X'd My AI Agents With Structured Outputs\" ], \"source\": \"https://www.youtube.com/watch?v=28_bzuHj4bk\" }",
    "file_path": "playlist_1\\How I 10X'd My AI Agents With Structured Outputs_28_bzuHj4bk.json",
    "file_size": 18824,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "10x",
     "agents",
     "are",
     "how",
     "how i 10x'd my ai agents with structured outputs_28_bzuhj4bk",
     "json",
     "lang:pt",
     "nthis",
     "some",
     "structured",
     "that",
     "the",
     "video",
     "website",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "3347415cc5af68a7885065b1cd135de5",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 5,
     "total_chunks": 6,
     "processing_time": 0.020616531372070312
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 5,
    "total_chunks": 6,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Agency Swarm Now Supports Open Source Models_Vd-Gtfm_zjw_Part_1",
    "content": "{ \"section_name\": \"Agency Swarm Now Supports Open Source Models\", \"content\": \"disadvantage of my framework is that\\nit's fully based on open AI assistance\\nAPI and to answer your question right\\nnow no we're not going to support any\\nopen source models right so agency swarm\\ndoes support open source models now I\\nstill recommend you guys go with open AI\\nwhenever you can but you know if you\\nwant to use anthropic Google Gemini Mixr\\nor even llama 3 Model running locally\\nwith AMA you now have the flexibility to\\ndo so and I was actually really\\nsurprised how simple it is to set up but\\nthe best part is that you can even\\ncombine different agents with different\\nllms like for example in this video\\nwe're going to create a manager agent\\nthat uses anthropic and controls two\\nother Google Gemini and llama 3 agents\\nlet's dive\\nin okay before we dive into the details\\non how to use my framework with with\\nopen source models we definitely have to\\ntalk about assistance API V2 it released\\na ton of new features that all\\nsignificantly improve how your agents\\nperform in production applications so\\nlet me go through all of them one at a\\ntime and explain how you can already use\\nthem within my framework okay first of\\nall the retrieval tool was replaced with\\nfile search that's actually huge because\\nbefore as I said in my previous video\\nthe retrieval tool in open a assistance\\nCPI is is currently now you get\\nessentially like Enterprise level rack\\nout of the box this has been a game\\nchanger for almost all of my clients\\nbecause now you don't have to set up any\\ndata processing yourself you don't have\\nto connect to third party Vector\\ndatabases all you have to do is just\\nattach files to your assistant and then\\nopeni will do all the processing all the\\nchunking for you and upload that data\\ninto your own Vector store so some of\\nthe techniques that they're currently\\nusing include like cury rewriting\\nbreaking down complex queres into\\nmultiple searches that can be run in\\nparallel using both keyword and semantic\\nsearches and additionally reranking the\\nresults so as I said this is all of the\\ntechniques that we use in production\\nlevel rag applications like straight out\\nout of the box without you having to\\nworry about any of the details okay next\\nhuge update is that now you can finally\\ncontrol the maximum number of tokens\\nthat assistant uses in a specific run so\\nwhat does this mean well before you know\\nyou couldn't really control how many\\ntokens were in The Prompt when you were\\nusing a assistance API now basically\\nwhat you can do is simply add Max prompt\\ntokens parameters inside my framework so\\nthen you can set it to for example 248\\nalthough openi does recommend setting it\\nto more than 20,000 if you're using any\\nfile searches additionally there is now\\na new parameter called tration strategy\\nwhich allows you to select how you want\\nthose prompt tokens to be truncated so\\nif you set it to Auto open AI says that\\nthey're using their own algorithm and\\nfrom what I've observed it seems like\\nthey're keeping like the first few\\nmessages and then they're also keeping\\nthe end of the conversation but they're\\nremoving the middle of the discussion so\\nthis allows you apparently to achieve\\nslightly better results because the\\nfirst few messages typically play a\\ncrucial role in how the conversation\\nwill unfold so I do recommend you keep\\nit at Auto because openi probably knows\\nwhat they're doing but you can also set\\nit to last messages if you want so if\\nyou make tration strategy and object and\\nthen inside you specify type to last\\nmessages you can then select how many\\nmessages will be kept in the\\nconversation history this means that\\nonly the five last messages will be used\\nin order to generate a response by the\\nassistant Additionally you can of course\\nalso select the max completion tokens\\nwhich will limit the number of tokens\\nthat your assistant can generate at once\\nas you can see all of those parameters\\nare actually under the Run endpoint not\\nunder the assistant endpoint however in\\nmy framework",
    "file_path": "playlist_1\\Agency Swarm Now Supports Open Source Models_Vd-Gtfm_zjw.json",
    "file_size": 19911,
    "last_modified": "2025-04-18 15:34:01",
    "tags": [
     "agency swarm now supports open source models_vd-gtfm_zjw",
     "all",
     "and",
     "api",
     "can",
     "example",
     "framework",
     "have",
     "how",
     "json",
     "lang:pt",
     "like",
     "model",
     "now",
     "open",
     "set",
     "that",
     "the",
     "this",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "ebd516e07606d7e5afdfffcdbcf2784c",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 7,
     "processing_time": 0.03861856460571289
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Agency Swarm Now Supports Open Source Models_Vd-Gtfm_zjw_Part_2",
    "content": "you can specify them\\ndirectly within each assistant in my\\nopinion it's more convenient this way\\nbecause typically those parameters don't\\nalternate between different messages as\\nmuch moreover you can set all of those\\nparameters even within the agency class\\nso now as you can see in the latest\\nversion of my framework you can also\\nspecify the max promt tokens within the\\nagency directly and this parameter will\\nact sort of as a default for all your\\nagents so for example if I set the max\\npromt tokens parameter inside the agency\\nclass to\\n248 all of the agents will use 248\\ntokens in the conversation by default\\nhowever if I set this parameter to 4,000\\nwithin the planner agent the planner\\nagent will actually use 4,000 tokens the\\nsame principle still applies to all the\\nother new parameters like truncation\\nstrategy and temperature by the way\\ntemperature is probably one of the most\\nuseful updates from the whole assistance\\nV2 API release because it seems like\\nopeni actually used one for temperature\\nby default in assistance API V1 which is\\nin my opinion a bit too much you see in\\nproduction applications especially in\\nagentic applications we almost never set\\ntemperature to one because in my opinion\\ncreativity is a lot less important than\\nhallucinations so if you reduce the\\ntemperature to something like zero or3\\nyou're going to reduce the\\nhallucinations but at the same time\\nobviously your outputs wouldn't be as\\ndiverse in my framework currently the\\ndefault is set to3 however for any\\ncoding use cases I do recommend that you\\nset it to zero okay next we got tool\\nChoice meaning that you can finally\\nselect which tool the assistant will use\\nthis is primarily going to be most\\nuseful for backend Integrations where\\nyou are using the get completion method\\nso now after you specify the message you\\ncan also specify the tool Choice within\\nthis method then you can select it as\\nAuto required or you can say set type to\\nfunction and then specify the function\\nchoice so in this example as you can see\\nI'm forcing the agent to use the send\\nmessage tool which means that this agent\\nwill be required to talk to another\\nagent when I say hi next we finally get\\na way to add assistant messages to\\nthreats which means that now we can\\nfinally do few short learning so let me\\nshow you how this works you can find\\nthis under Advanced usage agents section\\nin the commun ation for agency swarm\\nwhere I've added a section on how to use\\nfew short examples with my framework so\\nessentially you just have to create an\\narray of messages that you want your\\nagent to remember then you can pass\\nthese examples inside the example\\nparameter for your agent where this can\\nbe mostly useful is if for example you\\nwant to create emails or any other text\\nin your own style of writing so then you\\ncan say for example please create an\\nemail for me that answers the following\\nquestion\\nand as the assistant response you can\\nsimply include the email yourself that\\nyou have written before this way the\\nmodel will remember your style of\\nwriting and will try to replicate it in\\nfuture messages however keep in mind\\nthat if the tration strategy for your\\nagent is set to last messages and the\\nnumber of last messages exceeds the\\nnumber of messages in the conversation\\nit means that your examples might not be\\nincluded next we have Json mode which\\nmeans that you can force your assistant\\nto always response in Json object format\\nif you specify type to Json object\\nhowever keep in mind that you must also\\ninclude in the instructions that the\\nagent must respond using Json otherwise\\nthis parameter will not work and last\\nbut not least you can now use fine tuned\\nmodels directly within each assistant\\nyou can check any fine tune models that\\nyou've created by going to the\\nplayground here under the model\\nparameter you will see all the fine",
    "file_path": "playlist_1\\Agency Swarm Now Supports Open Source Models_Vd-Gtfm_zjw.json",
    "file_size": 19911,
    "last_modified": "2025-04-18 15:34:01",
    "tags": [
     "agency swarm now supports open source models_vd-gtfm_zjw",
     "all",
     "and",
     "api",
     "assistant",
     "can",
     "example",
     "json",
     "lang:pt",
     "messages",
     "set",
     "specify",
     "that",
     "the",
     "this",
     "use",
     "will",
     "within",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "ebd516e07606d7e5afdfffcdbcf2784c",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 7,
     "processing_time": 0.040625572204589844
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Agency Swarm Now Supports Open Source Models_Vd-Gtfm_zjw_Part_3",
    "content": "tune\\nmodels you can simply then copy this\\nmodel name and paste it inside the model\\nparameter for your agent then the agent\\nwill use this fune model that's it guys\\nfor all the new assistants V2 updates\\nkeep in mind that all of them are using\\nthe exact same format in my framework as\\nin the official open a API now finally\\nlet me show you how to use my framework\\nwith open source models or with any\\nmodels as a matter of fact okay so the\\nfirst step is to install my agency swarm\\nlab repository where by the time you\\nwatch this video you'll find a new open\\nsource swarm which you can use as a\\nstarting point for your project just\\nmake sure to follow all of the steps\\nfrom the readme first you need to clone\\nthis reer then install the main\\nrequirements from the main\\nrequirements.txt file in the root folder\\nand then you're basically ready to go so\\nafter that let's navigate into the open\\nsource form repository and here you need\\nto install additional requirements file\\nso this requirements file actually uses\\nagency form 017 version because\\ncurrently the repository that we're\\ngoing to be using to emulate assistant\\nAPI is not very stable with streaming\\nI'm hoping that it's going to change\\nsoon but for now we're going to have to\\nuse one of the previous versions agency\\nswarm which means that also most of the\\nassistant V2 features are currently not\\navailable once they become available\\nI'll of course update this reposit area\\nand send a notification in our Discord\\nso simply run peep install dasr\\nrequirements.txt from the op Source\\nswarm\\ndirectory after the installation is\\ncompleted you will find another light\\nllm config do yaml file in this file we\\nwill set all the API keys and models\\nthat we will use with light llm so light\\nllm is essentially a library that allows\\nyou to create an openi proxy server that\\nyou can use with any open source or\\ncommercial models so in this example I'm\\ngoing to be using anthropic Gemini\\nmistal provided by together AI Gro and\\nof course AMA running Lo Al with llama 3\\nso you can copy this file and simply set\\nall the API keys for any providers that\\nyou want to use for all Lama you\\nobviously don't have to set any API keys\\nso you can put 1 2 3 4 or anything else\\nawesome so because we want to run the\\nlatest llama 3 Model locally will'll\\nalso have to install AMA the\\ninstallation process is actually really\\nsimple all you have to do is just\\ndownload the file and then just follow\\nall the installation steps after the\\ninstallation process is completed all\\nyou have to do is simply run or Lama run\\nllama 3 command then you will see a chat\\ninterface like this and you can simply\\nsay hi as you can see we get this nice\\nresponse and we can also for example ask\\nwhat llm are you awesome so as you can\\nsee it indeed says that this is llama\\ndeveloped by meta AI which means that we\\ncan proceed to The Next Step so the next\\nstep is to actually run our light llm\\nproxy server which you can do with the\\nfollowing command light llm config and\\nthen you insert the name of your config\\nyaml file this will activate at our\\nproxy server on Local Host Port 4000\\nwith all of the models that you\\nspecified in your llama config file\\nawesome so the next step is to pull the\\nopen Assistant API repository this is\\nthe repository that will essentially\\nmimic the assistant's API back end on\\nour local machine it supports almost all\\nof the features that open AI assistance\\nAPI supports natively and even provides\\nsome additional features like for\\nexample you can already use web browsing\\nif you provide your subscription\\nkey however as I said some features are\\nstill a bit unstable for example I found\\na bug that prevents using this back end\\nwith custom tools so I already fixed\\nthis back and created my own Fork which\\nhopefully is going to be merged shortly\\nfor now however all you",
    "file_path": "playlist_1\\Agency Swarm Now Supports Open Source Models_Vd-Gtfm_zjw.json",
    "file_size": 19911,
    "last_modified": "2025-04-18 15:34:01",
    "tags": [
     "agency swarm now supports open source models_vd-gtfm_zjw",
     "all",
     "and",
     "api",
     "can",
     "config",
     "example",
     "file",
     "install",
     "json",
     "lang:pt",
     "model",
     "open",
     "server",
     "simply",
     "that",
     "the",
     "then",
     "this",
     "use",
     "will",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "ebd516e07606d7e5afdfffcdbcf2784c",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 7,
     "processing_time": 0.04162263870239258
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Agency Swarm Now Supports Open Source Models_Vd-Gtfm_zjw_Part_4",
    "content": "need to do is\\nsimply pull my Fork instead of the main\\nReaper and then we can proceed with\\nrunning this back end you will find all\\nof those detailed instructions inside\\nthe open source form directory in agency\\nSW lab to pull my Fork you can simply\\nuse the following git clone command\\nafter after it has been copied locally\\nyou will see this folder here on the\\nleft now the next step is to replace our\\nURLs inside the docker compost file\\nscroll down a bit until you see the open\\nAI base parameter under the llm config\\nhere you need to insert the following\\nURL HTTP host.",
    "file_path": "playlist_1\\Agency Swarm Now Supports Open Source Models_Vd-Gtfm_zjw.json",
    "file_size": 19911,
    "last_modified": "2025-04-18 15:34:01",
    "tags": [
     "agency swarm now supports open source models_vd-gtfm_zjw",
     "can",
     "following",
     "fork",
     "inside",
     "json",
     "lang:pt",
     "need",
     "open",
     "pull",
     "see",
     "the",
     "this",
     "will",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "ebd516e07606d7e5afdfffcdbcf2784c",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 3,
     "total_chunks": 7,
     "processing_time": 0.04162263870239258
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 3,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Agency Swarm Now Supports Open Source Models_Vd-Gtfm_zjw_Part_5",
    "content": "doer. internal Port 4000\\nV1 we're going to be using a special\\nhost. doer. internal URL because it Maps\\nthe address from within the docker\\ncontainer to our Local Host URL on our\\nhost machine for the API key you can\\nsimply set anything like 1 2 3 4 because\\nwe're using light llm okay next let's\\nnavigate into this open assistants API\\nrepository and then all you have to do\\nis simply run Docker compose app- D\\ncommand this will build your container\\nand start it as a background process it\\nwill take some time to build the first\\ntime you run it but then the opening\\nassist API will always be running on\\nyour local machine in the background\\nwhich is extremely convenient if you\\ndon't have Docker installed the\\ninstallation is very simple I've already\\nshown this in one my previous videos\\nsimply follow the link from the readme\\nin open source swarm directory and then\\ninstall it for whichever OS you use Okay\\ncool so now that our assistant API\\nbackend is running it's time to set up\\nour agents again navigate into the open\\nsource swarm directory and then I'm\\ngoing to use the agency swarm create\\nagent template command I'm going to\\nstart with the basic CEO\\nagent then I'm going to create a llama\\nagent and finally I want to create\\nanother Google Gemini agent\\ncool so after our agent template folders\\nhave been created you can open them on\\nthe left so let's start with the CEO\\nagent for the CEO I want to use the\\nlatest cloth model by\\nanthropic so all you have to do is\\nsimply copy the model name that you\\npreviously set in your light LM config\\nfor the Llama agent obviously I'm going\\nto be using AMA llama 3\\nmodel and for the Google Gemini agent\\nI'm going to be using the Gemini Pro 1.5\\nlatest cool so that's literally almost\\nit that's all it takes to run my\\nframework now with open source models\\nand the final step is to Simply set up\\nthe agency dopy file so let's add all\\nour agent inputs just like this then we\\nhave to initialize the opene client with\\na few different parameters so first\\nwe're going to be setting the base URL\\nto the URL of our open Assistant server\\nthe API key you can literally set to\\nanything and for the default headers\\nwe're going to be using assistance V1\\nAPI then you just have to set open\\nclient that you've initialized before\\nusing the set open client method from\\nagency form now we are ready to\\ninitialize our agents and create our\\nagency structure so let's initialize all\\nthe agents as variables and then simply\\nset the agency with whatever structure\\nyou want to use so here I'm going to\\nhave a COO agent that can communicate to\\nboth llama agent and the Google gini\\nagent awesome the final step is to\\nSimply run the demo gradio method\\nhowever here when we're not going to be\\nusing the default demo gradio method\\nfrom the agency class instead we're\\ngoing to use the demo gradio method that\\nyou will find inside the open source\\nswarm directory here on the left so this\\ndemo gradio method is essentially just a\\nprevious version which does not utilize\\nstreaming by default and instead simply\\nprints out the messages one by one again\\nas I said this is because the current\\nopen assistance API is not as stable\\nwith streaming however I'm hoping that\\nthis is going to be fixed shortly also\\nso now we should be ready to run this\\nagency again navigate into the open\\nsource form folder and then simply run\\npython agency.",
    "file_path": "playlist_1\\Agency Swarm Now Supports Open Source Models_Vd-Gtfm_zjw.json",
    "file_size": 19911,
    "last_modified": "2025-04-18 15:34:01",
    "tags": [
     "agency swarm now supports open source models_vd-gtfm_zjw",
     "agent",
     "all",
     "and",
     "api",
     "client",
     "going",
     "json",
     "lang:pt",
     "model",
     "nthe",
     "open",
     "our",
     "run",
     "set",
     "that",
     "the",
     "then",
     "this",
     "using",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "ebd516e07606d7e5afdfffcdbcf2784c",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 4,
     "total_chunks": 7,
     "processing_time": 0.04262113571166992
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 4,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Agency Swarm Now Supports Open Source Models_Vd-Gtfm_zjw_Part_6",
    "content": "Pi cool so as you can see\\nnow we get the same gradio interface and\\nnow let's ask the C agent who is\\nhere as you can see it says that it's\\nindeed an artificial intelligence\\ndeveloped by anthropic and the purpose\\nof this agent is to be a helpful digital\\nassistant it also includes thought here\\nat the top which aren't filtered by my\\ngradio interface but probably should be\\nthat's interesting actually I was quite\\nsurprised on how anthropic added like\\nthe special thinking prompts inside the\\nmodel responses so as you can see here\\nanthropic can actually print like a\\nspecial tag and then think before\\nanswering the question so this is not\\nfiltered by the demog gradio interface\\nwhich is why it might look like it's not\\neven speaking to you on the first\\nsentence and then it provides the\\nresponse for the question that you asked\\nbefore now let's tell it to ask the same\\nquestion from the Llama\\nagent as you can see it now sends the\\nmessage to the Llama agent using the\\nsend message\\ntool as you can see the Llama agent then\\nanswers the question and also includes\\nsome background capabilities and the\\npurpose cool Theo then relays all of\\nthis information to me but again as I\\nsaid it shows some of the thoughts in\\nthe beginning and then it also has like\\nthis special function output sorry\\nsearch quality score parameter which is\\ninteresting because it seems like\\nanthropic actually rates its own\\nfunction calls so probably by the time\\nyou watch this video I'll actually add\\nsome filtering for that or formatting in\\nthe demog gradio interface another\\nimportant thing that you do have to keep\\nin mind is that not all of the open\\nsource or commercial models currently\\nsupport function calling so for example\\nLama 3 by o Lama obviously does not\\nsupport any function calls which means\\nthat you can only use this agent as the\\nvery end in your agency chart because if\\nyou add it anywhere in front of your\\nagency chart and allow it to communicate\\nwith other agents it's not going to be\\nable to do this because as you might\\nknow in my framework all the\\ncommunication is handled through a\\nspecial send message tool okay finally\\nlet's as Theo as the Google Gemini\\nagent awesome as you can see it now\\nsends message to Google Gemini agent\\nwith all the arguments correctly defined\\nwhich is great I mean yeah it's\\nanthropic seems to be actually pretty\\ngood with function calls which is why I\\ndecided to use it as the COO agent\\nGoogle Gemini then says that it's a\\nlarge language model created by Google\\nand also provide some of the\\ncapabilities so yeah that's basically it\\nguys this is how you use my framework\\nwith any open source or commercial\\nmodels it's the process is actually\\nquite simple but as I said please do\\nkeep in mind that function col is not\\nsupported by every single model and in\\nany agentic system in my opinion\\nfunction calling is obviously the most\\nimportant feature so to check Which\\nmodels support function calling and\\nwhich don't in light LM I actually\\ncreated another function calling\\nsupport.",
    "file_path": "playlist_1\\Agency Swarm Now Supports Open Source Models_Vd-Gtfm_zjw.json",
    "file_size": 19911,
    "last_modified": "2025-04-18 15:34:01",
    "tags": [
     "actually",
     "agency swarm now supports open source models_vd-gtfm_zjw",
     "agent",
     "also",
     "and",
     "can",
     "interface",
     "json",
     "lang:pt",
     "like",
     "model",
     "not",
     "see",
     "that",
     "the",
     "then",
     "this",
     "which",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "ebd516e07606d7e5afdfffcdbcf2784c",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 5,
     "total_chunks": 7,
     "processing_time": 0.04262113571166992
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 5,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Agency Swarm Now Supports Open Source Models_Vd-Gtfm_zjw_Part_7",
    "content": "Pi file where you can insert\\nyour model name and then check if the\\nvalue is true or false so all you have\\nto do is simply run this file and this\\nwill allow you to check whether this is\\ncorrect or not I've also tested this\\nwith Gro and many other providers like\\ntogether Ai and it seems to be working\\njust fine as I said the read me with all\\nof the previous setup instructions will\\nbe available inside the open source\\nswarm directory in my agency swarm lab\\nrepository I know it was one of the most\\nrequested features on our Discord so I'm\\nsuper excited to see what all you guys\\ncreate thank you for watching and don't\\nforget to subscribe\",\n    \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\Agency Swarm Now Supports Open Source Models_Vd-Gtfm_zjw.json\",\n    \"tags\": [\n        \"Agency Swarm Now Supports Open Source Models\"\n    ],\n    \"source\": \"https://www.youtube.com/watch?v=Vd-Gtfm_zjw\"\n}",
    "file_path": "playlist_1\\Agency Swarm Now Supports Open Source Models_Vd-Gtfm_zjw.json",
    "file_size": 19911,
    "last_modified": "2025-04-18 15:34:01",
    "tags": [
     "agency",
     "agency swarm now supports open source models_vd-gtfm_zjw",
     "all",
     "and",
     "check",
     "file",
     "gtfm_zjw",
     "json",
     "lang:pt",
     "model",
     "now",
     "open",
     "setup",
     "source",
     "supports",
     "swarm",
     "the",
     "this",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "ebd516e07606d7e5afdfffcdbcf2784c",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 6,
     "total_chunks": 7,
     "processing_time": 0.043619632720947266
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 6,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Building an AI Agent to Automate My Agency Live_rHBM1erNqFM_Part_1",
    "content": "{\n    \"section_name\": \"Building an AI Agent to Automate My Agency Live\",\n    \"content\": \"In this video, I'll be automating one of the \\nhighest paying roles in my agency, which is a  \\ntechnical project manager. I'll show you how to \\nbuild an agent that will work in your Slack 24  \\nseven completely for free, meaning that you will \\nonly pay for tokens and nothing else. This system  \\nis also easily customizable, so you can fine \\ntune it for your or your client's business.\\n \\nNow let's see a quick demo. Okay, just pretend \\nthat I'm a client and that I have an issue  \\nwith an AI email agent that we recently \\ndelivered. And for those who don't know,  \\nmy agency specializes in creating custom AI \\nagent systems for businesses worldwide. So,  \\nafter I sent this message in Slack, the agent \\nimmediately responded to me in the same thread.\\n \\nAnd by the way, this agent can even determine \\nwhether it needs to respond in this thread or  \\nnot. So it only answers when the client has \\nan issue or some feedback. It asks me for  \\nsome additional details, as you can see on the \\nscreen, just like a real project manager would. \\nSo let me provide all of that. \\nOnce I do this, as you can see,  \\nit informs me that the task has been posted for \\nour development team. As I always say, your agents  \\nshould work alongside your employees, meaning \\nthat they should use the exact same systems  \\nthat your employees use daily. And because our \\ndevelopers are tightly organized around Notion,  \\nthis agent also posts tasks in Notion.\\nSo let's go into our Notion project page, and  \\nhere, under the backlog category, you can now see \\nthis new task. It has the exact same format that  \\nI would expect from the real project manager, with \\na clear background, some actionable to do items,  \\nand additional notes. So now, let me show you how \\nyou can build a similar Slack agent for your or  \\nyour client's needs in just 20 minutes.\\nLet's dive in. \\n \\nOkay, open your code editor, and if you \\nhaven't already done so, make sure to install  \\nAgency Swarm, which is my agentic framework \\nfrom GitHub. Then, of course, like always,  \\nwe're going to be using the Genesys agency to help \\nus get started faster. In my prompt, I'm going  \\nto say that I need this project manager with two \\ntools, and then describe what each tool does.\\n \\nSo the first tool is the Get Project Overview \\ntool, which fetches the project information  \\nfrom our Notion. And the second tool is the Post \\nBacklog Task tool. So let's send this prompt. And  \\nafter the process of creating our agents is \\ncompleted. We can see this agency on the left  \\nas I requested with one agent and two tools.\\nNow, the next step is to adjust these tools  \\nbecause obviously the Genesis agency is not \\nperfect. So since we're gonna be using Notion API,  \\nwe're gonna have to create a Notion account. \\nHowever, keep in mind that you can easily  \\nreplace Notion here with whatever system that \\nyour employees use. So for example, if you  \\norganize your tasks in Jira instead of Notion, \\nall you need to do in this tutorial is simply  \\nreplace this tool with a tool that Jira. \\nOkay, so on Notion, we need to get a new API  \\nkey by creating an integration, select my \\nworkspace, select type internal, and then you  \\ncan see the API key on the next page. So simply \\ncopy this key and go back into the code editor,  \\nand then paste it into the env file. Then we \\nneed to connect this integration to Notion.\\n \\nAfter that, you also need to copy the page \\nID, which you can find in the page URL. So  \\nsimply copy the page link, and then remove \\neverything from the URL except the ID at  \\nthe end. Now let's adjust the first tool, \\nwhich is the get project overview tool.\\n \\nSo what we're going to do is we're going to \\nget the first block from the Notion page,  \\nand then we're going to convert it to \\na markdown because by default, Notion  \\nreturns very strange format, similar to HTML, \\nwhich could be hard for the agent to read.",
    "file_path": "playlist_1\\Building an AI Agent to Automate My Agency Live_rHBM1erNqFM.json",
    "file_size": 15345,
    "last_modified": "2025-04-18 15:34:00",
    "tags": [
     "agency",
     "agent",
     "and",
     "api",
     "building an ai agent to automate my agency live_rhbm1ernqfm",
     "can",
     "client",
     "json",
     "lang:pt",
     "notion",
     "page",
     "project",
     "see",
     "that",
     "the",
     "then",
     "this",
     "tool",
     "tutorial",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "016b2f086b4d61a521c1b77db0bac050",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 5,
     "processing_time": 0.05163431167602539
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 5,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Building an AI Agent to Automate My Agency Live_rHBM1erNqFM_Part_2",
    "content": "\\n \\nTo test this tool, all you need to do is simply \\nadd if name equals main statement at the bottom,  \\nand then run this file. As you can see, we \\nget this nice project overview with some  \\ngoals and objectives exactly like they are \\ndefined in our notion page. Now let's also  \\nconnect to the tasks database so the agent \\ncan actually post the backlog task. \\n \\nLet's hardcode this page ID again on the \\ntop instead of providing it inside the  \\ntool. And what I want to do next is also \\nadd a special field validator. So again,  \\nbecause my framework relies on instructor \\nlibrary, you can add special validator  \\nfunctions inside the tools to ensure that all of \\nthe inputs provided by the agent make sense.\\n \\nAnd because I want my project managers \\nto always include certain to do items,  \\nwhat I'm gonna do is make sure that the \\nmarkdown actually contains the necessary  \\ncharacters that indicate the presence of a \\nto do item in this task. So let's add the  \\ninstructions similar to those that I would \\nprovide to my managers and also include.\\n \\nThose formatting details at the bottom for \\nhow to properly scope the tasks. After that,  \\nlet's adjust the logic of the task. So I'm going \\nto create another folder called util and inside  \\nthat folder I'm going to create a constants. py \\nfile where I'm going to move the task template. \\nSo this template will serve as, you know, \\nthe default parameters for the task.\\n \\nFor example, we're going to set the status \\nto backlog and also we're going to add some  \\nformatting that we've seen before. Next, let's \\nset the task title inside the properties of our  \\ntask template. And let's also convert the \\npage content to a list because in Notion,  \\nas you can see, it takes a list of content \\nblocks instead of a single markdown content. \\n \\nSo we'll need another function called \\nsplit into segments and markdown to list,  \\nwhich will essentially just format. The \\nmarkdown into the format preferred by  \\nNotion where each line is a separate content \\nblock with its own markdown inside. \\n \\nAnd finally, we can just send this data to Notion \\nAPI in the request. So to test this task again,  \\nlet's add if name equals main statement with \\nsome example, markdown text. And the background. \\nLet's execute this Python file. \\nAnd as you can see, it tells us that  \\nthe task has been posted successfully. So let's \\ncheck it in Notion and yes, indeed, we got this  \\ntask in Notion with some example content. Okay, \\nnow let's create a firebase account. We'll need  \\nfirebase later when we'll be integrating \\nagent in slack. Enter your project name.\\n \\nYou can disable Google Analytics and \\nthen simply click create project. After  \\nthe project has been created Go to Firestore \\ndatabase and then click create database. \\n \\nAfter that, we need to get the service account \\nkey. So go to settings and under service  \\naccounts click generate new private key. \\nCopy this key and paste it into the same project  \\nwith your agent.",
    "file_path": "playlist_1\\Building an AI Agent to Automate My Agency Live_rHBM1erNqFM.json",
    "file_size": 15345,
    "last_modified": "2025-04-18 15:34:00",
    "tags": [
     "also",
     "and",
     "building an ai agent to automate my agency live_rhbm1ernqfm",
     "can",
     "content",
     "create",
     "database",
     "example",
     "going",
     "inside",
     "json",
     "lang:pt",
     "notion",
     "nto",
     "project",
     "task",
     "test",
     "that",
     "the",
     "this",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "016b2f086b4d61a521c1b77db0bac050",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 5,
     "processing_time": 0.05263495445251465
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 5,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Building an AI Agent to Automate My Agency Live_rHBM1erNqFM_Part_3",
    "content": "Now we'll need to create a \\nspecial generate response function that we'll  \\nuse later on when integrating the agency in slack \\nSo we'll be using a simple get completion function  \\nto generate a response But we also as I said need \\nto save the threads in the database This ensures  \\nthat the agent can later on continue the same \\nconversation where it left off So it's import our  \\nservice API key initialize the database and then \\nwe need to create two new functions So the first  \\nfunction will get these threats from the \\ndatabase, depending on the conversation ID,  \\nwhere the conversation ID later on is \\ngonna be the threat ID from Slack.\\n \\nAgain, this is because we want our agent \\nto continue the same conversation or start  \\na new conversation for each threat, and the \\nsecond function will be called safe threats  \\nto the database. This function will act in a \\nsimilar way, except it will save the threats  \\nto the database. Now let's try to generate a \\nresponse with a test channel and a test id.\\n \\nBut also don't forget to add your OpenAI key. \\nSimply run this file and it's gonna print a  \\nresponse. Now let's check if this thread actually \\nexists in Firestore. And as you can see, yes,  \\nwe have this Slack chats collection with \\nthe document that is named test channel test  \\nthread and our threads ID inside. Now, let's \\ncreate the Slack app itself. Go to api.\\n \\nslack. com slash apps and click create a new \\napp. Here you can click from scratch, select  \\nyour workspace, app name, and then click create \\napp. Go to the OAuth and permissions and scroll  \\ndown to the scopes. Here we'll need to add a few \\npermissions for the app to work properly. \\n \\nAfter that, click install to workspace \\nand install this app into your Slack. \\nCopy your bot user OAuth token and then go \\nback to basic information. Here you also  \\nneed to copy the sign in secret. Paste them \\ninto the env variable and then create a new  \\napp. py file. So this app. py file will actually \\ncontain the code for our Slack application.\\n \\nWe're going to be using SlackBot, \\nwhich is a really nice package  \\nfor creating simple Slack apps fast. \\nSo here we need to add another if block which  \\nwill just return the challenge and authenticate \\nour application. Now let's proceed with creating  \\nthe actual bot logic. So here I'm going to create \\na special function which will be triggered on two  \\nevents. The first event will be appMention \\nand the second event will be onMessage.\\n \\nThis essentially means that our bot will be \\ntriggered anytime someone mentions it in Slack  \\nor also on every message. And the reason we want \\nto trigger it on every message is because later  \\non we're going to also add some logic to determine \\nwhether it needs to respond in the thread or not. \\nSo here we're going to get some additional user \\ninformation to see who sent the message. \\n \\nI don't really want the Slack bot to respond to my \\nmanagers, which is why I'm going to filter out all  \\nrequests that are coming from the same workspace. \\nThen I'm going to get the real name of the user  \\nwho sent the message and slightly adjust the \\nformat for the message itself. So I want the agent  \\nto also understand who sent the message, which is \\nwhy I'm going to add this real name up front. \\n \\nAnd then I'm going to check if the response is \\nrequired. So as you can see, this function has  \\na pretty large prompt and it uses GPT 4 O mini \\nto determine whether the agent needs to respond  \\nor not. So here are some specific guidelines \\nfor when to respond to the clients or not,  \\nbecause again, we don't want this agent \\nto respond on every single message.\\n \\nWe only want it to respond in this thread \\nwhen there is some feedback from the client.",
    "file_path": "playlist_1\\Building an AI Agent to Automate My Agency Live_rHBM1erNqFM.json",
    "file_size": 15345,
    "last_modified": "2025-04-18 15:34:00",
    "tags": [
     "also",
     "and",
     "api",
     "building an ai agent to automate my agency live_rhbm1ernqfm",
     "create",
     "database",
     "going",
     "here",
     "json",
     "lang:pt",
     "message",
     "need",
     "now",
     "nto",
     "respond",
     "slack",
     "test",
     "the",
     "this",
     "want",
     "will"
    ],
    "is_chunked": true,
    "content_hash": "016b2f086b4d61a521c1b77db0bac050",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 5,
     "processing_time": 0.05263495445251465
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 5,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Building an AI Agent to Automate My Agency Live_rHBM1erNqFM_Part_4",
    "content": "\\nAnd then we're going to check if the thread \\nID is not in the event, and in this case,  \\nwe need to create a new thread and then post the \\nmessage in this thread. And if the thread already  \\nexists, we can simply generate the response like \\nabove, but send it in the exact same thread. \\n \\nSo for testing this locally, you'll also need \\nto install ngrok and then authenticate it. After  \\nthat, you can simply run ngrok HTTP and then enter \\nyour localhost address. This will create a public  \\nURL for your uvcorn server. Copy this forwarding \\naddress, go back to the Slack app configuration,  \\nand paste it into the request URL.\\nNow it's subscribed to some of the events  \\nthat we have just created in our Slack app. Then \\nyou can just save the changes and now we're ready  \\nto test this app. Make sure to add this agent in \\nthe channel first, and then you can simply tag it  \\nlike this and say hello. As you can see the agent \\nnow responds in the same thread and If I send  \\nsome requirements like I'm a client, you can see \\nthat it immediately tells me that the development  \\nteam will start working on this task soon.\\nAnd you can see this new task being posted in  \\nour Notion project. Now all that's left is to \\ndeploy the Slack app so you can use it at any  \\ntime in your workspace. So let's create another \\ndirectory called slack app and move all the  \\ncode there. Then we need to create a docker \\nfile. The docker file is really simple.\\n \\nIt will simply install some additional packages \\nand then run our uvcorn server. So go to Google  \\nCloud and select the same project which \\nyou used to create your Firebase account  \\nand then here under the cloud run server, you \\ncan actually connect your github repository  \\nand completely automate the deployments.\\nWhich is extremely convenient, because anytime  \\nyou push the code into the main branch, it \\nwill be automatically updated in the cloud,  \\nand the changes will be reflected in your \\nSlack bot. So let's select our repository,  \\nclick next, then select the branch, build type \\nyou should set to dockerfile and click save. \\n \\nThen make sure to allow \\nunauthenticated invocations. \\n \\nThe rest of the settings you can leave on \\nthe default and then click create. Click on  \\nedit and deploy new revision and then here just \\nslightly adjust the container port to be 8000. \\nThen go to variables and secrets And add all \\nthe same variables from your env file. \\n \\nAfter that simply click deploy. \\nAwesome, so then on GitHub you'll see  \\nthis action being currently executed. And \\nyou can even check the logs to see when it's  \\ncompleted. After the build is finished, Go back \\nto Cloud Run, click on Slack Bot, and copy your  \\napp URL. After that, go back to your Slack app \\nconfiguration and change your request URL. \\n \\nClick Save Changes again, and now your bot \\nshould be deployed and ready for production  \\nuse. Let's send another message that I have a \\nfeedback about the product. And as you can see,  \\nnow it responds without me having to run any \\ncommands locally. Awesome. So let's test it again. \\nLet's say that I want more personalized elements, \\nadjusting the customer by name and so on.\\n \\nAnd as you can see, it again, asks me more \\nquestions, tries to clarify the requirements  \\nas much as possible. And then it posts this task \\nas a backlog task in Notion for our development  \\nteam. Awesome. So that's it for this \\ntutorial. The code will be in our agency  \\nswarm lab repository.",
    "file_path": "playlist_1\\Building an AI Agent to Automate My Agency Live_rHBM1erNqFM.json",
    "file_size": 15345,
    "last_modified": "2025-04-18 15:34:00",
    "tags": [
     "and",
     "app",
     "building an ai agent to automate my agency live_rhbm1ernqfm",
     "can",
     "create",
     "json",
     "lang:pt",
     "nand",
     "see",
     "simply",
     "slack",
     "test",
     "that",
     "the",
     "then",
     "this",
     "thread",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "016b2f086b4d61a521c1b77db0bac050",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 3,
     "total_chunks": 5,
     "processing_time": 0.053633689880371094
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 3,
    "total_chunks": 5,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Building an AI Agent to Automate My Agency Live_rHBM1erNqFM_Part_5",
    "content": "So if you want to deploy \\na Slack app like this for your own workspace,  \\ncompletely for free, make sure to go there \\nand adjust it for your specific process.\\n \\nSo thank you for watching and \\ndon't forget to subscribe.\",\n    \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\Building an AI Agent to Automate My Agency Live_rHBM1erNqFM.json\",\n    \"tags\": [\n        \"Building an AI Agent to Automate My Agency Live\"\n    ],\n    \"source\": \"https://www.youtube.com/watch?v=rHBM1erNqFM\"\n}",
    "file_path": "playlist_1\\Building an AI Agent to Automate My Agency Live_rHBM1erNqFM.json",
    "file_size": 15345,
    "last_modified": "2025-04-18 15:34:00",
    "tags": [
     "agency",
     "agent",
     "automate",
     "building",
     "building an ai agent to automate my agency live_rhbm1ernqfm",
     "json",
     "lang:pt",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "016b2f086b4d61a521c1b77db0bac050",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 4,
     "total_chunks": 5,
     "processing_time": 0.053633689880371094
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 4,
    "total_chunks": 5,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Introducing Agency Swarm Realtime Voice Interface_cep6dscKWQo_Part_1",
    "content": "{\n    \"section_name\": \"Introducing Agency Swarm Realtime Voice Interface\",\n    \"content\": \"imagine if you could have an eii agent\\nthat could run your entire life for you\\nwhat if you could just say hey Sky\\nwhat's my schedule as like for today\\nyour schedule for today 5:30 a.m. to\\n6:30 a.m. meditation and journaling 6:30\\na.m. to 12:00 p.m. deep work 11:30 a.m.\\nto 12:30 p.m. meeting with Helen\\nElizabeth Wayne arseny and Merlin Ravens\\n2:00 p.m. to 3:30 p.m.\\nworkout okay awesome can you check all\\nof the emails I have unread in my\\nmailbox you have 10 unread emails the\\nlatest ones\\ninclude need more details or want to\\naddress any of these now can you please\\nopen that website that the client\\nmentioned in one of the\\nemails the website has been\\nopen okay cool and can you tell me\\nwhat's on this website on the website\\nyou see an e-commerce store with a\\nvariety of Kitchen products is there\\nanything else you'd like to do yes can\\nyou please tell the project scoper agent\\nto create a project scope for this\\npotential client the project scoper\\nagent has created a detailed project\\nscope for the e-commerce client\\nspecializing in Kitchen products it\\ncovers objectives key deliverables\\nrequirements timeline collaboration and\\nsuccess metrics\\nwould you like to review any specific\\nsection in more detail uh no can you\\njust save this project scope to a local\\nfile please the project scope has been\\nsaved to a local file named projector\\nscope\\nEcommerce kitchen products. txt so\\nthat's how it works I've been saying for\\nmonths now that the way we interact with\\ntechnology is going to change soon and\\ntoday we are introducing agency form\\nvoice in interface which allows you to\\ninteract with your agents in a more\\nnatural way but the best part about this\\nproject is how simple it is to customize\\nyourself so all it takes to add your\\ntools and agents is literally just\\ndropping them into either the tools or\\nthe agency's directory and that's it and\\nfor those who do not know how to create\\ntools or agents themselves we of course\\nalso have the cursor rules file which\\nwill allow you to create all of the\\ntools and agents for you so let's Dive\\nIn\\nokay so first huge shout out to indev\\nDan this project was fored from his PC\\npython realtime API assistant repo\\nhowever with this repo there were a few\\nsignificant challenges specifically it\\nmade it incredibly hard to add tools\\nespecially if you're a beginner all of\\nthe tools in the repo are inside the\\ntools.",
    "file_path": "playlist_1\\Introducing Agency Swarm Realtime Voice Interface_cep6dscKWQo.json",
    "file_size": 15544,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "agency",
     "agents",
     "all",
     "and",
     "api",
     "can",
     "client",
     "could",
     "have",
     "introducing agency swarm realtime voice interface_cep6dsckwqo",
     "json",
     "lang:pt",
     "ntools",
     "project",
     "that",
     "the",
     "this",
     "website",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "684734046ad44dcdb7bd636de753f055",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 6,
     "processing_time": 0.0069997310638427734
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 6,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Introducing Agency Swarm Realtime Voice Interface_cep6dscKWQo_Part_2",
    "content": "P directory and in order for you\\nto add a tool you would have to like\\ncreate and modify code in like three\\ndifferent places because at first you\\nwould have to like create a function\\nthen you would have to create the schema\\nthen you would also have to upload it to\\nyour agent so that's definitely\\nchallenging for not just beginners but\\neven for pros which is why in our repo\\nyou can do this with a consistent B tool\\nclass interface that you can extend with\\nyour own capabilities and then all you\\nneed to do is basically just drop it\\ninto the tools that trory and this\\nassistant will instantly have access to\\nthat tool so as you can see the code is\\nmuch cleaner if you know how to use my\\nframework you know how convenient it is\\nto use penic for tools so the same\\nprinciples apply here additionally it\\nmade it incredibly hard to add agents in\\nfact agents in this repo are not really\\nagents they are just basically tools so\\nas you can see here it has like a tool\\nthat calls another lolm and it has a\\nspecific prom structure and then just\\nReturns the response from this lolm but\\nin ouro again you can just simply drop\\nyour agents into the agency's folder and\\nthen instantly this voice interface will\\nallow you to interact with these agents\\nand it canot only interact you know with\\nthe CEO of your agency so for example if\\nyou drop like an agency here with the\\nCOO agent on top it can still interact\\nwith other sub agents in this agency and\\nlastly you can't use assistance API here\\nwhile of course in Agency for all of the\\nagents are built with assistant so it\\nmeans that you have code interpreter and\\nfile search out of the box so that's\\nbasically what we've done here and now\\nlet me show you how to actually use it\\nhow to add your own agents and tools if\\nyou already have them and then later\\nwe'll also do a step-by-step tutorial on\\nhow you can create new tools and agents\\nwith cursor all right let's dive in so\\nthe first step would be to clone the\\nrepo if you run into any challenges here\\njust ask Char gbt and then open it in\\ncursor after that the next step would be\\nto install the requirements so for this\\nproject to run you need to install UV\\nwhich is a modern package manager I\\nreally like this choice to be honest and\\nyou can install it with just a single\\ncommand so you can either use Mac OS or\\nLinux command so just run this in your\\nterminal and this will install UV after\\nthat you would need to copy the n.\\nsample file so just copy this n.",
    "file_path": "playlist_1\\Introducing Agency Swarm Realtime Voice Interface_cep6dscKWQo.json",
    "file_size": 15544,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "agency",
     "agents",
     "and",
     "api",
     "can",
     "example",
     "have",
     "here",
     "introducing agency swarm realtime voice interface_cep6dsckwqo",
     "json",
     "just",
     "lang:pt",
     "like",
     "that",
     "the",
     "this",
     "tools",
     "tutorial",
     "use",
     "would",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "684734046ad44dcdb7bd636de753f055",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 6,
     "processing_time": 0.008001089096069336
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 6,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Introducing Agency Swarm Realtime Voice Interface_cep6dscKWQo_Part_3",
    "content": "sample\\nfile and here add your own open I key\\nand also rename it into justn so you\\nneed to copy this and rename it into n\\nand then add your API key then you can\\nalso modify personalization and this\\nactually another thing that we modified\\nfrom the PC repo in the PC repo it was\\nhard to modify the instructions for your\\nagent while here you have access to the\\nassistant instructions so you can easily\\nknow add your own information about know\\nwhat you do about yourself and the tasks\\nthat you want this agent to perform and\\nhow Okay after that install Port audio\\nso just simply run this command Brew\\ninstall Port audio in your terminal and\\nfinally just run the UV sync command\\nwhich is like pep install basically in\\nUV like this you can already use this\\ndefault assistant with some of the tools\\nthat don't require authentication\\nhowever if you want to use tools that\\nuse Google cloud apis like for example\\nthe tool to check your calendar or the\\ntool to check your emails and of course\\nyou can also build more tools on top of\\nthis with other Google apis you would\\nhave to get the Google Cloud credentials\\nso in order to do that we first need to\\ncreate a Google Cloud project so go to\\nconsole cloud.google.com\\nand here just select your project if you\\ndon't have a project just create one\\nit's not that hard and after that you\\nwould need to enable two API so first of\\nall you would search for Gmail API in\\nthe search bar here on top and then\\ninitially here you will see an activate\\nbutton or something so just click on\\nthat button and then wait until the API\\nis enabled\\nafter that do the same for the Google\\nCalendar\\nAPI then click manage and here under o\\noff consent screen you would need to\\nconfigure your app so just name it as\\nthe name of your project like for\\nexample voice interface and then when\\ncreating this app so I already have this\\napp created but I think it will go\\nthrough the same process here so just\\nclick save and continue here on add or\\nremove Scopes you would need to add the\\nScopes from the the readme file so here\\njust copy all of these links right here\\nand then add them under manually add\\nScopes just add it like this and then\\nclick add to the table so do this for\\nall of the Scopes I've already done this\\nbefore so I'm not going to do all of\\nthat and then just click save and\\ncontinue again in your test users just\\nadd email addresses of everyone who's\\ngoing to be using this application and\\nthen click save and continue again okay\\nnow what we need to do is just get the\\ncredentials file so go to credentials\\nright here and then just click create\\ncredentials here on top and select all\\noff client ID for the application type\\nselect desktop app name it again as the\\nname of your\\nproject and click\\ncreate awesome so after that click\\ndownload Json and this will download the\\ncredentials. Json file to your local\\nmachine and you would just need to\\nrename it into simply credentials.",
    "file_path": "playlist_1\\Introducing Agency Swarm Realtime Voice Interface_cep6dscKWQo.json",
    "file_size": 15544,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "add",
     "and",
     "api",
     "click",
     "client",
     "google",
     "here",
     "introducing agency swarm realtime voice interface_cep6dsckwqo",
     "json",
     "just",
     "lang:pt",
     "like",
     "need",
     "test",
     "that",
     "the",
     "then",
     "this",
     "would",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "684734046ad44dcdb7bd636de753f055",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 6,
     "processing_time": 0.008001089096069336
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 6,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Introducing Agency Swarm Realtime Voice Interface_cep6dscKWQo_Part_4",
    "content": "Json\\nso like I have right here initially it's\\ngoing to have like a very long name but\\nyou just need to name it credentials.\\nJson and place it into the top level\\ndirectory of voice interface repo so\\nyeah that's basically it for setup this\\nis literally all it takes now you can\\nuse it with the default tools so we've\\nadded some example tools for you that\\nyou can run out of the box and to do\\nthat just simply run the final command\\nwhich is UV run\\nMain hey Sky how are you hello how can I\\nhelp you today awesome so sky is online\\nand yeah feel free to play with this\\neven like this it can be really helpful\\nI'm actually going to be using it as a\\nCOO you can use it for a lot of\\ndifferent purposes actually just by\\nmodifying The Prompt but if you want to\\ntake it a step further what you can do\\nis of course also create your own tools\\nand agencies so if you want to add\\nagencies as I said it's very simple you\\nwill just like drop them into the\\ndirectory so let me show you for example\\nlet me take the agency that I developed\\non the previous video which is the\\ncontent creation agency so let me copy\\nthat and then go back here and just\\npaste it into the agency's file so now\\nas you can see the content creation\\nagency is here but what you need to do\\nis also just change the UTS so you can\\njust select all the code and say change\\nto relative\\nImports and yeah that's the smartest way\\nto use AI ever as you can see I added\\nthree thoughts this is why open I chain\\nthis model for $100 million so now we\\ncan run this again and this voice\\nassistant will have access to this\\nagency so I actually got an error\\nbecause the T package is not installed\\nso I just forgot to install the packages\\nfrom the previous repot so just make\\nsure to copy the requirements.txt file\\nalso put it somewhere in the root\\ndirectory and then just run UV people\\ninstall dasr requirements.",
    "file_path": "playlist_1\\Introducing Agency Swarm Realtime Voice Interface_cep6dscKWQo.json",
    "file_size": 15544,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "and",
     "but",
     "can",
     "example",
     "have",
     "here",
     "into",
     "introducing agency swarm realtime voice interface_cep6dsckwqo",
     "json",
     "just",
     "lang:pt",
     "like",
     "model",
     "ndirectory",
     "nis",
     "run",
     "setup",
     "that",
     "the",
     "this",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "684734046ad44dcdb7bd636de753f055",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 3,
     "total_chunks": 6,
     "processing_time": 0.00900125503540039
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 3,
    "total_chunks": 6,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Introducing Agency Swarm Realtime Voice Interface_cep6dscKWQo_Part_5",
    "content": "txt so this\\nwill install all of the packages from\\nthe requirements then you can run the UV\\nmain command\\nagain hey sky so what's the performance\\non my Channel\\ntoday the performance metrics for your\\nYouTube channel today are as follows one\\n5 AI Trends you must be prepared for by\\n2025 16,21 15 views two why structured\\noutputs by open AI change everything\\n13,000 524 views all right amazing thank\\nyou thank you Sky okay now let me\\nactually show you how to build new\\nagents in Tools in this repo the process\\nis extremely similar to what I have\\nalready showed you in my previous video\\nwhere we built an agency from scratch\\nusing cursor without writing a single\\nline of code here the folder structure\\nis just a bit different but essentially\\nthe process is the same so the first\\nstep will be to open cursor composer\\nwith command shift I and if you're on\\nWindows just replace it with control\\nthen I'm going to ask it to create a new\\ntool that will check all the unread\\nmessages in my slack because as a COO I\\nalso want to you know get a quick\\noverview without having to go through\\nall the messages\\nmyself okay so very simple prompt you\\ncan play with the models I'm going to\\nuse GPT 4 all for this one please create\\na tool that will check all my unre\\nmessages in slack so as you can see it\\nnow adds a tool but here it actually\\nadded it into incorrect folder so this\\ncan happen I mean we're still working on\\nthe cursor rules file for this repo so\\nhopefully by the time you use this it's\\ngoing to be fixed but if this happens\\njust tell it to place it in the correct\\nfolder and the correct folder for this\\nwould be the tools folder inside the SRC\\nvoice assistant so inside tools you\\nwould Place tools that the voice\\nassistant can access directly and inside\\nagencies you would place any tools that\\nthe sub agents can access on its behalf\\nso let me now just tell cursor to place\\nthis tool under Tools in SRC Voice\\nAssistant okay so as you can see now the\\npath is correct SRC Voice Assistant\\ntools check andr messages so let's\\naccept the changes let's go now check\\nour new tool so as you can see it\\nrequires also slack SDK so if you need\\nto install any additional package\\nyou will simply do this with UV by\\nrunning UV add and then package\\nname Okay cool so let's see if these\\nquickly lines\\ndisappear and now the package is\\ninstalled so let's now run this tool to\\ntest it I previously already added this\\nslackbot token into the N file but again\\nif you don't know how to do this simply\\nask cursor it provides some pretty\\naccurate instructions but it's going to\\ndepend on the API that you want to use\\nokay now let me run this file and see if\\nit works so as you can see it says\\nChannel not found because for some\\nreason it decided to use like a channel\\nID in the parameters of the tool so I'm\\nactually just going to tell it to check\\nall channels and output and messages at\\na\\ntime all right so this looks better now\\nlet's run again so again the process is\\nvery simple you just tell cursor what to\\nmodify and then you run this again and\\ntest and then if there are any errors\\njust add the error message back you can\\nselect it like this and then just press\\ncommand I so this will add the error\\nmessage into the composer and then you\\ncan just tell it to fix this\\nthing okay so the arrow is fixed but now\\nas you can see it's checking like all of\\nthe channels so let me just tell it that\\nI want to only check channels which I am\\na member\\nof right awesome so there is actually a\\nway to do this as you can see sometimes\\nyou just need to hint these models on\\nwhat EX exactly you want because this is\\na much simpler way than checking all\\nchannels at a\\ntime okay cool so now it works total\\nunder messages is zero because I had\\nsome coffee this morning and after this\\nyou don't have to run any other commands\\nall you need to do is just run UV run\\nMain and instantly the agent will have\\naccess to your tools hey sky can you\\nplease check the latest messages and\\nslack from me here are the latest\\nmessages from the",
    "file_path": "playlist_1\\Introducing Agency Swarm Realtime Voice Interface_cep6dscKWQo.json",
    "file_size": 15544,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "all",
     "and",
     "api",
     "can",
     "check",
     "cursor",
     "introducing agency swarm realtime voice interface_cep6dsckwqo",
     "json",
     "just",
     "lang:pt",
     "now",
     "okay",
     "run",
     "see",
     "the",
     "then",
     "this",
     "tools",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "684734046ad44dcdb7bd636de753f055",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 4,
     "total_chunks": 6,
     "processing_time": 0.00900125503540039
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 4,
    "total_chunks": 6,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Introducing Agency Swarm Realtime Voice Interface_cep6dscKWQo_Part_6",
    "content": "artemy test slack\\nChannel a few moments later all right so\\nthat's basically it this is how you can\\ncreate your agents and tools again\\nwithout writing a single line of code\\nthe process for creating agents in the\\nstreer is the same just adjust the\\nprompt and make sure it places it into\\nthe correct folder so in conclusion\\nafter working with this realtime API I\\nfound it extremely similar to assistants\\nhonestly I'm not sure why open I decided\\nto create like a whole different API for\\nthis because the only difference between\\nreal time API and assistance is that\\nassistance we have threads and in real\\ntime we have conversations and obviously\\nyou can store the state of your agent on\\nopeni site and you can't use the file\\nsearch and code interpreter so I'm\\nreally hopeful that in the future openi\\nwill bring this API directly in\\nassistance and this will streamline the\\nprocess for us even further so when this\\nhappens we'll probably add a new method\\nin agency's form something like demo\\nVoice or demo real time and this will\\nallow you to instantly run your\\nassistants using voice and interact with\\nthem in a more more natural way so yeah\\nthat's it for this video let us know in\\nthe comments what you're building and\\ndon't forget to subscribe\", \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\Introducing Agency Swarm Realtime Voice Interface_cep6dscKWQo.json\", \"tags\": [ \"Introducing Agency Swarm Realtime Voice Interface\" ], \"source\": \"https://www.youtube.com/watch?v=cep6dscKWQo\" }",
    "file_path": "playlist_1\\Introducing Agency Swarm Realtime Voice Interface_cep6dscKWQo.json",
    "file_size": 15544,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "agency",
     "agents",
     "and",
     "api",
     "can",
     "code",
     "introducing agency swarm realtime voice interface_cep6dsckwqo",
     "json",
     "lang:pt",
     "nthat",
     "nthe",
     "realtime",
     "sure",
     "swarm",
     "test",
     "the",
     "this",
     "voice",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "684734046ad44dcdb7bd636de753f055",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 5,
     "total_chunks": 6,
     "processing_time": 0.010000944137573242
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 5,
    "total_chunks": 6,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Deploy AI Agents in Minutes Step-by-Step Guide with Free Template_53_e3lmk6Mo_Part_1",
    "content": "{\n    \"section_name\": \"Deploy AI Agents in Minutes Step-by-Step Guide with Free Template\",\n    \"content\": \"So, you've built a few agents, they can perform \\ncertain tasks, but now you’re wondering, how do I  \\nactually, allow my clients to use them, right?\\nWhat can I do to integrate these agents seamlessly  \\ninto my clients business?\\nAnd the answer is always  \\nyou need to deploy them. \\nYour agents must not only be  \\nreliable in terms of their performance, \\nbut also in terms of availability. \\n \\nEven if you had the smartest employee in the \\nworld who could do anything, if they took an  \\nhour to respond to each message, they wouldn't \\nbe so useful. The same goes for AI agents.\\n \\nSo, this video is divided into two parts. In the \\nfirst part, we'll explore the theory of AI agent  \\ndeployment, covering all the options available to \\nyou. Then, in the second part, we'll walk through  \\na practical example, deploying an AI agent in \\nproduction using the exact template we use in our  \\nAI agency for the cloud deployment option. \\nLet’s dive in.\\n \\nOkay before we get started, quickly about \\nme, my name is Arsenii, and I built an AI  \\nagent framework that allows you to create \\nAI powered agencies that can serve clients,  \\ncalled Agency-Swarm. By the way, I also recently \\ndecided to rename my channel to my full name.\\n \\nNow let’s go over the fundamentals. First \\nof all, what is AI agent deployment?\\n \\nAI Agent Deployment is the process of making your \\nAI agents accessible to your users. Essentially,  \\nmaking them available whenever \\nyou or your clients need them.\\n \\nMakes sense, but let’s unpack \\nthis with a couple of examples.\\n \\nIf you are running your agent locally on your \\ncomputer, is it considered deployed or no? \\n \\nMany people would say no, \\nbut it actually can be.\\n \\nLike for example last week we released a new \\nrepo agency-voice-interface that allows you  \\nto interact with your agents in real time. \\nCurrently it does not support cloud deployment,  \\nbut the thing is - it doesn't have \\nto. Because the primary use case for  \\nthat repo is personal assistants.\\nSo, most likely it's not going to be  \\nused by multiple employees at a time. It is \\ngoing to be used only by a single person on  \\ntheir own computer. In this situation, \\nit is considered deployed because it is  \\nalready usable in its production environment. \\nNow let's take a look at the second example. \\n \\nSay you have an agent that you are running in the \\ncloud via API. Is this agent deployed or not?\\n \\nWell again, it depends.\\nIf this agent is supposed to be  \\nused primarily on backends, so if the users are \\ngoing to be interacting with this agent via API,  \\nthen it is considered deployed. However, \\nif this agent is primarily intended for  \\nyour team who is not very technical and they \\ndon't even know how to make an API request,  \\nthan it is still not deployed.\\nSo the point is that the agent is  \\ndeployed only when it is accessible and \\nusable for its intended audience.\\n \\nOnly when the target audience can interact with \\nthis agent seamlessly without any barriers,  \\ncan we truly say that it has \\nbeen successfully deployed.\\n \\nNow, why does ai agent \\ndeployment matter so much?\\n \\nWell, the first reason is because user \\nexperience is key in making AI agents useful.\\n \\nI often say that integrations are \\nmore important than functionality.\\n \\nIf it takes an hour to get a response from the \\nagent because it's hard to access or requires a  \\ncomplex setup, the amount of value your users can \\nget from this agent will be severely limited.\\n \\nSecondly, using a suboptimal \\ndeployment approach can lead to  \\nsignificant issues further down the line. \\nThere are a lot of factors that you need to  \\nconsider all factors like data privacy, costs, \\nscalability, and ease of management together,  \\nbecause getting even one of these wrong could \\npotentially derail your entire project.",
    "file_path": "playlist_1\\Deploy AI Agents in Minutes Step-by-Step Guide with Free Template_53_e3lmk6Mo.json",
    "file_size": 17928,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "agent",
     "agents",
     "api",
     "are",
     "can",
     "deploy ai agents in minutes step-by-step guide with free template_53_e3lmk6mo",
     "deployed",
     "example",
     "guide",
     "json",
     "lang:pt",
     "not",
     "that",
     "the",
     "they",
     "this",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "4bb324e657b6eba61df8d1d94418cefb",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 5,
     "processing_time": 0.06397056579589844
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 5,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Deploy AI Agents in Minutes Step-by-Step Guide with Free Template_53_e3lmk6Mo_Part_2",
    "content": "\\n \\nFor instance, accidentally sharing client \\ndata with third parties when your client  \\nhas strict data policies in place could \\nlead to serious legal issues - something  \\nyou definitely want to avoid.\\nSo typically there are three primary challenges  \\nthat developers face when deploying AI agents. \\nThe first one is not having enough technical  \\nexperience. Simply not understanding the \\ntechnologies involved in the process.\\n \\nThe second, and perhaps more dangerous, \\nis not knowing your options. \\n \\nBecause even if you don't have enough technical \\nexperience, you can always ask ChatGPT. But if  \\nyou simply don't know your options, then you \\ndon't even know which questions to ask.\\n \\nAnd lastly, not understanding the tradeoffs \\nin the context of your project.\\n \\nThere is rarely one choice fits all, and \\nultimately, the best deployment option will  \\nheavily depend on the context of your own project. \\nSo, you need to clearly understand the tradeoffs  \\nto select the most optimal one.\\nAlright, so now let's go ahead and  \\nreview all of these options in detail so you \\ncan avoid all of these costly mistakes.\\n \\nThe first deployment option is local \\ndeployment. This involves running your  \\nagent locally or setting up your own server. \\nThe pros of this approach is that you can make  \\nyour system fully private, where no data ever \\nleaves your own private network. Additionally,  \\nyou have complete control over the environment.\\nThe drawbacks of this approach is that the system  \\nneeds to be kept online constantly, and scaling \\nthis system is almost impossible. As your  \\nuser base grows, you'll need to always buy more \\nhardware, reconfigure and manage it yourself.\\n \\nI generally recommend local deployment only \\nwhen clients are using agents locally like with  \\npersonal assistants or for large enterprises \\nwith enough existing hardware in place.\\n \\nThe second option is cloud deployment.\\nThis option involves deploying your  \\nagents in a container in the cloud.\\nA container is like a box that packages your code,  \\nlibraries, and settings together. You can move it \\nbetween different provides without reconfiguring  \\neverything from scratch. It helps you to \\navoid the \\\"it works on my machine\\\" problem.\\n \\nThe primary advantage of this option is balance \\nbetween scalability and flexibility. You have  \\nenough control over the environment and \\nyou can easily scale it with the help of  \\nservices like Google Cloud Run, Amazon ECS, or \\nRailway, which we will use it at the end.\\n \\nThe cons of this option is that you \\nhave ongoing subscription fees.\\n \\nAlthough cloud deployment is quite \\nrobust, it really shines for large  \\nscale external applications where you \\nmight have thousands of active users.\\n \\nWe’ll go over some project \\nexamples later as well.\\n \\nThe next option is serverless deployment. \\nWith serverless, instead of deploying agents in a  \\none big box, you have multiple smaller boxes. Each \\nbox can represent a specific service, like a tool,  \\nan agent, or even an entire agency.\\nThe main advantage of serverless  \\nis its elasticity. Each function scales \\nindependently based on workload. So whenever  \\nyour tools or agents are not being utilized, \\nyou are not paying for anything. The costs for  \\nserverless are also lower than for cloud \\nbased. For example, a 1000 executions,  \\non average would only cost you a few cents.\\nHowever, it does have some limitations. First,  \\nyou have restricted execution time, typically \\nup to a few minutes, and secondly you have  \\nless control over the environment. \\nI recommend this option for internal  \\nprojects with a smaller user base.\\nThe next option is SaaS deployment. This  \\nmeans deploying your agents on a SaaS \\nplatform for building AI agents. \\n \\nThe main advantage of SaaS is zero infrastructure \\nmanagement.",
    "file_path": "playlist_1\\Deploy AI Agents in Minutes Step-by-Step Guide with Free Template_53_e3lmk6Mo.json",
    "file_size": 17928,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "agents",
     "and",
     "are",
     "can",
     "cloud",
     "deploy ai agents in minutes step-by-step guide with free template_53_e3lmk6mo",
     "deployment",
     "have",
     "json",
     "lang:pt",
     "not",
     "nthe",
     "nyou",
     "option",
     "the",
     "this",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "4bb324e657b6eba61df8d1d94418cefb",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 5,
     "processing_time": 0.06497907638549805
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 5,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Deploy AI Agents in Minutes Step-by-Step Guide with Free Template_53_e3lmk6Mo_Part_3",
    "content": "You don't even need to think about  \\nscaling servers or managing deployments, so \\nthere's less technical experience required.\\n \\nBut of course it does come at a cost. \\nNot only financial, because most SaaS  \\nplatfroms overcharge you 10s of times per \\ntoken, but also in terms of flexibility.\\n \\nI personally receive partnership requests from \\nthese platforms every week and by now I have  \\ntested over 20 of them. Still, I couldn't find \\nany SaaS product that we'd use at our AI agency,  \\nbecause none of them provide enough access to the \\nunderlying agent configuration, and often don’t  \\neven let you write your prompts yourself.\\nSo I recommend using SaaS only option for  \\nvery simple projects, or MVPs.\\nAnd the final option is hybrid.\\n \\nThis is a new emerging option that \\nwe discovered at our agency. \\n \\nYou see, often, it's not the agents but \\nthe tools that need complex setup. So,  \\nyou can mix and match different options we talked \\nabout earlier. For instance, you could run agents  \\nlocally but put tools in a container, or deploy \\nagents in a cloud container while keeping tools  \\nserverless. Or keep your agents on SaaS, while \\ntools in the cloud. This approach lets you  \\nbalance the trade-offs between each deployment \\noption to truly find the most optimal one. \\n \\nNow let’s go over some common project \\nexamples, and then select the best  \\ndeployment option accordingly for each, \\nso you can practice your understanding.\\n \\nFirst, imagine are working with \\nan enterprise client who wants to  \\nautomate their sales process by generating \\nmeeting summaries, performing lead research,  \\nand then combining all of this information \\ninto a well crafted email. However, they  \\nhave strict data privacy concerns, so none of this \\ninformation can leave their internal systems.\\n \\nIn this case, you'd typically deploy on-premise. \\nHowever, many enterprises use Google Cloud or AWS,  \\nso the cloud deployment will also work, \\nif you ensure that their data never leaves  \\ntheir cloud environment. In case if they can’t \\nuse OpenAI, I suggest going with Azure OpenAI,  \\nwhich ensures your data is not \\neven shared with OpenAI itself.\\n \\nIf Now, what if you are building an external \\nSaaS product, like a fitness coach to help  \\npeople create personalized workout plans. In \\nthis case you might choose cloud deployment. \\nThis option allows you to tailor your environment \\nto your own unique needs and scale it to virtually  \\nany number of users. Unlike serverless, \\ncloud deployment also supports streaming,  \\nwhich is one of the key features for user \\nexperience in external applications.\\n \\nNow let’s say you are working on an internal \\nproject manager agent that onboards new clients  \\nand can handle common inquiries in your shared \\nslack channel to help save human employees time. \\nIn this case, I would recommend hybrid or \\nserverless. Since it’s an internal project,  \\nmost likely it won’t be used at all \\ntimes, so to adapt to variable work loads,  \\nyou’d typically want to deploy the agents in \\na serverless function, or only the tools and  \\nkeep the agents on a SaaS platform. \\nAs this is the most common project type  \\nthat we receive in our AI agency, always go with \\nhybrid option, except when our clients have super  \\nstrict data privacy concerns. So unless we are \\nworking with a very large enterprise client, we  \\ndeploy tools in a container and agents on our SaaS \\nplatform, which gives us a perfect balance between  \\nflexibility, and control. We have a playbook and \\nan exclusive template for this in our community  \\nso check it out if you are interested.\\nIf you prefer not to use SaaS at all,  \\nthan for most projects I'd recommend deploying \\nagents in a container using a modern service like  \\nRailway.",
    "file_path": "playlist_1\\Deploy AI Agents in Minutes Step-by-Step Guide with Free Template_53_e3lmk6Mo.json",
    "file_size": 17928,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "agents",
     "and",
     "are",
     "can",
     "client",
     "cloud",
     "deploy ai agents in minutes step-by-step guide with free template_53_e3lmk6mo",
     "json",
     "lang:pt",
     "option",
     "our",
     "saas",
     "that",
     "the",
     "this",
     "tools",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "4bb324e657b6eba61df8d1d94418cefb",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 5,
     "processing_time": 0.06497907638549805
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 5,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Deploy AI Agents in Minutes Step-by-Step Guide with Free Template_53_e3lmk6Mo_Part_4",
    "content": "Although it is a service for container \\ndeployment, it also provides you with serverless  \\noptions and simplified management. All you \\nneed to do is literally just hit a button,  \\nand then Railway will automatically manage and \\ndeploy everything for you. Any time you push  \\nany new code to your repo, your deployment \\nwill be automatically updated as well.\\n \\nThe template for this will be in the description, \\ncompletely for free, so now let’s go ahead and  \\nlet me now show you how to actually use it.\\nSo, here’s the template we use at our agency to  \\ndeploy agents in just a few clicks. The \\nsetup is really simple in this repo.\\n \\nThe prerequisites for this repo are simply having \\nPython installed. Docker is optional if you want  \\nto test locally, although it's not necessary.\\nFor this deployment template, you’ll need to have  \\nalready created and fully tested your agency \\nfor a specific use case. If you haven’t made  \\nagents with Agency Swarm before, check out my \\nprevious video on creating agents using Cursor  \\nwithout writing any code.\\nAfter you have your agency,  \\nthe next step is to simply click \\\"Use this \\ntemplate.\\\" Click \\\"Create a new repository,\\\"  \\nname your repository, and then click \\\"Create.\\\"\\nNow that the repo is cloned, let’s copy the link  \\nand go to GitHub Desktop. In GitHub Desktop, \\nclick \\\"Clone repo\\\" and insert your URL.\\n \\nNext, open your code editor. I’ll be using \\nCursor. Open the new folder, and as I mentioned,  \\nthe setup is simple. Just add your agency inside \\nthe `src` directory. I’ll quickly copy my content  \\nagency that I created in the Cursor video.\\nI’ll copy the entire agency folder and paste  \\nit here. Then, you can remove the example agency \\nby moving it to trash. Replace the input inside  \\n`main.py` by changing `example_agency` to \\nthe name of your agency folder. For me,  \\nit’s `content_creation_agency`. \\nEnsure that the `agency.py` file  \\nhas your agency variable exported.\\nAlso, don’t forget to change it to  \\nrelative imports by adding dots for all \\nyour agent imports inside `agency.py`.\\n \\nNow, there are just a few more steps left. First, \\ninstall the packages. Press Command+Shift+P (or  \\nControl+Shift+P on Windows), create a virtual \\nenvironment, select your Python, and click OK.\\n \\nAdditionally, don’t forget to copy \\nthe requirements from your agency’s  \\n`requirements.txt` into the `requirements.txt` \\nfile inside the `src` folder of the repo.\\n \\nLet’s wait until the squiggly \\nlines disappear, which means the  \\npackages are successfully installed.\\nAfter that, copy the `.env.example` file  \\nand rename it to `.env`. In `.env`, \\nyou’ll need to add two variables:  \\nyour OpenAI API key and an app token. Generate \\nany random password for the app token and  \\ninsert it as your API authentication token.\\nThat’s it for the setup! The last step before  \\nwe deploy is to test it locally. Open your \\nterminal, navigate to the `src` directory,  \\nand run `python main.py`.\\nWe get a URL with `:8000`,  \\nso open this in your browser and add `/demogrado` \\nto the end of the URL. As you can see, we now have  \\nthis agency interface with Gradio running on our \\nserver. Say \\\"Hi\\\" or something similar to generate  \\nthe `settings.json` file. If the agent responds, \\nit means your agency is functioning properly. Now  \\nwe have this `settings.json` file inside `src`, \\nwhich is important. Make sure to add this file  \\nto your repository; otherwise, your agents will \\nbe recreated every time users use your API.\\n \\nAlright, awesome! Now we’re ready to \\ndeploy. Hit \\\"Commit\\\" for all these changes,  \\nadd a commit message like \\\"Added content creation \\nagency,\\\" and then click \\\"Commit and Push.\\\"\\n \\nNow let’s deploy it on Railway. Go to \\nRailway.app and, on your dashboard,  \\ncreate a new project.",
    "file_path": "playlist_1\\Deploy AI Agents in Minutes Step-by-Step Guide with Free Template_53_e3lmk6Mo.json",
    "file_size": 17928,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "agency",
     "and",
     "api",
     "click",
     "copy",
     "deploy ai agents in minutes step-by-step guide with free template_53_e3lmk6mo",
     "example",
     "file",
     "inside",
     "json",
     "just",
     "lang:pt",
     "now",
     "nthe",
     "repo",
     "setup",
     "test",
     "the",
     "this",
     "use",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "4bb324e657b6eba61df8d1d94418cefb",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 3,
     "total_chunks": 5,
     "processing_time": 0.06597757339477539
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 3,
    "total_chunks": 5,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Deploy AI Agents in Minutes Step-by-Step Guide with Free Template_53_e3lmk6Mo_Part_5",
    "content": "Select \\\"Deploy from \\nGitHub repo,\\\" choose the repo you just created,  \\nand click \\\"Deploy Now.\\\" That’s all it takes.\\nThe final step is to generate your URL and add  \\nyour environment variables. Go to the \\\"Variables\\\" \\ntab, and for each variable you added before,  \\ncreate a new variable name and add your value.\\nHit \\\"Deploy\\\" again to apply the changes,  \\nthen wait until the deployment is complete. \\nMeanwhile, get your URL by going to \\\"Settings\\\"  \\nand, under \\\"Public Networking,\\\" hit \\n\\\"Generate Domain.\\\" If the port wasn’t  \\ndetected automatically, set it to `8000`.\\nNow our deployment is successful. Navigate to  \\nthis link and add `/demogrado` at the end. You’ll \\nsee the Gradio interface, but now you don’t have  \\nto run any local commands. This Gradio interface \\nwith your agency will always be online.\\n \\nThe main feature of this deployment template \\nisn’t the Gradio interface, but the API. There’s  \\nan API endpoint at `/api/agency`. It won’t \\nwork from the browser, but you can test it  \\nwith Linux or PowerShell. With this API, you \\ncan connect your agents to other systems.\\n \\nFor example, you could follow our tutorial \\non integrating this agency in Slack,  \\nor connect it to a tool like Zapier to integrate \\nwith other apps. For instance, you could connect  \\nit to Google Chat and, when there’s \\na new message in Google Chat,  \\nrun this API through Zapier to send \\nthe response back to Google Chat.\\n \\nThat’s it for this video. Thanks for \\nwatching, and don’t forget to subscribe!\",\n    \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\Deploy AI Agents in Minutes Step-by-Step Guide with Free Template_53_e3lmk6Mo.json\",\n    \"tags\": [\n        \"Deploy AI Agents in Minutes Step-by-Step Guide with Free Template\"\n    ],\n    \"source\": \"https://www.youtube.com/watch?v=53_e3lmk6Mo\"\n}",
    "file_path": "playlist_1\\Deploy AI Agents in Minutes Step-by-Step Guide with Free Template_53_e3lmk6Mo.json",
    "file_size": 17928,
    "last_modified": "2025-04-18 15:33:59",
    "tags": [
     "add",
     "agency",
     "and",
     "api",
     "but",
     "deploy",
     "deploy ai agents in minutes step-by-step guide with free template_53_e3lmk6mo",
     "deployment",
     "gradio",
     "guide",
     "interface",
     "json",
     "lang:pt",
     "nthe",
     "nwith",
     "step",
     "test",
     "the",
     "this",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "4bb324e657b6eba61df8d1d94418cefb",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 4,
     "total_chunks": 5,
     "processing_time": 0.06597757339477539
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 4,
    "total_chunks": 5,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How To Add ANY Production-Ready API To Your Custom GPT_voJuGHTfO_g_Part_1",
    "content": "{ \"section_name\": \"How To Add ANY Production-Ready API To Your Custom GPT\", \"content\": \"in this video I'll demonstrate how to\\nintegrate a production ready third party\\nAPI into your custom GPT we'll avoid\\nrepet or any other playground\\nenvironment instead we'll focus on\\ndeploying a real serverless API using\\nFirebase functions this ensures that you\\ncan scale to virtually any number of\\nrequests without ever worrying about\\nyour server shutting down and if you'd\\nlike to adapt this code for your own\\ncustom tools or logic I will show you\\nexactly how to do that at the end of the\\nvideo let's begin\\nin this tutorial we'll connect Google\\nanalytics data API to our custom GPT to\\nanswer questions about my website's\\ntraffic this is a very common project\\nthat I often receive as an AI developer\\ndatadriven decisions are the key to\\nsuccess in 21st century but the problem\\nis that most of these apis are not\\nstraightforward to work with first you\\nhave to create a correct cury then you\\nhave to know how to receive the results\\nand third you have to know how to\\ninterpret them before you can make use\\nof any of this data and GPT models\\nstreamline this entire process like\\nnever before instead of spending hours\\nto analyze your data you can simply ask\\na question and get an instant response\\nsaving you or your client hours of time\\nto get started create a new repo on\\nGitHub and clone it then open it in your\\nterminal and install the Firebase CLI\\nyou can do this with npm by running npm\\nDG install Firebase tools if you don't\\nhave npm installed then guess what ask\\nChad\\nnext run Firebase init functions command\\nto initialize Firebase functions in your\\ncurrent folder Firebase CLI manages all\\nof the deployment aspects for you so you\\ncan focus solely on coding additionally\\nthey provide a generous free usage quota\\nthat in my three years of working with\\nthem I still haven't been able to exceed\\nI do hope that this will change soon\\nthough when prompted in the terminal\\nselect create new project and enter your\\nproject ID and project name if needed\\nwait until Google Cloud resources are\\ncreated and then when asked about about\\nwhich language you would like to use to\\nwrite your functions select Chinese just\\nkidding select python select yes to\\ninstall the dependencies and now you\\nshould see a functions folder in your\\nroot directory which means that we are\\nready to start coding in\\nrequirements.txt file add two new\\ndependencies the first one is the\\ninstructor Library which allows us to\\nDefine openi functions as identic\\nschemas and the second one is Google\\nanalytics data package the second\\npackage is going to differ based on your\\nown requirements you can chat with GPT 4\\nto find out which one you need depending\\non the API that you're going to use Now\\nactivate your virtual environment and\\nrun pip install dasr requirements.txt\\ncommand open the main.py file uncomment\\nthe example function and rename it into\\nsomething more descriptive since we are\\ndeveloping an internal API which means\\nit is not intended to be used by anyone\\noutside of your organization we can use\\na simple hardcoded token authentication\\ncreating a public app that uses o off\\nand manages refresh and access tokens\\nwith custom gpts involves more\\ncomplexity so if you're interested in\\nlearning about how to allow anyone to\\nconnect their accounts to your app on\\nGPT store let me know in the comments\\nnevertheless I believe that internal\\napplications hold even greater potential\\ncompared to those on the GPT store and I\\nwill explain exactly why at the end of\\nthis video now we will add a simple DB\\ntoken Global variable above this\\nfunction to use for authentication which\\nyou can generate by asking chat GPT to\\ngenerate a random token make sure not to\\npublicly Commit This repo or use an\\nenvironment variable instead to prevent\\nyour token from being exposed now to\\ncheck authentication we will simply\\nretrieve the token from the\\nauthorization header and then compare it\\nwith the database token that we have\\njust defined if they don't",
    "file_path": "playlist_1\\How To Add ANY Production-Ready API To Your Custom GPT_voJuGHTfO_g.json",
    "file_size": 14303,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "about",
     "and",
     "api",
     "are",
     "can",
     "client",
     "database",
     "example",
     "firebase",
     "functions",
     "gpt",
     "how",
     "how to add any production-ready api to your custom gpt_vojughtfo_g",
     "json",
     "lang:pt",
     "server",
     "that",
     "the",
     "then",
     "this",
     "tutorial",
     "use",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "4ca90cfb330e2532129a73fff1471f46",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 5,
     "processing_time": 0.05898785591125488
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 5,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How To Add ANY Production-Ready API To Your Custom GPT_voJuGHTfO_g_Part_2",
    "content": "match we will\\nreturn a 401 response to initialize the\\nGoogle analytics client import the beta\\nanalytics data client and then use the\\nfrom service account file function I\\nknow that working with Google apis can\\nbe really confusing at first but luckily\\nthe general process is the same for\\nalmost all of them first you have to go\\nto the Google Cloud console and then\\nselect your project then you have to\\nfind the API that you want to connect\\nout of hundreds of options by the way\\nthen you have to enable this API then\\nclick on manage and get your service\\naccount Key by clicking on create\\ncredentials under the credentials tab\\nenter your service account name and then\\nclick done click on this service account\\ngo to keys and click add key click\\ncreate new key and then choose Json and\\nclick create after that go back to your\\nproject folder and drop this key into\\nyour fun functions directory again\\nplease make sure not to publicly commit\\nthis key on GitHub because I don't want\\nto be implicated if someone hacks your\\norganization on gcp then add the path to\\nyour service key into the from service\\naccount file function after that just\\none more step is required before your\\nservice account can access yours or your\\nclient's data through the API which is\\nadding it to the user to the account\\nitself since we are using Google\\nanalytics I'm going to open\\nanalytics.google.com and select the\\naccount that I want to analyze then I'm\\ngoing to click on admin on the bottom\\nleft corner and click on account access\\nmanagement after that I'm going to click\\non add user under the plus icon and\\nenter my service account email address\\nfrom the Google Cloud console which\\ntypically starts with your service\\naccount name and ends with I AMG\\nservice.com this is the tricky part\\nbecause the Curious will be performed by\\nyour service account not yourself so you\\nhave to make sure that it also has the\\nnecessary permissions for our use case\\nthe analyst roll should be more than\\nenough you can also add your service\\naccount to as many Google apis as needed\\nnext go back to the admin on analytics\\nconsole copy the property ID from the\\nproperty details and insert it into our\\nCloud function as a variable in this\\nexample we will analyze just one\\nproperty but you can use multiple\\nproperties if needed and allow GPT to\\ndecide which one to use this will allow\\nyou to analyze data across multiple\\nwebsites or streams the next step is to\\ngo ahead and Define our openi function\\nschema just like in the last tutorial\\nwe'll do this with the instructor\\nlibrary because it is a lot more\\nconvenient then Json we'll need a few\\nmodels starting with the main one G4\\ncury params model I will not go too much\\ninto the details here because the schema\\nwill be different for each application\\nor API endpoint that you create instead\\nI will show you how to add a custom\\nschema for your own purposes at the end\\nof this video basically any dock strings\\nor parameter descriptions will be passed\\nto your custom GPT by using the\\ninstructor Library which it will then\\nuse to decide how to call your function\\ntherefore you should provide clear\\nexplanations of each functions purpose\\nin the dock string and the role of each\\nparameter in the field description other\\nmodels in this schema like Dimension\\nschema metric schema and date range\\nschema Define the types for some of the\\nproperties in my main schema for example\\ndate ranges is a list of date range\\nschemas because there can be multiple in\\nthis API check out the GitHub repoint\\ndescription for more details but the\\nmost important part in this file is\\nbelow the if name equals main statement\\nthis piece of code converts our function\\ndefinitions into the open API schema\\nthat GP Builder expects after defining\\nyour functions you can simply run this\\nfile to get your open API schema printed\\nin the",
    "file_path": "playlist_1\\How To Add ANY Production-Ready API To Your Custom GPT_voJuGHTfO_g.json",
    "file_size": 14303,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "account",
     "and",
     "api",
     "can",
     "click",
     "client",
     "google",
     "how to add any production-ready api to your custom gpt_vojughtfo_g",
     "json",
     "key",
     "lang:pt",
     "model",
     "schema",
     "service",
     "that",
     "the",
     "then",
     "this",
     "will",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "4ca90cfb330e2532129a73fff1471f46",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 5,
     "processing_time": 0.05898785591125488
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 5,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How To Add ANY Production-Ready API To Your Custom GPT_voJuGHTfO_g_Part_3",
    "content": "terminal but for now let's finish\\nthe main logic in our main endpoint you\\ncan get your data from the request by\\nusing request.get Json method we'll then\\nunpack it into our data model and set it\\nas a variable another great benefit of\\nusing an instructor library is that if\\nthe request parameters passed by your\\nGPT do not Feit your schema which often\\nhappens you will receive an error we can\\nthen catch this error with the accept\\nstatement and return it back back to GPT\\nallowing it to correct itself on the\\nnext request if needed but if the data\\nis good and it passes validation we can\\nproceed to constructing a request body\\nfor the Google analytics data API this\\nentails unpacking all the parameters\\ninto Google analytics classes and then\\ncalling the Run report and point itself\\nthe final step is to Simply return the\\ndata from the report as a string we are\\nnow ready to deploy our function to do\\nthis simply run Firebase deploy D- only\\nfunctions command and wait until the\\ndeployment is complete that's it your\\nfirst endpoint is now live and it can\\nscale to virtually millions of users in\\nproduction you should also see your\\nendpoint URL at the very bottom copy\\nthis URL and go back to the schema.",
    "file_path": "playlist_1\\How To Add ANY Production-Ready API To Your Custom GPT_voJuGHTfO_g.json",
    "file_size": 14303,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "and",
     "api",
     "back",
     "but",
     "can",
     "data",
     "endpoint",
     "get",
     "how to add any production-ready api to your custom gpt_vojughtfo_g",
     "json",
     "lang:pt",
     "main",
     "model",
     "now",
     "nthe",
     "our",
     "request",
     "the",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "4ca90cfb330e2532129a73fff1471f46",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 5,
     "processing_time": 0.05898785591125488
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 5,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How To Add ANY Production-Ready API To Your Custom GPT_voJuGHTfO_g_Part_4",
    "content": "py\\nfile then replace it under service in\\nyour schema now run the schema file from\\nthe terminal again copy the output and\\nlet's jump into the GPT Builder to test\\neverything out I'm going to name my GPT\\nj4 data analyst in instructions I will\\ntell it to curate the provided endpoint\\nand interpret the data for the user then\\nI'm going to hit add and insert our\\nschema the last step is to add\\nauthentication which you can do by\\nclicking the edit button and then\\nselecting the API key type paste your DB\\ntoken into the API key field select the\\nbearer off type and hit save again let\\nme know in the comments if you'd like me\\nto explore a more complex or off option\\nfor public applications we are now ready\\nto test the first question I'm going to\\nask my GPT is how many visitors were on\\nmy website this week as you can see the\\nmodel immediately curies the endpoint\\nand after allowing it to submit the\\nrequest it now gets the data and\\ninterprets it for us I had a few active\\nusers this week most likely from YouTube\\nhopefully we can increase this number\\nsoon next I'm going to ask the primary\\nlocation of my website visitors for the\\nyear 2023 the main location appears to\\nbe United States which I'm not surprised\\nabout but this is already an extremely\\nvaluable insight and finally I'll ask\\nhow much time the users are spending on\\naverage on my site sometimes the model\\nmight not get the first request right\\nbut since we're passing back the arrow\\nmessage it immediately corrects itself\\nand then tells us that the engagement\\nrate is moderate honestly I have no idea\\nwhere to find this information on Google\\nanalytics myself so this is already\\nextremely useful I'm going to save this\\nGPT to use privately in the future if\\nyou want to share this GPT with your own\\norganization or clients enter privacy\\npolicy URL it can be any random link or\\nyou can generate it with chpt and host\\nit on a not taken app like notion and\\nthen click publish to only people with\\nthe link and share it now as I promised\\nbefore I'm going to quickly guide you\\nand show you how to add your own custom\\nlogic and create more endpoints for your\\ncustom GPT for example you can make an\\naction to shorten URLs you can create a\\nweb scraper or you can connect to any\\ndatabase or a CRM system the\\npossibilities here are endless the first\\nstep to do so would be to create a new\\nfunction inside the main.py file and\\nname it accordingly for example I going\\nto do a simple calculator that adds two\\nnumbers then I'm going to Define my\\nschema by copying the schema.",
    "file_path": "playlist_1\\How To Add ANY Production-Ready API To Your Custom GPT_voJuGHTfO_g.json",
    "file_size": 14303,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "add",
     "and",
     "api",
     "can",
     "data",
     "example",
     "going",
     "gpt",
     "guide",
     "how to add any production-ready api to your custom gpt_vojughtfo_g",
     "json",
     "lang:pt",
     "nand",
     "now",
     "nto",
     "schema",
     "test",
     "the",
     "then",
     "this",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "4ca90cfb330e2532129a73fff1471f46",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 3,
     "total_chunks": 5,
     "processing_time": 0.05997753143310547
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 3,
    "total_chunks": 5,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How To Add ANY Production-Ready API To Your Custom GPT_voJuGHTfO_g_Part_5",
    "content": "P file\\ninto the root directory again I will\\nname my data model add two numbers and\\nthe description for the model would be\\nthat this function simply adds two\\nnumbers the parameters would obviously\\nbe number one and number two both\\nrequired integers without default values\\nto make one or all of your parameters\\noptional you can wrap them in an\\noptional type from the type in default\\npython library and provide default\\nvalues then I'm going to replace the\\nprevious model in the name equals main\\nblock below now I just have to finish\\nthe main Logic for our endpoint in the\\nmain.py file the process is the same as\\nbefore we unpack the request parameters\\ninto our model catch and return arrow if\\nthere are any and if not execute our\\nlogic and return the data as a response\\nnow we can run the deploy command again\\ncopy our new function URL into the\\nschema example file under servers print\\nour schema and paste it into our new\\naction for our custom GPT that's it now\\nit should be able to add two numbers\\nwithout printing a block of unnecessary\\ntext in conclusion custom gpts is a huge\\nopportunity but you have to approach it\\nstrategically if you think that you have\\na unique idea for the GPT store I can\\nassure you that a thousand other people\\nhave the ex exact same idea and if it's\\nreally good open AI will most likely\\nrelease it themselves on the other hand\\nif you are developing a custom solution\\ntailored for a specific business in my\\nopinion you are much more likely to\\nsucceed open a rapper startups rarely\\nsatisfy all my clients business needs\\nmost of them require custom logic or\\nguard rails to ensure that only specific\\ndata can be accessed or modified for\\nexample you can allow the model to store\\ndelet information in a client CRM while\\nat the same time curing a Salesforce API\\nto calculate the total revenue that the\\nsite can bring in all in one function\\nwithout the need to create any user\\ninterface any longer so let me know in\\nthe comments what you want to see next I\\ndo read all of them and I try to respond\\nas much as possible more videos on agent\\nswarms certainly coming soon so thank\\nyou for watching and don't forget to\\nsubscribe\",\n    \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\How To Add ANY Production-Ready API To Your Custom GPT_voJuGHTfO_g.json\",\n    \"tags\": [\n        \"How To Add ANY Production-Ready API To Your Custom GPT\"\n    ],\n    \"source\": \"https://www.youtube.com/watch?v=voJuGHTfO_g\"\n}",
    "file_path": "playlist_1\\How To Add ANY Production-Ready API To Your Custom GPT_voJuGHTfO_g.json",
    "file_size": 14303,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "add",
     "all",
     "and",
     "any",
     "api",
     "can",
     "client",
     "custom",
     "example",
     "file",
     "how to add any production-ready api to your custom gpt_vojughtfo_g",
     "json",
     "lang:pt",
     "model",
     "nthe",
     "one",
     "our",
     "parameters",
     "that",
     "the",
     "two",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "4ca90cfb330e2532129a73fff1471f46",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 4,
     "total_chunks": 5,
     "processing_time": 0.05997753143310547
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 4,
    "total_chunks": 5,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How to Integrate Your Agent Swarms Into Custom GPTs_nrfVO8bLRL4_Part_1",
    "content": "{\n    \"section_name\": \"How to Integrate Your Agent Swarms Into Custom GPTs\",\n    \"content\": \"In this video I'm gonna show you how to integrate \\nyour agent swarms directly into custom GPTs,\\n \\nmaking them easily accessible to \\nany number of users at any time,\\n \\nregardless of their technical experience. I will \\nalso talk about a lot of exciting updates,\\n \\nincluding a discord community \\nwhich I know you guys have been  \\nwaiting for. So make sure to stay\\nuntil the end. Let's dive in. If you  \\nhaven't been following me before, \\nwelcome to this channel. My\\n \\nname is Arsen and my goal is to automate my entire \\nAI agency with AI. To do this, I've created a\\n \\nframework called Agency Swarm, which unlike other \\nframeworks does not write prompts for you, is\\n \\nextremely reliable in production, \\nand allows you to easily define  \\ncommunication flows. But the one\\nbiggest piece that we were missing  \\nuntil today was a community where \\nyou guys can grow ideas, share\\n \\nyour work and get some help. Now finally with our \\nnew discord server you have the opportunity\\n \\nto do all of these things and more. \\nI'll be there with you personally  \\nsharing my own perspectives,\\ninsights and listening closely  \\nto your feedback. So for everyone \\nwho wants to be a part of this\\n \\nmovement shaping the future of AI the link will \\nbe in the description and in comments. Now,\\n \\nwithout further i do, let's \\nsee what we are going to build  \\ntoday. So, this is my custom GPT that is\\ncurrently integrated with a BitInvest swarm from  \\nmy previous video created by the Genesys swarm.\\nSo make sure to check out this video later.\\n \\nNow, let's see how this works. \\nI'm gonna ask what are\\n \\nthe Bitcoin prices for today. And as you can \\nsee, the BitInvest CEO immediately proceeds\\n \\nwith calling the first function \\nwhich sends our message to the  \\nmarket analyzer agent. Make sure to\\nclick always allow so I can upload  \\nsome viruses to your computer and \\nsteal your data. And just so you\\n \\ndon't have to confirm these messages each time. \\nThe CEO simply informs me that the process of\\n \\nfetching the latest Bitcoin \\nprices is underway. As some of  \\nyou might have already guessed, we finally\\nhave a synchronous execution. But more on this  \\nlater. So currently, the Market Analyzer agent\\nis running on our Firebase backend in a  \\nseparate serverless function. \\nWe will check back with him\\n \\nlater. In the meantime, let's ask the CEO what are \\nthe latest news today. Amazing, so this time\\n \\nit calls the News Harvester agent, which is our \\nsecond agent and also notifies me that fetching\\n \\nthe latest news is underway. In \\nthe meantime, let's check if we  \\ngot the response from the first\\nagent. Indeed, as you can see,  \\nwe now get a list of Bitcoin prices \\nfrom the market analyzer agent,\\n \\nand it seems like Bitcoin prices have dropped, \\nunfortunately. So now let's also check if there\\n \\nare any news related to this. Awesome, now we get \\na list of top news from the market harvester.\\n \\nSeems like most of them aren't very \\npositive and we might be expecting  \\na crash soon. So let's ask\\nthe CEO if I should invest in  \\nBitcoin or not. Now the CEO provides \\nme with some factors to consider\\n \\nbased on these news and prices. Not an investing \\nadvice. The link to this custom GPT will be in\\n \\nour Discord if you want to try \\nthis out yourself or hack my  \\nBinance account. Now before I show you\\nhow to create this integration yourself,  \\nyou need to understand the three \\nsignificant updates that I\\n \\nhave added to this framework. First and foremost, \\nwe now have a synchronous execution mode inside\\n \\nthe agency class. This allows your agents to send \\ntasks to one another without having to wait for\\n \\na response. All you have to do to enable it \\nis simply set async mode to threading when\\n \\ninitializing your agency. Currently, only \\nthe threading mode is available, however,\\n \\nin the future I do plan to add \\nmore options.",
    "file_path": "playlist_1\\How to Integrate Your Agent Swarms Into Custom GPTs_nrfVO8bLRL4.json",
    "file_size": 10565,
    "last_modified": "2025-04-18 15:34:02",
    "tags": [
     "agent",
     "and",
     "ceo",
     "custom",
     "have",
     "how to integrate your agent swarms into custom gpts_nrfvo8blrl4",
     "json",
     "lang:pt",
     "news",
     "now",
     "nthe",
     "server",
     "that",
     "the",
     "this",
     "will",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "cbb1da460c1e79c4d87b9d5dff0a3858",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 3,
     "processing_time": 0.03734278678894043
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 3,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How to Integrate Your Agent Swarms Into Custom GPTs_nrfVO8bLRL4_Part_2",
    "content": "After you've done so,  \\nall your agents will automatically\\nutilize two tools instead of one. The first tool,  \\nSendMessage, is still there, however, in async\\nmode, it doesn't wait for the recipient agent to  \\nfinish the task. Instead, it simply triggers it\\nin another thread and then sends a status  \\nresponse back. The caller agent \\ncan then check the response\\n \\nby using the new GetResponse tool. \\nThis tool retrieves the latest  \\nmessage from the thread using\\nOpenAI Assistance API or returns  \\nanother status update if the run \\nis still in progress. Literally\\n \\neverything else works almost \\nexactly in the same way. You  \\ndon't even have to think about it. There\\nis still not a single hard-coded prompt  \\nlike in all other frameworks. \\nYour agents will determine\\n \\nhow to communicate with each \\nother only based on these tool  \\ndescriptions. This means that you still\\nhave full control over your entire system. The  \\nsecond major update is that now you can easily\\nload your agents and threats from the database,  \\nmaking this framework easily runnable on all\\ntypes of backends. So even if you have a stateless  \\nbackend like a serverless \\nfunction, you can still\\n \\nallow your agents to continue \\ntheir conversations exactly where  \\nthey left off. To use this feature,\\nyou have to insert two functions into the  \\nThreads callbacks and Settings \\ncallbacks parameters inside\\n \\nthe Agency class. Essentially, the Save function \\nshould take the input parameter and save it to\\n \\nyour database, while the Load \\nfunction should load this parameter  \\nin the exact same format and return\\nit as a function output. I will\\n \\nshow you how to set this up yourself with \\nFirestore NoSQL database in just a moment.\\n \\nAnd finally, I've hired someone from my YouTube \\nchannel to help me out with documentation and\\n \\nsome examples for this framework. Now, let's \\nsee how you can create your own custom GPT\\n \\nswarm yourself. To get started, I've created a \\nrepository for you called Agency Swarm Custom\\n \\nGPT. Simply clone this repo, \\nthe link will be in our Discord  \\nserver and follow these steps. First,\\nsearch for Firebase Console on Google and login  \\ninto your account. Create a new project,\\nset the billing plan to Blaze. Don't worry  \\nabout the costs as Firebase \\noffers a generous free usage\\n \\nquota that you're super unlikely to hit. This step \\nis only necessary so you can enable certain\\n \\nfeatures required for deployment. After creating \\nthe project you'll be taken to your project's\\n \\ndashboard. Open the Firestore database \\nunder the build tab and enable this  \\nservice. Then go to your\\nproject settings click service  \\naccounts then click Python and click \\ngenerate new key. Drop this key\\n \\ninto the functions directory of the \\nrepository that you have just cloned  \\nfrom our discord server\\nand then also don't forget  \\nto insert your OpenAI key and create \\na DB token for authentication. You\\n \\ncan follow the provided link to generate a simple \\nrandom token or use any random password. Now,\\n \\ngo to Firebase console, copy \\nyour project ID and paste it into  \\n\\\".firebaserc file\\\". Open your terminal,\\nnavigate into the functions directory and  \\ncreate a new Python environment with the\\nfollowing command. Activate it and then run  \\npip install-r requirements.txt. Now\\nit's time to set up your agency. You can  \\ndrop your agency folder or separate agent\\nfiles into the same functions directory.\\n \\nAfter adding your agent \\nfiles, import them inside\\n \\nthe helpers.py file inside the init agency method. \\nPlease refer to the commented example on how to\\n \\ndo this. Alternatively, if \\nyour agency is super simple,  \\nyou can set it up in the same helpers.py\\nfile.",
    "file_path": "playlist_1\\How to Integrate Your Agent Swarms Into Custom GPTs_nrfVO8bLRL4.json",
    "file_size": 10565,
    "last_modified": "2025-04-18 15:34:02",
    "tags": [
     "agency",
     "agent",
     "agents",
     "and",
     "api",
     "can",
     "database",
     "documentation",
     "example",
     "how to integrate your agent swarms into custom gpts_nrfvo8blrl4",
     "json",
     "lang:pt",
     "new",
     "same",
     "still",
     "the",
     "then",
     "this",
     "tool",
     "will",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "cbb1da460c1e79c4d87b9d5dff0a3858",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 3,
     "processing_time": 0.03734278678894043
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 3,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How to Integrate Your Agent Swarms Into Custom GPTs_nrfVO8bLRL4_Part_3",
    "content": "The only thing you have to keep in mind  \\nis to add the threads callbacks as shown in the\\ncommented example with the two functions defined  \\nabove. If you are not sure how to create your\\nagency, this is unfortunately out of scope of this  \\nvideo, so make sure to check out this one next.\\nTo save the threads we'll use a special  \\nfunction that connects to our \\nFirestore database and stores\\n \\nthem in the conversations collection document. \\nThe ID of this document will be a conversation\\n \\nID from our custom GPT provided in a special \\nheader by OpenAI. You can see this header in\\n \\nthe main.py file. The load function will check \\nif a document with this conversation ID exists\\n \\nand return the saved threads accordingly. If the \\ndocument does not exist, it means that this is\\n \\na new conversation, so we can simply return an \\nempty object. This setup ensures that all chat\\n \\nhistories between your agents are \\nunique to each conversation in your  \\ncustom GPT. So if a user\\nstarts a new conversation,  \\nall the chat histories between your \\nagents will be reset. But in the same\\n \\nconversation, your agents can continue talking to \\none another, even if the user has left the chat\\n \\nand returned back later. Now, there are just a few \\nmore steps left. First, run the schema.py file,\\n \\nwhich will create a schema.json and settings.json \\nfiles in your functions directory. This schema\\n \\nwill be used to create our actions on custom \\nGPT, and the settings file will initialize\\n \\nour agents on the backend. Then, if you don't \\nalready have Firebase tools installed, install\\n \\nthem with npm using the \\nfollowing command. After that,  \\nrun firebase login if needed. And finally,\\nrun \\\"firebase deploy - -functions\\\". After our  \\nfunctions are deployed, copy the URL from the\\nterminal, go back into the schema.py file, paste  \\nit into the \\\"getCustomGPTSchema\\\" method and run\\nthe schema.py file again. This will replace the  \\nserver URL of your schema with the correct URL\\nfrom our cloud function. Now we are finally ready  \\nto configure our custom GPT. Copy the\\nCEO instructions from the terminal output  \\nafter running schema.py file, \\ncreate a new custom GPT,\",\n    \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\How to Integrate Your Agent Swarms Into Custom GPTs_nrfVO8bLRL4.json\",\n    \"tags\": [\n        \"How to Integrate Your Agent Swarms Into Custom GPTs\"\n    ],\n    \"source\": \"https://www.youtube.com/watch?v=nrfVO8bLRL4\"\n}",
    "file_path": "playlist_1\\How to Integrate Your Agent Swarms Into Custom GPTs_nrfVO8bLRL4.json",
    "file_size": 10565,
    "last_modified": "2025-04-18 15:34:02",
    "tags": [
     "and",
     "are",
     "conversation",
     "custom",
     "database",
     "example",
     "file",
     "gpt",
     "how to integrate your agent swarms into custom gpts_nrfvo8blrl4",
     "into",
     "json",
     "lang:pt",
     "our",
     "schema",
     "setup",
     "that",
     "the",
     "this",
     "will",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "cbb1da460c1e79c4d87b9d5dff0a3858",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 3,
     "processing_time": 0.038341522216796875
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 3,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How To Use the NEW Streaming Feature in OpenAI Assistants API_iHVP7SkpUHE_Part_1",
    "content": "{ \"section_name\": \"How To Use the NEW Streaming Feature in OpenAI Assistants API\", \"content\": \"one announcement that has recently been\\noverlooked is that openi assistants API\\nfinally supports streaming I mean so\\nwhat it support streaming who cares\\nabout streaming when we're all going to\\nget replaced by eii developers like\\nDevin right well don't turn off this\\nvideo just yet because this feature\\nplays a much larger role for production\\napplications than you might think to\\nillustrate a study at Amazon discovered\\nthat a mere 100 milliseconds of latency\\ncost them over 1 % of their sales this\\nby the way amounts to almost $900\\nmillion annually so in this video I'll\\nexplain exactly what streaming is why\\nit's so vital for production and how you\\ncan use it with both assistance API and\\nmy own framework agency SW let's dive\\nin okay first of all one of the reasons\\nall the Transformer models we use today\\nsuch as Char PT are unidirectional is\\nbecause of the support for this exact\\nfeature what makes these models so\\npractical is that they can examine all\\nthe previous ws and begin generating new\\nWS one by one unlike bidirectional\\nmodels which require entire sequence for\\nprocessing so on the open eii side\\nstreaming makes absolutely no difference\\nbecause whether you use it or not the\\noutput by these models is still\\ngenerated word by word however on the\\nclient side it can make all the\\ndifference because the way you get this\\noutput dramatically affects the user\\nexperience to understand exactly how it\\naffects your users in your specific\\nsituation you must first understand the\\ndifference between latency and response\\ntime often these two terms are used\\ninterchangeably but they're not the same\\nthing the response time is what the\\nclient sees and latency is the duration\\nthat a request is waiting to be handled\\nso when comparing streaming and\\nnon-streaming approaches the total\\nresponse time May remain essentially the\\nsame for both however it is the latency\\nthat matters because this is what the\\nuser perceives to be the waiting time\\nfor instance if generating a full\\nresponse takes a total of 10 seconds the\\ntotal response time would be\\napproximately 10 seconds in both\\nstreaming and non-streaming approaches\\nhowever in the streaming approach the\\nlatency can be very low potentially\\nclose to zero this means that the user\\nwill get value from this interaction\\nalmost immediately which significantly\\nenhances user satisfaction and\\nengagement now what are the types of\\napplications for which you should and\\nshould not use streaming well definitely\\nany external applications that use some\\nform of a front end to interact with the\\nAI in real time should always use\\nstreaming if possible for example even\\non our own SAS platform this has been\\none of the most requested features from\\nthe very start with AI Integrations like\\na website wiget you potentially only\\nhave a few seconds in total before the\\nuser leaves SO waiting for an entire\\nresponse might not even be an option\\nthis is why we are personally\\nprioritizing this feature next so if\\nyou're curious about how we are\\nimplementing it specific specifically\\nmake sure to stay until the end for\\ninternal applications that are used only\\nby your employees on the other hand\\nstreaming can make absolutely no\\ndifference this is because your own\\nemployees most likely already understand\\nthe value of the application if it was\\ndeveloped specifically for them so\\nthere're a lot less likely to leave\\nbackend Integrations where there is no\\nuser interface like data analysis\\napplications do not need streaming at\\nall because the user interaction is\\nasynchronous anyways so now let me show\\nyou how to implement this feature with\\nthe new open AI assistance API the\\nprocess for generating streaming\\ncompletions with assistance API is\\nactually much harder to implement than\\nin all previous open end points and if\\nyou think about it it actually makes\\nperfect sense because in all previous\\nopen end points there was only a single\\nevent which is the next token",
    "file_path": "playlist_1\\How To Use the NEW Streaming Feature in OpenAI Assistants API_iHVP7SkpUHE.json",
    "file_size": 14618,
    "last_modified": "2025-04-18 15:34:01",
    "tags": [
     "all",
     "and",
     "api",
     "are",
     "because",
     "example",
     "feature",
     "how",
     "how to use the new streaming feature in openai assistants api_ihvp7skpuhe",
     "json",
     "lang:pt",
     "not",
     "streaming",
     "that",
     "the",
     "this",
     "time",
     "use",
     "what",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "1cffe773d6f061f78ad1c019d02a4b44",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 4,
     "processing_time": 0.03933143615722656
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How To Use the NEW Streaming Feature in OpenAI Assistants API_iHVP7SkpUHE_Part_2",
    "content": "generation\\nbut in the assistance API there are many\\ndifferent events like for example\\nexecuting your code with code\\ninterpreter on the back end retrieving\\nfiles or using other custom tools and\\nthen submitting tool outputs all of\\nthose of various events that need to be\\nhandled differently however don't be\\ndiscouraged yet because after you\\nunderstand why it's implemented this way\\nit actually becomes very simple and to\\ndo so make sure to open the notebook in\\nthe description and follow this tutorial\\nwith me right now this way you'll be\\nable to test it out yourself and get all\\nthe concepts much faster okay first\\nlet's install the packages and set the\\nopen a key after that so you can feel\\nthe difference yourself let's revisit\\nthis feature with the previous chat\\ncompletions API all it takes in chat\\ncompletions is literally just set the\\nstream parameter to true now instead of\\na complete response we get a special\\npython generator object to get the text\\nfrom this object all we have to do is\\niterate through it in a loop and print\\nthe Delta value which is basically the\\nnext generated token that's how simple\\nit was with the previous chat\\ncompletions API however don't forget\\nthat with this API you have to execute\\nall your logic yourself after the\\ngeneration is complete so although the\\nstreaming response generation in this\\nAPI is much simpler if you try to\\nimplement a feature like code\\ninterpreter yourself you'd find that it\\nwould be not just more difficult but\\nalmost impossible to do by yourself\\nthere are even startups like notable\\nwhere the main functionality of the\\nplatform is literally just one feature\\nin assistance API so now let's implement\\nthis ourselves with assistance all the\\nsteps for creating and running your\\nassistant are basically the same only\\nthe last step differs first we initiate\\nour assistant with some instructions and\\ncapabilities we can give it a name\\ndescription and so on second we create a\\nthread third we need to add a message to\\nthis threat now fourth this is where it\\ngets interesting to stream your\\ncompletions you need to create a new\\nevent handler class in this class we\\nneed to Define special event handler\\nmethods each of these methods is called\\nbased on the specific event it\\ncorresponds to as I said because there\\nare many different events we can't just\\niterate through them in Loop we need to\\nhandle each event differently so for\\nexample on text created is called when\\nyour assistant starts to generate text\\nfor the first time and it makes sense to\\nprint the assistant name on Text data is\\nis called when the assistant generates\\nthe next token in this text you can get\\nthis token from the Delta value or you\\ncan get the complete response up to this\\nmoment with the snapshot value parameter\\nthe event on tool created is triggered\\nwhen your assistant decides to utilize a\\nfunction so you can print the function\\nname for example meanwhile on tool\\ncalled Data is activated when the\\nassistant begins to generate arguments\\nor even execute some built-in\\ncapabilities like code interpreter on\\nthe back end there are also many other\\nevents that you can find by browsing the\\ncode for open I pack p on GitHub for\\nexample on end fires when the stream is\\nfinished and on create message fires\\nwhen the new message is created which\\nones you use depends heavily on your\\nbackend logic typically you would want\\nto either stream these events back to\\nthe client or save them in your database\\nnow to run your assistant with streaming\\nyou need to use a new method called\\ncreate and stream passing your event\\nhandler as a parameter then you need to\\nwait until the stream is done while this\\nthreat is running your event handler\\nmethods will be called with the\\ncorresponding events so as you can see\\nour event handler now prints our\\nassistant response and the code that",
    "file_path": "playlist_1\\How To Use the NEW Streaming Feature in OpenAI Assistants API_iHVP7SkpUHE.json",
    "file_size": 14618,
    "last_modified": "2025-04-18 15:34:01",
    "tags": [
     "all",
     "and",
     "api",
     "assistant",
     "can",
     "client",
     "code",
     "event",
     "events",
     "example",
     "how to use the new streaming feature in openai assistants api_ihvp7skpuhe",
     "json",
     "lang:pt",
     "need",
     "now",
     "nthe",
     "test",
     "that",
     "the",
     "this",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "1cffe773d6f061f78ad1c019d02a4b44",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 4,
     "processing_time": 0.04033017158508301
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How To Use the NEW Streaming Feature in OpenAI Assistants API_iHVP7SkpUHE_Part_3",
    "content": "was\\nexecuted by code interpreter on openi\\nthat's the most basic example of how you\\ncan use streaming with assistants\\nhowever most likely in production your\\nassistant will also need to utilize some\\ncustom tools this is where it can get a\\nbit more complex assistant creation\\nprocess is the same I will just replace\\nthe code interpreter with two custom\\ntools one to get the weather and the\\nother to get a nickname of a city then\\njust like in the previous example I will\\ncreate a threat and add a message to\\nthis threat however now before running\\nit we also need to save the Run object\\nbecause we will need to submit our\\noutputs to this object later so after\\nthis stream is done I will use another\\nmethod called get final run to save it\\nglobally as you can see the assistant\\ncalled two functions but the output has\\nstopped this is because now to continue\\ngenerating a response our assistant\\nneeds to know the results of those two\\nfunction calls in this example I will\\njust iterate through the two calls and\\npass some hard coded values in a real\\nworld scenario you would obviously need\\nto incorporate your own unique logic\\nbased on the arguments provided by the\\nassistant after that you need to submit\\nthese tool outputs to do so you need to\\nrun submit tool output stream you can\\nuse the same event handler and then also\\nadd your function outputs this will now\\ncontinue running the thread that we have\\nstarted before as you can see the\\nassistant now generates a full response\\nbased on the two outputs we've submitted\\nstating that the weather is 75° and the\\ncity's nickname is the Big Apple awesome\\nnow obviously utilizing this in\\nproduction can make your code base a bit\\ncomplex that's exactly what my framework\\naims to solve it will automatically\\ncreate your assistants add messages run\\nthreads and submit tool outputs as\\nneeded without you even having to think\\nabout it so let me give you a glimpse of\\nhow you can achieve this with the help\\nof agency form the process is pretty\\nsimilar however with my framework your\\ncode will be much cleaner in the end the\\nfirst step is to create our tools with\\nthe instructor Library instead of\\nexecuting your logic somewhere else in\\nyour code base you can simply Define it\\ninside the run method here we will\\nsimply return our example values like\\nbefore then we can proceed with creating\\nour agent most of the parameters are\\nalmost the same except in tools you must\\npass your tool classes defined above\\ninstead of schemas which also makes your\\ncode cleaner by the way next you need to\\ninitialize the agency in this example\\nwe'll simply use one agent maybe I\\nshould call it a freelancer after that\\nwe will Define the event handler similar\\nto the one we defined above the only\\ndifference is that with my framework you\\nmust extend the agency event handler\\nclass which has two additional\\nproperties for you the agent name and\\nthe recipient agent name you can use\\nthese properties to print the names of\\nthe agents conversing with one another\\nalso there is an additional class method\\non all streams end which is called when\\nall streams have ended this method is\\nneeded because unlike in the official\\nopen a documentation your event handler\\nwill be called multiple times and\\nprobably by even multiple agents so you\\ncan use this method to find out when the\\nfinal response from the agency is\\ncompleted the final step is to Simply\\nrun our agency using the new get\\ncompletion stream method with this event\\nhandler as you can see the agent calls\\ntwo functions just like before however\\nnow instead of you having to execute\\ntools and submit the tool outputs\\nmanually the framework does it for you\\nand the agent simly continues generating\\na response this is an example for a\\ncustom backend integration alternatively\\nyou can simply use the demo gradio\\nmethod to run a gradio",
    "file_path": "playlist_1\\How To Use the NEW Streaming Feature in OpenAI Assistants API_iHVP7SkpUHE.json",
    "file_size": 14618,
    "last_modified": "2025-04-18 15:34:01",
    "tags": [
     "agent",
     "and",
     "can",
     "documentation",
     "example",
     "get",
     "how to use the new streaming feature in openai assistants api_ihvp7skpuhe",
     "json",
     "lang:pt",
     "need",
     "run",
     "submit",
     "that",
     "the",
     "this",
     "two",
     "use",
     "will",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "1cffe773d6f061f78ad1c019d02a4b44",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 4,
     "processing_time": 0.04033017158508301
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How To Use the NEW Streaming Feature in OpenAI Assistants API_iHVP7SkpUHE_Part_4",
    "content": "interface or the\\nRun demo method to run this agency from\\nthe terminal both of these methods\\nalready used streaming by by default in\\nconclusion as I promised let me provide\\nyou with some production tips and\\nexplain how we are implementing this\\nfeature on our SAS platform before you\\nbegin it's important to review your\\nexisting infrastructure because some\\nbackend Technologies don't support\\nstreaming at all for instance our SAS\\nbackend was fully developed using\\nserverless functions on Google Cloud\\nwhich unfortunately have this exact\\nlimitation so what we're going to do\\nnext is transfer a part of our\\napplication responsible for generating\\nmodel responses to Google Cloud run\\nGoogle Cloud run is also a serverless\\nplatform however instead of running\\nsingle functions it is designed to run\\nstateless containers which have a lot\\nfew limitations if you're interested in\\nmore details about my experience\\nlaunching an AI SAS product such as the\\nserver costs or the development process\\nlet me know in the comments and I'll\\nmake a separate video on that later so\\nafter you've decided on your\\ninfrastructure setup the next step is to\\nchoose the right protocol for streaming\\nhere you have three options you can\\neither use serers side events websockets\\nor GR PC websockets and grpc are bir\\ndirectional communication standards\\nmeaning that you can not only receive\\ngenerated tokens from the back end but\\nalso send events back to the server\\nhowever for most llm chat-based\\napplications I believe that bir\\ndirectional communication standards may\\nbe an Overkill this is because there are\\nreally any events that you need to send\\nback to the server while generating a\\nresponse so for most llm applications I\\nwould actually recommend using serers\\nside events because of their Simplicity\\nwith SS you can set up a stream with\\njust a few lines of code on both the\\nserver and the client moreover it is\\nbuilt on top of the HTTP protocol which\\nintegrates seamlessly with all modern\\nweb browsers this is how we are\\npersonally going to implement this on\\nour SAS platform very soon however for\\nthe exact details on how to do this I\\nrecommend chatting with Chad jpt because\\nthis heavily depends on your technology\\nstack my job here was to make sure that\\nyou know the right questions to ask so\\nthat's it for this video thank you for\\nwatching and don't forget to\\nsubscribe\", \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\How To Use the NEW Streaming Feature in OpenAI Assistants API_iHVP7SkpUHE.json\", \"tags\": [ \"How To Use the NEW Streaming Feature in OpenAI Assistants API\" ], \"source\": \"https://www.youtube.com/watch?v=iHVP7SkpUHE\" }",
    "file_path": "playlist_1\\How To Use the NEW Streaming Feature in OpenAI Assistants API_iHVP7SkpUHE.json",
    "file_size": 14618,
    "last_modified": "2025-04-18 15:34:01",
    "tags": [
     "and",
     "are",
     "because",
     "client",
     "cloud",
     "events",
     "how",
     "how to use the new streaming feature in openai assistants api_ihvp7skpuhe",
     "json",
     "lang:pt",
     "our",
     "run",
     "sas",
     "server",
     "setup",
     "streaming",
     "that",
     "the",
     "this",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "1cffe773d6f061f78ad1c019d02a4b44",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 3,
     "total_chunks": 4,
     "processing_time": 0.04033017158508301
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 3,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "My AI Agent Blueprint to Fully Automate Any Business_yamHnWoOcM0_Part_1",
    "content": "{ \"section_name\": \"My AI Agent Blueprint to Fully Automate Any Business\", \"content\": \"so in today's video I will present you\\nwith our entire blueprint for automating\\nany business with AI agents completely\\nfrom scratch I will explain the seven\\nkey steps in our process that we use to\\ngo from finding your first client to\\nbuilding out as many agents for them as\\npossible until your or your client's\\nbusiness literally runs by itself before\\nwe get started my name is areni and we\\nwere the first AI agencies to start\\nbuilding real production AI agents not\\nexamples back in 2024 today we already\\nhave over 20 people and we are still\\ncontinuing to scale and Pioneer this new\\nagents as a service model on this\\nchannel I'm sharing with you all of our\\nlearnings completely for free now let's\\nDive Right In the first step in our\\nblueprint is of course to find a client\\na frequent mistake that I see people\\nmake in the space is waiting too long to\\nfind their first client many people\\nthink that they need to master AI agent\\ndevelopment completely before starting\\nto offer real services but the truth is\\nyou can get your first client even\\nbefore you build any agents at all yes\\nthat's true you can actually learn\\neverything you need to know along the\\nway up after you got your first client\\nand in my opinion it's a much better way\\nto do this not only you will get paid\\nfor it which is a pretty significant\\nAdvantage but you will also learn faster\\nbecause you'll be learning from real\\nexperience and feedback but the best\\npart is that you already probably know\\nsomeone who could massively benefit from\\nAI agents because those people are\\ntypically business owners and\\nentrepreneurs and everyone knows at\\nleast a couple of them maybe it's your\\ndeath friend who owns a small restaurant\\nor maybe it's someone who you studied\\nwith at college or maybe even it's a\\ncompany that you work for right now so\\njust reach out to them and tell them\\nthat you're starting to build AI agents\\nthat can improve efficiency and automate\\ntheir boring repetitive tasks this is\\ncalled warm Outreach by the way and\\nthat's usually the first way that I\\nwould recommend to find your client the\\nsecond way that I would recommend for\\nbeginners is using freelance platforms\\nlike Fiverr or upwork right now there's\\npractically zero competition for AI\\nagent Services most people still offer\\nvery basic outdated services that today\\ncan be completely replaced by eii agents\\nso think about what industries you have\\nthe most experience with think about\\nwhat you're passionate about and then\\nsearch for similar services on these\\nplatforms even if you're not planning to\\noffer your services through freelance\\nplatforms this exercise is still going\\nto be incredibly valuable for you so try\\nsearching for example for marketing and\\ninstantly you can see that people are\\noffering marketing strategies for over\\n$600 so why would anyone buy a $600\\nmarketing strategy if they can buy an\\nagent that can generate infinite\\nmarketing strategies for them so the\\nbest part about these two methods is\\nthat they require no upfront investment\\nliterally it doesn't take you anything\\nto outreach to some of the people you\\nknow and create those gigs on Fiverr and\\nupwork and later you can then expand\\ninto other lead gen strategies like cold\\nOutreach or organic content but\\ndefinitely make sure you find your first\\nclient first because this will allow you\\nto learn and get real feedback much\\nfaster and after you found your first\\nclient the next step is to find a\\nproblem so here's how we find problems\\nto automate with AI agents in any\\nbusiness first you are looking for a\\nrecurring problem that your clients have\\nstruggled to automate before it needs to\\nbe a dynamic process that is performed\\nrepeatedly by one or more employees\\nwithin the company it shouldn't be a\\nsimple process where each step and the\\nsequence of those steps are determined\\nin advance because such processes can be\\neasily automated with tools like zapier\\nor make we are looking specifically",
    "file_path": "playlist_1\\My AI Agent Blueprint to Fully Automate Any Business_yamHnWoOcM0.json",
    "file_size": 20061,
    "last_modified": "2025-04-18 15:34:04",
    "tags": [
     "agents",
     "and",
     "are",
     "can",
     "client",
     "example",
     "find",
     "first",
     "json",
     "lang:pt",
     "model",
     "my ai agent blueprint to fully automate any business_yamhnwoocm0",
     "nto",
     "people",
     "that",
     "the",
     "them",
     "this",
     "will",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "0d795e9988a47ea169721061953b844b",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 6,
     "processing_time": 0.022000551223754883
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 6,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "My AI Agent Blueprint to Fully Automate Any Business_yamHnWoOcM0_Part_2",
    "content": "for\\nmore Dynamic processes that are never\\nexecuted twice in the exact same way so\\ntypically in such processes there's\\nalways something that can go wrong so\\nthe agent needs to adapt based on\\ncircumstances take for example project\\nmanagement managing multiple employees\\nat different time zones managing delays\\ndealing with changes in requirements all\\nof these things simply cannot be mapped\\nout on a workflow Builder it would be\\nimpossible or another great example is\\ncontent creation where you need to\\nconstantly provide your agent with\\nregular feedback just like you would\\nprovide it to a human blog writer and\\nthe easiest way to uncover these\\nprocesses within a business is to start\\nfrom Sops or standard operating\\nprocedures luckily most businesses have\\nalready documented these processes\\nsomewhere so typically all you need to\\ndo is just ask however if your client\\ndoesn't have these processes documented\\nwhich of course does happen quite\\nfrequently you'll need to get curious\\nand uncover these processes by yourself\\nso here are some great practical\\nquestions that we use in our agency to\\nfind these processes all the time what\\nroles currently exist in your company\\nwhich processes are currently causing\\nthe most frustration for you which\\ndepartments have recently been\\nstruggling to scale which tasks do your\\nemployees find themselves doing\\nrepeatedly on a weekly or daily basis if\\nyou want to get our full AI strategy\\nmeeting template completely for free\\nthen head over to our school Community\\nwhich previously was available only to\\nour paid subscribers of our platform\\nthere's also some additional extra\\ncontent and playbooks there that you can\\nuse to get started completely for free\\nthe reason we are making this community\\npublic is because we are now adding a\\nfree plan to our platform which\\nhopefully should be available by the\\ntime you watch this video so make sure\\nto sign up and if it's not available\\nwe'll notify you okay so after asking\\nthese questions you should have a few\\nvery concrete ideas of what you can\\nautomate however before you start\\nbuilding please consider carefully which\\nagent to deploy first focusing on a\\nwrong agent at the beginning caused a\\nton of frustration for us and for our\\nclients when we were just getting\\nstarted your first agent is the most\\nimportant if it takes too long for you\\nto build your first agent or if it\\ndoesn't bring enough value then most\\nlikely the client is simply not going to\\ncontinue with the second one so you will\\nnever have a chance to fully automate\\ntheir business so now we use this\\nformula to calculate the ROI for any\\ngiven process so we'll leave the formula\\nhere on the screen I've previously\\ncovered it in another video and a key\\nthing to note is that hours are total\\nhours performed by all employees\\ncurrently responsible for this process\\nand operational costs are just model\\ncosts which typically are pretty much\\nnegligible so essentially what this\\nformula shows you is that you are\\nlooking for processes that are either\\nperformed by many employees at the same\\ntime or that are performed by very\\nexpensive positions and at the same time\\nare relatively simple to build so it\\nsounds really obvious but make sure you\\nactually consider all of these\\nparameters to together because it is\\nreally tempting to just jump into the\\nfirst agent solution that comes to mind\\nand this is has actually been holding us\\nback for quite a while in our agency\\nuntil we really started to resist\\nbuilding the agents that client tells us\\nto build and instead focus on what they\\nreally need we were actually stale for a\\nvery long time so to gauge the\\ncomplexity of your agent A good rule of\\nthumb is that the more apis your agent\\nhas to connect conect to or the harder\\nit is to work with those apis the harder\\nthe agent will be for you to build",
    "file_path": "playlist_1\\My AI Agent Blueprint to Fully Automate Any Business_yamHnWoOcM0.json",
    "file_size": 20061,
    "last_modified": "2025-04-18 15:34:04",
    "tags": [
     "agent",
     "all",
     "and",
     "are",
     "client",
     "example",
     "have",
     "json",
     "just",
     "lang:pt",
     "my ai agent blueprint to fully automate any business_yamhnwoocm0",
     "nthe",
     "our",
     "processes",
     "that",
     "the",
     "these",
     "this",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "0d795e9988a47ea169721061953b844b",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 6,
     "processing_time": 0.022000551223754883
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 6,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "My AI Agent Blueprint to Fully Automate Any Business_yamHnWoOcM0_Part_3",
    "content": "so\\nmake sure that you again consider all of\\nthese together and then after you pick\\nthe best process to automate you are\\nready for the next step which is\\nbuilding an MVP so when you're building\\nan MVP there are basically two paths\\nthat you can take you can either use a\\nframework or you can use a platform and\\nthe main difference is that with a\\nframework you have more flexib ability\\nand control but there's more technical\\nexperience required and with a platform\\ntypically there might be some extra cost\\ninvolved however it's much easier to use\\nso my recommendation is actually go with\\na platform whenever possible and if\\nthat's not possible only then use a\\nframework yes you see when we just got\\nstarted building agents in our agency we\\nused to only use a framework but then we\\nrealized that it would take us sometimes\\n2 days to build an agent but then it\\nwould also take us 3 days to deploy it\\nand deployment is like tedious backand\\nengineering tasks that no one enjoys so\\nthat's exactly why we built our own\\nplatform that combines the flexibility\\nof a framework with the Simplicity of a\\nplatform and soon we'll also be adding a\\nvery cool feature on our platform where\\nyou'll be able to deploy agents built\\nwith a framework directly on our\\nplatform with with just a few clicks\\nfrom GitHub however regardless which\\napproach you select you need to know\\nthat all agents consist of three primary\\ncomponents which are instructions\\nknowledge and actions and most of the\\ntime you will actually spend on actions\\nwhich are the tools tools are the most\\nimportant component in any eii agent\\nsystem because that's how your agents\\ndeliver value unlike standard llms\\nagents shouldn't just provide resp\\nresponses to your users they should\\nactually execute the tasks this is the\\nkey thing about agents they actually\\ndeliver value by executing tasks this is\\nwhy we start from the tools we first\\nconnect our agents to all of the same\\nsystems that employees use throughout\\nthe process and only then we work on\\nprompting and knowledge so for example\\nif your client uses Trello for project\\nmanagement you need to ensure that the\\nagent can interact with the Trello API\\nas well and if the use Google Drive or\\nGitHub in the process then you need to\\nconnect the agent to these systems as\\nwell so we recently updated the\\ndocumentation for a framework I\\npersonally spent over 30 hours on it and\\nit contains detailed instructions on how\\nyou can create Reliable Tools with penic\\npenic is the only right way for you to\\ncreate agents because it allows you to\\nvalidate all of the agent inputs and\\noutputs in the tools this is key because\\nit helps you to reduce any\\nhallucinations by by the way people have\\nbeen asking me about penic Ai and\\nhonestly I was really disappointed by\\nthis framework because they are using\\npenic in all their own places they're\\nusing it for structured outputs but\\nthey're actually not using it for the\\ntools which is where things can actually\\ngo wrong like if the agent executes one\\naction incorrectly then it might cause\\nsome issues like it could erase all of\\nyour files from a Google drive right so\\nthis is why we only build tools with pen\\nlastly just one more quick tip by the\\nway this is also an example from our\\ncommunity where I'm currently also\\nhosting weekly Q&A calls which you can\\njoin and someone asked me on one of\\nthese calls what should they do if the\\nclient doesn't have all of the necessary\\ndata stored somewhere for the agent to\\naccess and the solution was quite simple\\nyou simply prom the agent to ask for\\nthis information directly so this helps\\nyou to avoid the problem of the agent\\nnot having access to some systems and\\nafter your agent is set up the next step\\nis to integrate it so Integrations are\\njust as important as your agent\\ncapabilities because how easy it is for\\nyour",
    "file_path": "playlist_1\\My AI Agent Blueprint to Fully Automate Any Business_yamHnWoOcM0.json",
    "file_size": 20061,
    "last_modified": "2025-04-18 15:34:04",
    "tags": [
     "actually",
     "agent",
     "agents",
     "all",
     "and",
     "are",
     "can",
     "client",
     "example",
     "json",
     "lang:pt",
     "my ai agent blueprint to fully automate any business_yamhnwoocm0",
     "our",
     "that",
     "the",
     "then",
     "tools",
     "use",
     "which",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "0d795e9988a47ea169721061953b844b",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 6,
     "processing_time": 0.022999048233032227
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 6,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "My AI Agent Blueprint to Fully Automate Any Business_yamHnWoOcM0_Part_4",
    "content": "client to use your agent can often\\ndetermine its success so here are six\\nprimary Integrations to consider for\\nyour agents number one web interface\\nthis is a standalone chat app like chat\\njpt it's great for both internal and\\nexternal agents when other options are\\nnot available number two widgets widgets\\nare embeddable chats that you can often\\nsee at the bottom of websites these are\\nideal for external customer facing\\nscenarios like customer support number\\nthree Messengers Messengers are\\ncommunication platforms that your client\\nalready uses like slack or Whatsapp at\\nour agency we found that slack is\\nparticularly important because almost\\nall of our clients use Slack to\\ncommunicate with their own employees\\nthat's why it's already supported on our\\nplatform and you can even create one\\nslack agent completely for free number\\nfour third party software what's less\\nfrequently used however but is still a\\nhuge opportunity is integrating agents\\ninto other common software tools like\\nSalesforce GitHub notion and others\\nsometimes you actually don't even need\\nto run an agent in a chat like interface\\nbecause you can trigger it based on\\ncertain events so for example we had a\\ncase study where we integrated an agent\\ninto an Azure devops environment so\\ninstead of triggering it with a message\\nit was triggered any time there was a\\nnew task posted on a Azure devops board\\njust like a human developer would so\\ninstead of just reading messages in chat\\nthis agent was reading comments and\\nrequirements posted on this task by\\nother developers and anytime we would\\nchange the status of this this task it\\nwould review them again and then proceed\\nto the next stage number five Chrome\\njobs Chrome jobs allow you to execute\\nyour agents on a fixed schedule like\\nhourly daily weekly and so on so for\\nexample many businesses often generate\\nreports every month and in this case you\\ncan simply schedule your report\\ngenerator agent to run monthly as well\\nwe will soon be adding this feature on\\nour platform too and lastly API API\\nIntegrations provide you with with full\\nFlex ability to integrate your agents\\nanywhere else so you can connect them to\\nyour own custom backends or any other\\ninternal software tools a key thing that\\nyou need to remember on this step is\\nthat your agent must be working in the\\nexact same systems that your employees\\nuse daily if your client uses slack to\\nchat with their data analyst agent then\\nintegrate this agent in slack as well\\nthis will make unboarding much simpler\\nafter you integrate your agent the next\\nstep is to iterate on it you see right\\nnow all agent development is an\\niterative process you will never get\\nyour agents right from the first attempt\\ntrust me so you need to be able to\\nadjust them as you go back when I\\nreleased our agency framework over a\\nyear ago I was personally managing and\\nsometimes even developing most of our\\nprojects initially we started to charge\\nper project just like with standard AI\\napps we used to build and although it\\nworked well at the start the problem\\nwith agentic projects is that they are\\nmuch more agile agentic projects are\\nhands down the most agile projects that\\nI've ever seen so what happened is that\\nany time we would start working on an\\nagent would immediately uncover more\\nopportunities we didn't realize were\\nthere or a better approach that we\\ninitially have not foreen before\\nprimarily because now we had access to\\nour clients and journal systems so we\\ncould see the business in and out so\\nwhen working with your clients you need\\nto ensure that you can adjust your\\nagents as you go this is why we now\\nentirely shifted to a new subscription\\nbased model which we still use to this\\nday this subscription approach lets us\\nto work as true partners with our\\nclients because honestly when you're\\nbuilding AI agents you're not just like\\na",
    "file_path": "playlist_1\\My AI Agent Blueprint to Fully Automate Any Business_yamHnWoOcM0.json",
    "file_size": 20061,
    "last_modified": "2025-04-18 15:34:04",
    "tags": [
     "agent",
     "agents",
     "and",
     "api",
     "are",
     "can",
     "client",
     "example",
     "json",
     "lang:pt",
     "like",
     "model",
     "my ai agent blueprint to fully automate any business_yamhnwoocm0",
     "number",
     "nyour",
     "our",
     "slack",
     "that",
     "the",
     "this",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "0d795e9988a47ea169721061953b844b",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 3,
     "total_chunks": 6,
     "processing_time": 0.022999048233032227
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 3,
    "total_chunks": 6,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "My AI Agent Blueprint to Fully Automate Any Business_yamHnWoOcM0_Part_5",
    "content": "software development shop you're more\\nlike a business growth agency so your\\ngoal isn't just to deliver agents it's\\nto help business ACC to scale so of\\ncourse it's completely fine to start\\nfrom one of projects because it's easier\\nto pit at the beginning but then once\\nyou get some momentum definitely make\\nsure to switch to a more flexible model\\nand once you've gathered some feedback\\nand adjusted your agent and now that\\nit's working well in your client's\\nbusiness the next way is to repeat you\\nsee today all businesses have way more\\npotential agent Integrations that they\\ncan even imagine literally any role\\ntoday can be replaced with an AI agent\\nit's just a matter of time and effort\\nbut if you try to automate too many\\nthings at once you will never succeed so\\nfor this I recommend using divide and\\nconquer approach first start with\\nautomating Sops then proceed to\\nautomating roles and then the\\nDepartments the key thing is that you\\nmust be automating the same roles and\\ndepartments first so don't switch\\nbetween different roles and departments\\ntoo much because the more a agents you\\nbuild for a single role or a department\\nthe more powerful they will become\\nunlike automations or workflows agents\\ncan collaborate together so after for\\nexample we've built a few agents in the\\nsame Department what we typically do is\\ncombine those agents like with a manager\\nagent and instantly the power of the\\nsystem 10xs now the manager agent can\\nuse the analysis provided by the analyst\\nagent and then coordinate with a\\nmarketing agent or a Content agent who\\ncan then take these insights and create\\na much better ad campaign or social\\nmedia post for example so after you've\\nsuccessfully deployed your first agent\\ndon't stop there go back to step two\\nwhich is find a problem and immediately\\nlook for additional Sops to solve within\\nthe same role or Department this is how\\nyou should proceed to automate and then\\nsimply keep repeating this process for\\nas long as you can try to stay with the\\nsame client for as long as possible\\nuntil again liter their business runs by\\nitself and after you've built several\\nagents preferably across even multiple\\nclients the last step is to productize\\nand scale by this point you will notice\\nsome patterns and similarities across\\nsome previous agents that you've built\\nthis is exactly where you have the\\nopportunity to transform them into a\\nmore scalable specialized vertical\\nsolution so for example in our agency we\\nbuilt many Facebook marketing agents in\\na fast for various companies so now we\\nare building a vertical Facebook\\nmarketing agent that can be reused\\nquickly and customized for any business\\nthis previous experience allowed us to\\nsee which components from the three\\nprimary agent components I mentioned\\nbefore remain constant and which need\\ncustomization but the best part is that\\nby productizing an agent you can then\\nImplement a more scalable outcome based\\npricing similar to how traditional\\nmarketing agencies operate for example\\nyou can charge per lead per client or\\nper appointment booked another Advantage\\nis that you are no longer starting from\\nscratch because you can improve the base\\nagent and instantly all of the clients\\nbenefit from these improvements as well\\nhowever don't try to create vertical\\nagents without first building a few\\nhorizontal custom agents first otherwise\\nyou'll just be shooting in the dark\\nwithout clearly understanding how this\\nagent should perform the process across\\nmultiple businesses you risk building\\nthings that no one is going to need so\\nsoon we'll be releasing a more practical\\ntutorial video on creating vertical\\nagents complete with a free vertical\\nagent template and in the meantime if\\nyou want to see how we build incredibly\\npowerful custom horizontal e agents that\\neven have memory and can self-improve\\ncompletely from",
    "file_path": "playlist_1\\My AI Agent Blueprint to Fully Automate Any Business_yamHnWoOcM0.json",
    "file_size": 20061,
    "last_modified": "2025-04-18 15:34:04",
    "tags": [
     "agent",
     "agents",
     "and",
     "business",
     "can",
     "client",
     "example",
     "first",
     "json",
     "lang:pt",
     "more",
     "my ai agent blueprint to fully automate any business_yamhnwoocm0",
     "nagent",
     "nyou",
     "that",
     "the",
     "then",
     "this",
     "vertical",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "0d795e9988a47ea169721061953b844b",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 4,
     "total_chunks": 6,
     "processing_time": 0.0240018367767334
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 4,
    "total_chunks": 6,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "My AI Agent Blueprint to Fully Automate Any Business_yamHnWoOcM0_Part_6",
    "content": "scratch I recommend\\nwatching this video next thank you and\\ndon't forget to subscribe\", \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\My AI Agent Blueprint to Fully Automate Any Business_yamHnWoOcM0.json\", \"tags\": [ \"My AI Agent Blueprint to Fully Automate Any Business\" ], \"source\": \"https://www.youtube.com/watch?v=yamHnWoOcM0\" }",
    "file_path": "playlist_1\\My AI Agent Blueprint to Fully Automate Any Business_yamHnWoOcM0.json",
    "file_size": 20061,
    "last_modified": "2025-04-18 15:34:04",
    "tags": [
     "agent",
     "any",
     "automate",
     "blueprint",
     "fully",
     "json",
     "lang:pt",
     "my ai agent blueprint to fully automate any business_yamhnwoocm0"
    ],
    "is_chunked": true,
    "content_hash": "0d795e9988a47ea169721061953b844b",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 5,
     "total_chunks": 6,
     "processing_time": 0.0240018367767334
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 5,
    "total_chunks": 6,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How to Create Agent Swarms With the NEW OpenAI Assistants API_8fMnAZI1bdA_Part_1",
    "content": "{ \"section_name\": \"How to Create Agent Swarms With the NEW OpenAI Assistants API\", \"content\": \"I have successfully recreated AutoGen from\\nscratch using just five or six functions with\\nthe new OpenAI Assistants API.\\nHere is their famous example, featuring a\\nchart of YTD, Meta, and Tesla stock prices,\\nthat was made by this system, consisting of\\njust 2 agents: a coding assistant and a user\\nproxy agent.\\nBut the best part is that this system is much\\nmore controllable and customizable, which\\nmeans unlike autogen, it is actually deployable\\nin production.\\nI will show you how you can easily add your\\nown agents at the end of the video, so make\\nsure to stay tuned for that.\\nLet s get started.\\nAlright, open the notebook open from the description,\\nand first, the only additional packages that\\nwe will need are are OpenAI and Instructor.\\nIf you haven t heard about instructor, this\\nis a library created by Jason Liu that allows\\nus to define OpenAI functions as pydantic\\nschemas.\\nThis is an absolutely genius way to do this,\\nbecause it is much more convenient than JSON,\\nand also provides additional features like\\ninput and output validation.\\nIt is the only library that I consistently\\nuse in production, and we actually recently\\nhad a call with Jason so hopefully we ll release\\nsome highlights soon.\\nWe will also create a small convenience function\\nto print wrapped text outputs.\\nNow, let me explain how the Assistant API\\nworks, because is quite different from the\\nprevious chat completions approach.\\nIn this new api, there are threads that represent\\nconversations, messages that represent individual\\nmessages within the threads, and agents that\\nexecute the threads to generate new messages.\\nI know it can be confusing.\\nSo, the general process is as follows:\\n1.\\nFirst, you have to create an agent.\\n2.\\nThen, you have to create a thread.\\n3.\\nNext, you have to add a message to the thread.\\n4.\\nAfter that, you have create a run for this\\nthread and agent ids.\\nThe big change here is that runs execute asynchronously,\\nso you have to continuously check for the\\nupdates until the run is finished.\\n5.\\nAnd finally, once that's done, if the run\\nis in completed status, the run goes into\\nrequires_action or completed status.\\nIf it s in completed it means that you safely\\nretrieve the thread with the new assistant\\nmessage, when if it s in requires_action,\\nit means that you have to run your function,\\npass the output back and run the thread again.\\nBut to simplify the entire process and make\\nit familiar for all of us who are used to\\nthe previous version of the OpenAI API, I\\nhave created a function called get_completion\\nthat essentially goes through all the steps\\nthat I have just described until the final\\nassistant response is received.\\nCheck out the doc string for more details,\\nbecause you might wanna copy this function\\nfor your own projects\\nNow let's go ahead and create our first code\\nassistant agent, which will be responsible\\nfor generating and executing code locally.\\nWe'll begin with the tools that this agent\\nwill utilize, defined with the instructor\\nlibrary.\\nThe first tool is `ExecutePyFile`, will rus\\nan existing Python file from the disk, taking\\nthe file name as a parameter.\\nIn the `run` function inside this model, we'll\\nexecute the file with Python 3 using the subprocess\\nmodule and capture any outputs.\\nOur second function, named `File`, serves\\nto write a file onto the disk for later execution.\\nAccurate function descriptions are crucial\\nhere; and as you can see by using the instructor\\nlibrary, you can define them directly in the\\ndocstrings or the field descriptions associated\\nwith each specific parameter, which is extremely\\nconvenient.\\nWe'll also add an additional parameter 'chain\\nof thought'.\\nThis is another ingenious technique introduced\\nby Jason Liu.\\nThis parameter forces the model to map out\\neach action, step by step before, proceeding\\nwith the function execution itself.\\nThis makes our agent more accurate on certain\\ncomplex tasks, without the need to use a chain\\nof thought",
    "file_path": "playlist_1\\How to Create Agent Swarms With the NEW OpenAI Assistants API_8fMnAZI1bdA.json",
    "file_size": 12476,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "agent",
     "and",
     "api",
     "are",
     "create",
     "have",
     "how to create agent swarms with the new openai assistants api_8fmnazi1bda",
     "json",
     "lang:pt",
     "model",
     "new",
     "nthe",
     "openai",
     "run",
     "that",
     "the",
     "this",
     "will",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "70da2567ed71a264f366dac3c03ded05",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 4,
     "processing_time": 0.059350013732910156
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How to Create Agent Swarms With the NEW OpenAI Assistants API_8fMnAZI1bdA_Part_2",
    "content": "prompt globally, as autogen does,\\nwhich significantly increases token usage\\nand latency in production.\\nNext, we'll add both of these functions into\\nan array to be used later in our get completion\\nfunction and create our code assistant using\\nthe new beta assistants API.\\nFor the instructions, we'll state that our\\ncode assistant is a top-tier programming AI\\nspecializing in creating precise Python scripts.\\nWe will also tell it to ensure that the code\\nis executed before providing a response to\\nthe user.\\nIn our case, the user interacting with the\\ncode assistant will actually be the user proxy\\nagent.\\nI decided to design this system by following\\na typical Cubernetes cluster architecture,\\nwhere the user proxy agent is essentially\\nacting as a load balancer that distributes\\nrequests to specialized individual agents\\nand converses with them until the task is\\nexecuted.\\nTherefore, the only tool that the user proxy\\nagent will need is a sendMessage tool to send\\nmessages to other agents.\\nIt has two parameters: a recipient and a message.\\nThe run call in this function actually calls\\nour previous method, getCompletion, with a\\nseparate thread for each agent, making our\\nsystem sort of recusrsive.\\nI say sort of because it has only one level\\nof recursion, after the main loop that also\\nuses the getCompletion function.\\nBut I actually believe that recursion is the\\nonly way to achieve AGI because everything\\nelse implies that we have to provide predefined\\nsteps to achieve the given task, which is\\nnot really general intelligence.\\nBesides, it is unlikely that you could change\\nthe behavior of a super intelligent agi simply\\nby switching the prompt or something.\\nOn the other hand, if this system is fully\\nrecursive, it means that it prompts itself\\nfrom the very start, and that's where I believe\\nthings get really fun.\\nI will show you later, as I said before, how\\nto create more agents.\\nIf this video gets a lot of views, I can turn\\nit into an open source project and try to\\ncreate an agent that creates other agents\\nand tools.\\nSo please like this video and share it if\\nthat's something you want to see.\\nTo ensure that our proxy agent has a separate\\nconversation with each of the other agents\\nin the group chat, we will store separate\\nthreads for each agent in a global object\\ncalled agents_and_threads.\\nFinally, we can define the user proxy agent\\nitself with some instructions that you can\\ncheck out on your own.\\nThe most important part here is that the user\\nproxy agent must maintain ongoing communication\\nwith other agents until the task is completed.\\nThis parameter has a huge impact on the behavior\\nof the whole system, so definitely make sure\\nto play around with that.\\nTo launch this system, simply create a new\\nthread and start an infinite loop that prompts\\nfor a user message, gets a completion from\\nthe user proxy agent and prints a response.\\nThat s it.\\nNow we re ready to test.\\nI ll run it with a famous example from Autogen\\nfor creating a graph of stock prices for Meta\\nand Tesla, starting with the first question:\\nwhat is today's date?\\nAs you can see, the user proxy agent immediately\\ncalls the code agent with a given task.\\nAlthough the first time might not get the\\nrecipient name right, it immediately corrects\\nitself, and then the code assistant starts\\nto execute the file function.\\nThe function calls are displayed in red color,\\nand the function outputs are displayed in\\nyellow.\\nAfter the code assistant agent writes the\\ncode to the file, it executes and returns\\nthe current date to the user proxy assistant,\\nwhich then prints it for us below.\\nSo in this conversation, the user proxy agent\\nconverses with other agents through the send\\nmessage function.\\nBasically when it needs to chat with another\\nagent, it calls this function with the message,\\nwhich the other agent than receives as",
    "file_path": "playlist_1\\How to Create Agent Swarms With the NEW OpenAI Assistants API_8fMnAZI1bdA.json",
    "file_size": 12476,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "agent",
     "agents",
     "and",
     "assistant",
     "code",
     "example",
     "how to create agent swarms with the new openai assistants api_8fmnazi1bda",
     "json",
     "lang:pt",
     "nand",
     "nthe",
     "other",
     "our",
     "proxy",
     "that",
     "the",
     "this",
     "user",
     "will"
    ],
    "is_chunked": true,
    "content_hash": "70da2567ed71a264f366dac3c03ded05",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 4,
     "processing_time": 0.0603485107421875
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How to Create Agent Swarms With the NEW OpenAI Assistants API_8fMnAZI1bdA_Part_3",
    "content": "the\\nuser message.\\nAfter the other agent responds, we pass it\\nback as the output of the send message function.\\nThis allows for a more natural conversation\\nflow, where the user proxy agent can chat\\nwith the other agents as much as needed directly\\nfrom the main chat with the user.\\nLet's try to run the second question.\\nCompare the year-to-date gain for Meta and\\nTesla.\\nNow the user proxy agent immediately asks\\nthe code assistant to provide the YTD gain,\\nand then the code assistant proceeds with\\ncreating the chain of thought prompt and writing\\nthe code itself.\\nAs you can see, it gets it on the first try\\nand returns the actual numbers using the yFinance\\nlibrary.\\nFor the final question let s ask the user\\nproxy to plot the stock price change and save\\nit to the stockpriceytd.png file.\\nAfter the Code Assistant executes the necessary\\ncode, the User Proxy confirms that the file\\nhas been successfully saved.\\nYou can verify this by browsing the files\\non the left.\\nAs you can see, the resulting graph looks\\nexactly like the one generated by AutoGen.\\nHowever, our system actually did in far less\\ntokens wasted.\\nNevertheless, there are a few things that\\nyou can still improve, which I m gonna discuss\\nnext.\\nFirst of all, the current system does not\\nsupport conversations between the agents that\\nexecute the tasks.\\nIt only supports the conversation between\\nthe user proxy with these agents.\\nThis is not necessarily a bad thing; however,\\nbecause this improves the overall steerability\\nof the system and helps to prevent infinite\\nloops.\\nHowever, you can easily adjust this, by adding\\nmore threads into the agent_and_threads object\\nand also allowing other agents to use the\\nsendMessage function.\\nSecond, sometimes, it feels like the user\\nproxy agent doesn't fully understand the instructions.\\nI've experimented with the prompt for a bit,\\nbut it could certainly use some improvement.\\nAnd third, as I said before, you could actually\\nmake a tool for the user proxy agent that\\nwould allow it to create other agents and\\ntools.\\nIf you actually manage to do this, I believe\\nit could lead to exponential growth and a\\ncomplete humanity extinction in the next few\\nmonths.\\nNow, adding new agents to this system is pretty\\nstraightforward.\\nFirst, create the tools the agent will use\\nwith the Pydantic schemas using Instructor.\\nYou can simply copy the code for the code\\nassistant agent, replacing any tools as needed.\\nThen, add this new agent to the agents and\\nthreads object and create the assistant using\\nthe new beta assistants API.\\nYou can also include out-of-the-box tools\\nlike web browsing and code interpreter, but\\nnote that the code interpreter can't execute\\nlocal files and has limitations.\\nAfter creating your new agent, add its name\\nto the recipient literal in the send message\\nfunction and describe what this agent should\\ndo in the property description.\\nThen, after running all the cells again, run\\nthe main loop, and your second task execution\\nassistant should now be operational.\\nIn conclusion, the best thing about creating\\ncustom agent swarms with the assistants API\\nis that they're actually usable in production.\\nUnlike other multi-agent systems, here you\\nhave complete control over the creation of\\nnew agents and tools.\\nYou can easily add any guardrails for you\\nspecific use case or even implement any custom\\nlogic, making this system easily steerable\\nand adaptable.\\nFor instance, I decided to design this example\\nwith the Single Responsibility Principle in\\nmind.\\nThis is a common practice for building scalable\\nsystems, and it implies that each component\\nshould have only one specific responsibility,\\nwhich allows for easy addition of more components\\nor replacement of the existing ones in case\\nof any errors.\\nSo let me know in the comments if you still\\nthink that AGI will be achieved with one",
    "file_path": "playlist_1\\How to Create Agent Swarms With the NEW OpenAI Assistants API_8fMnAZI1bdA.json",
    "file_size": 12476,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "agent",
     "agents",
     "and",
     "can",
     "code",
     "how to create agent swarms with the new openai assistants api_8fmnazi1bda",
     "json",
     "lang:pt",
     "nand",
     "nthe",
     "nyou",
     "other",
     "proxy",
     "that",
     "the",
     "this",
     "user",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "70da2567ed71a264f366dac3c03ded05",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 4,
     "processing_time": 0.0603485107421875
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How to Create Agent Swarms With the NEW OpenAI Assistants API_8fMnAZI1bdA_Part_4",
    "content": "super\\nintelligent model or rather by scaling thousands\\nof smaller agents together.\\nAnd lastly, for those who need help building\\ncustom agent swarms like this for their own\\npurposes, feel free to reach out to me.\\nThank you for watching, and don't forget to\\nsubscribe.\", \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\How to Create Agent Swarms With the NEW OpenAI Assistants API_8fMnAZI1bdA.json\", \"tags\": [ \"How to Create Agent Swarms With the NEW OpenAI Assistants API\" ], \"source\": \"https://www.youtube.com/watch?v=8fMnAZI1bdA\" }",
    "file_path": "playlist_1\\How to Create Agent Swarms With the NEW OpenAI Assistants API_8fMnAZI1bdA.json",
    "file_size": 12476,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "agent",
     "assistants",
     "create",
     "how",
     "how to create agent swarms with the new openai assistants api_8fmnazi1bda",
     "json",
     "lang:pt",
     "model",
     "new",
     "openai",
     "swarms",
     "the"
    ],
    "is_chunked": true,
    "content_hash": "70da2567ed71a264f366dac3c03ded05",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 3,
     "total_chunks": 4,
     "processing_time": 0.0603485107421875
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 3,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How to Build an AI GitHub Code Analysis Agency_NKrAECt9AZo_Part_1",
    "content": "{ \"section_name\": \"How to Build an AI GitHub Code Analysis Agency\", \"content\": \"Hey, in this video, we're going to create\\na GitHub code analysis agency that will analyze\\nyour code according to your standard operating\\nprocedures and will leave analysis comments\\non your pull requests.\\nThis is an example of a non-standard AI agent\\nautomation that runs only on the backend and\\nallows you to significantly increase the efficiency\\nof your operations.\\nEven in our agency, we recently released a\\nnew feature on our SaaS platform that allows\\nyou to create those custom GPT apps, white\\nlabel them, add multiple agents and control\\nuser access.\\nBut the problem is that as our code base continues\\nto grow and we keep adding more and more features,\\nit becomes increasingly harder to scale.\\nThis is where SOPs or Standard Operating Procedures\\ncome in.\\nIf all your developers follow the same code\\nquality standards, it becomes much easier\\nfor your team to collaborate and add new features.\\nAnd secondly, I have personally received more\\nthan 5 requests for this exact AI solution\\nfrom various businesses around the world.\\nSo it seems like there is a real need for\\nthis solution across large corporations.\\nBesides, it is a great use case to get started\\nwith because you can build upon it and even\\nadd additional capabilities.\\nLike for example, you can make your agents\\nactually fix the problematic code and then\\npush it on GitHub as well.\\nSo let's see how this works.\\nOkay, so this is my agency here on the left\\nthat I created in this video and it consists\\nof three agents, the CEO, the code analyzer,\\nand the report generator agent.\\nInside the code analyzer agent instructions,\\nI'm providing the code quality standards that\\nthis agent must adhere to.\\nSo let's try to break them.\\nHere's a function to create a chat name automatically\\nafter a user sends the first message.\\nSo let's try to modify this.\\nSay for example I made an error and instead\\nof calling the DB class, I updated the document\\nin Firestore directly with the new chat name.\\nNow I'm going to push these changes on GitHub.\\nAfter I've pushed these changes, I'm now going\\nto create a new pull request.\\nAwesome, so now as you can see, we've triggered\\nour agency on GitHub actions automatically,\\nwhich means that they're currently running\\nand analyzing our code base for any code quality\\nissues.\\nPerfect, so then as you can see, we get the\\ncode quality report on our pull request that\\nidentifies the exact issue I have just created\\nwith the direct Firestore call.\\nIt even specifies the file path and some details\\nlike that the DB collections interface was\\nnot properly used to ensure encapsulation\\nand maintainability.\\nIt even provides a recommendation that to\\nadhere to our code quality standards, it is\\nrecommended that all Firestore interactions\\nmust be refactored to use the DB Collections\\ninterface.\\nThis will ensure that our codebase remains\\nclean, maintainable, and in compliance with\\nour encapsulation policies.\\nSo now let's see how you can make this agency\\nyourself.\\nFor everyone who's new, please make sure to\\ninstall Agency Swarm with pip install agency\\nswarm and then to get started much faster\\nyou can run agency swarm genesis command.\\nThis is how I personally start all of my projects\\nbecause the genesis agency will create all\\nthe agent folders and tools for you.\\nOf course it does not get everything right\\non the first attempt just yet but it does\\nspeed up the process significantly.\\nWhen chatting with the genesis agency make\\nsure to clarify what your mission is, what\\nyour goals are, what tools or APIs you want\\nto utilize, and how many agents you want to\\ncreate.\\nAlso include the communication flows between\\nyour agents.\\nIn my prompt, I'm just going to say that I\\nneed a code analysis agency with three agents,\\nand \\nthe Report Generator agents.\\nIt does take some time for your agents to\\nbe created, so we're going to skip this part\\nand I'll see you again when we are ready to\\nfine-tune this agency.\\nWe will have three agents, the CEO",
    "file_path": "playlist_1\\How to Build an AI GitHub Code Analysis Agency_NKrAECt9AZo.json",
    "file_size": 11151,
    "last_modified": "2025-04-18 15:34:02",
    "tags": [
     "agency",
     "agents",
     "and",
     "can",
     "code",
     "example",
     "github",
     "how",
     "how to build an ai github code analysis agency_nkraect9azo",
     "json",
     "lang:pt",
     "nand",
     "nthis",
     "our",
     "that",
     "the",
     "this",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "b2f04fa4bf12cac28e1476209d5d1e84",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 3,
     "processing_time": 0.07784843444824219
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 3,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How to Build an AI GitHub Code Analysis Agency_NKrAECt9AZo_Part_2",
    "content": "who will\\ninitiate the communication that will fetch\\nall of the changes from the GitHub, and the\\nreport generator agent that will create comments\\non our pull requests and highlight any problematic\\nlines of code.\\nOkay, as you can see, we now got the GitHub\\npull request fetcher tool, which uses GitHub\\nAPI to get all the changes from the pull request,\\nwhich is already super helpful because it\\nsaved me a lot of time on browsing GitHub\\nAPI documentation and writing all of this\\nboilerplate code.\\nIn the meantime, I'll start working on the\\nagency instructions because this is where\\nyou can really tailor the agency for your\\nspecific process in your company.\\nOkay, awesome.\\nSo now the agency creation process is complete\\nand we can see all the agent files here on\\nthe left with the tools defined accordingly.\\nThe best part is how close the tools are to\\nwhat I actually wanted to implement myself.\\nSo now all we have to do is just adjust these\\ntools accordingly.\\nTo test your tool, what you can do is simply\\nadd if name equals main at the end of the\\ntool file and then hard code the parameters\\nwhen initializing this tool.\\nThen simply execute\\nthe run method inside the print statement.\\nThe pull request idea I'm also going to hard-code\\nfor now just for testing, but in the production\\nenvironment we will use GitHub event to get\\nthis dynamically.\\nOkay, so after I have adjusted this tool we\\nare finally ready to test it.\\nSimply run this file and then you should get\\na response from the GitHub API right here.\\nAwesome, now as you can see on the pull request\\nwe get a comment which was created by myself\\nvia API.\\nSo then we also need to adjust and test the\\nGitHub pull request etcher tool.\\nOkay, it seems like our agent wanted to keep\\nonly the TypeScript files, because this is\\nthe way I defined my prompt when I was chatting\\nwith the Genesis agency.\\nBut for this tutorial, I do want it to analyze\\nall of the files and see all of the file changes,\\nwhich is why I'm basically getting the file\\nname and then listing all of the changes accordingly\\nand then returning them from this tool.\\nSo if we run this tool, as you can see, we\\nnow get a list of all of the file changes\\nthat includes the file name and then all of\\nthe lines that were changed in this pull request.\\nSo we are now almost ready to test this whole\\nagency.\\nLiterally, I just adjusted two tools and we\\nare almost there.\\nIt's incredible how much of the work was done\\nby the Genesis agency for me.\\nSo what I'm going to do next is adjust all\\nof the instructions and define our code quality\\nstandards just so our agent knows what to\\nlook at when analyzing those files.\\nSo I already have this standard operating\\nprocedure for how to work on our project backends\\nright here.\\nAnd basically, I'm just going to copy and\\npaste some of the checklist items into the\\ninstructions for the Code Analyzer agent.\\nBecause this is an integration that will be\\nrunning solely on the backend, we actually\\ndon't need to run the demo gradio or the run\\ndemo commands because our agency will essentially\\nbe triggered by a pull request on GitHub.\\nSo what we can do instead is simply use the\\nagency.getCompletion method with a simple\\nprompt like please analyze the code and generate\\na report.\\nSo let's test it out.\\nOkay, cool.\\nSo after we launched our agency, you can see\\nall the threads appear in the terminal.\\nSo you can click on them and check out the\\nconversations between your agents.\\nFor example, here we can see how the code\\nanalyzer agent just used the pull request\\nfetcher tool and got all of the file changes.\\nAwesome.\\nSo then the agency get completion method returns\\nthat the analysis of the TypeScript codebase\\nhas been completed, and we can even actually\\nadd a link to the issue comment, which we\\ncan check out like this.\\nNow the only thing left to do is just",
    "file_path": "playlist_1\\How to Build an AI GitHub Code Analysis Agency_NKrAECt9AZo.json",
    "file_size": 11151,
    "last_modified": "2025-04-18 15:34:02",
    "tags": [
     "agency",
     "all",
     "and",
     "api",
     "can",
     "code",
     "documentation",
     "github",
     "how to build an ai github code analysis agency_nkraect9azo",
     "json",
     "lang:pt",
     "nso",
     "our",
     "pull",
     "request",
     "see",
     "test",
     "the",
     "this",
     "tool",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "b2f04fa4bf12cac28e1476209d5d1e84",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 3,
     "processing_time": 0.07884669303894043
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 3,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "How to Build an AI GitHub Code Analysis Agency_NKrAECt9AZo_Part_3",
    "content": "deploy\\nthis agency in production and make sure it\\nruns on every pull request automatically.\\nHowever, to run this agency live, we need\\nto replace the hard-coded pull request number\\nwith the pull request which triggered the\\naction.\\nTo do so, I basically chatted with ChatGPT\\nand figured out that GitHub uses GitHub event\\npath environment variable to store all of\\nthe information about the event that triggered\\nthis action.\\nSo, what we can do is simply parse this file\\nand then extract the pull request ID just\\nlike that.\\nThen we can use this pull request ID inside\\nour URL.\\nI'm going to do the same in the report generator\\ntool.\\nSo now that our agency is ready for deployment\\nwhat we can do is simply copy the whole agency\\nfolder and then drop it into our OpenAI widget\\nproject repository.\\nAdd all of the files to GitHub and don't forget\\nto also add an environment file with your\\nOpenAI key and the GitHub token.\\nThen I'm going to create a new workflow which\\nwill essentially just trigger this agency\\nand run it on the back end.\\nTo do so, I'm simply going to tell ChargePT\\nto create a basic GitHub workflow file that\\nexecutes a Python file.\\nThen I'm going to copy this file and paste\\nit inside our repository.\\nAwesome, so now that our agency and the workflow\\nfiles are done, we can simply push this code\\nto GitHub.\\nAfter that, I'm going to intentionally break\\none of the files just so we can test this\\nworkflow.\\nSo now that I pushed this code, I'm going\\nto create a pull request to trigger the agency.\\nPerfect.\\nSo now as you can see, our action has been\\nexecuted on the backend and we should see\\nthe analysis report right here.\\nAnd it indeed states that the Firestore direct\\naccess violation was detected and that the\\ncall to Firestore database was not done through\\nthe DB collections class as I have specified\\nin my standard operating procedures.\\nIt also provides some recommendations on how\\nto fix this.\\nHonestly, this is incredibly helpful.\\nI'm probably actually going to run this on\\nalmost every single project from now, so we\\ncan always keep track of our code quality\\nstandards and ensure that there are no issues\\nbefore we merge any pull requests.\\nLike always, all of the code will be on my\\nnew agency swarm lab repository where you\\ncan directly copy this agency and use it for\\nyour own code base with your own standard\\noperating procedures or even tailor it for\\na different process.\\nLike, for example, you can even make it generate\\ncode and fix those issues and then commit\\nthem on GitHub as well, or even leave comments\\non the specific lines of code where the problems\\nwere encountered and then commit them on GitHub\\nas well, or even leave comments on the specific\\nlines of code where the problems were encountered\\nusing GitHub API.\\nThank you for watching and don't forget to\\nsubscribe.\", \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\How to Build an AI GitHub Code Analysis Agency_NKrAECt9AZo.json\", \"tags\": [ \"How to Build an AI GitHub Code Analysis Agency\" ], \"source\": \"https://www.youtube.com/watch?v=NKrAECt9AZo\" }",
    "file_path": "playlist_1\\How to Build an AI GitHub Code Analysis Agency_NKrAECt9AZo.json",
    "file_size": 11151,
    "last_modified": "2025-04-18 15:34:02",
    "tags": [
     "agency",
     "and",
     "can",
     "code",
     "database",
     "file",
     "github",
     "going",
     "how to build an ai github code analysis agency_nkraect9azo",
     "json",
     "lang:pt",
     "now",
     "nto",
     "our",
     "pull",
     "request",
     "test",
     "that",
     "the",
     "this"
    ],
    "is_chunked": true,
    "content_hash": "b2f04fa4bf12cac28e1476209d5d1e84",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 3,
     "processing_time": 0.07884669303894043
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 3,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "I Built an AI Web Development Agency to Do the Work for Me_X3Ff2MRz0Eo_Part_1",
    "content": "{\n    \"section_name\": \"I Built an AI Web Development Agency to Do the Work for Me\",\n    \"content\": \"In this video, I'm going to show you how I create \\ncustom AI agent teams to do the work for me. \\nSpecifically in this tutorial, we will create \\na custom AI agency that develops responsive web  \\napplications using Next.js and Material UI. But \\nthe best part about this tutorial is that most of  \\nthe work was actually done by AI rather than by \\nmyself. Yes, almost anyone can now create their  \\nown custom AI agent teams just by chatting with \\nthe Genesys Agency that creates your agents for  \\nyou. So whether you are an AI developer or an \\nentrepreneur, this video will show you how to  \\ncreate those custom agent swarms for your or \\nyour client's business. Let's dive in. Okay,  \\nso let's check this out live. Let me know what \\nyou guys think about the new format. And now  \\nyou can basically use the Genesys agency directly \\nfrom your CLI to get started much faster. Simply  \\nrun agency swarm genesis command and this will \\nactivate the Genesys agency directly in your  \\nterminal. So then you can just say like I need \\na web development agency. So I've prepared this  \\nprompt in advance and I'm just going to say that \\nthe goal is to develop responsive web applications  \\nusing Next.js and MUI, which is what we use in \\nour agency, and that the CEO must communicate  \\nwith the designer, who communicates with the \\nweb developer and copywriter, and then I'm  \\nalso describing which tools each agent must use. \\nPerfect, so now it proposes the initial structure  \\nfor my agency exactly like I described with the \\nGenesys CEO, who communicates with the designer,  \\nwho then communicates with the web developer and \\ncopywriter. It also defines some initial goals,  \\nmission, processes for my agency, and then asks \\nme to confirm if this aligns with my vision which  \\nit does so I'm just going to tell it to proceed. \\nAwesome so first the Genesy CEO creates the agency  \\nfolder for my agency which you can see right here \\non the left with the agency manifesto and then it  \\nproceeds with telling the agent creator to create \\nthe first agent. After the designer agent has been  \\ncreated, which you can also see on the left, it \\nproceeds with telling the tool creator agent to  \\ncreate tools for this agent. As you can see, the \\ntool creator then creates the first tool, which is  \\nthe browser analysis tool, which uses beautiful \\nsoup. By default, we might want to adjust this  \\nlater, but so far it looks pretty good. It then \\nproceeds with testing the tool, but as you can  \\nsee it encounters an error because non-type \\nobject has no attribute loader I suppose this  \\nis because the beautiful soup is not installed \\nyet. So let's see what happens next Okay,  \\nit then tells the agent creator that there was an \\nerror which it then tells the CEO agent Then the  \\nCEO agent tells the agent creator to create the \\nnext agent, which is the web developer agent's  \\ninstructions. The first tool that it creates is \\ncalled the directory navigator tool and as you can  \\nsee it just simply uses the OS change dir method \\nwhich is probably how I would implement this tool  \\nas well. And then it also creates a file reader \\ntool which simply opens the file using Python,  \\nreads the content and then returns it. This \\nactually looks pretty good already so I don't  \\nthink there are even any modifications required \\njust yet. And then it also creates the FileWriter  \\ntool, which takes the file path, the content as a \\nstring, and then it opens this file, and then it  \\ndoes the confirmation as the tool output. Then it \\ntells the agent creator that all of the tools were  \\nsuccessfully created. One tool we didn't check out \\nis a comment executor tool, which uses subprocess  \\nwith the command. This could be dangerous, so \\nwe might want to modify this later. Perfect! So  \\nnow the Genesys CEO tells me that the WebCrafters \\nagency has been successfully established.",
    "file_path": "playlist_1\\I Built an AI Web Development Agency to Do the Work for Me_X3Ff2MRz0Eo.json",
    "file_size": 15704,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "agency",
     "agent",
     "and",
     "can",
     "creates",
     "creator",
     "i built an ai web development agency to do the work for me_x3ff2mrz0eo",
     "json",
     "lang:pt",
     "nthe",
     "that",
     "the",
     "then",
     "this",
     "tool",
     "tutorial",
     "web",
     "which",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "02988bf8c078de3634e4a59d7a523a24",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 4,
     "processing_time": 0.05508708953857422
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "I Built an AI Web Development Agency to Do the Work for Me_X3Ff2MRz0Eo_Part_2",
    "content": "However,  \\nit seems like the Genesys CEO forgot to create the \\nCopywriter agent, but now we can easily fix this  \\nwith the new mentions feature that I have added \\nto this framework. Now, when creating your agency,  \\nyou can add multiple agents as the entry points \\nfor communication. So, in the top level array,  \\nyou can now include multiple agents, not just \\nthe CEO agent, and then the user will be able  \\nto communicate directly with those agents. The \\nway you use this tool is simply add an add sign  \\nand then name the agent that you want to talk \\nwith, followed by the message to this agent. So  \\nI'm going to say to the agent creator instead of \\nthe Genesy CEO, which speeds up the communication  \\nflow. So now the agent creator tells me that the \\ncopywriter agent has been created, and you can  \\nsee it on the left with the instructions files \\ndefined accordingly. Then the CEO tells me that  \\nwe can run this agency with the python agency.py. \\nCool, so now it opens up a link with the Gradio. \\nFirst of all, you can now upload files. You \\ncan select which agent you are talking with,  \\nbut as I said before, you do have to add those \\nagents right here. So if you add like another  \\nagent like this in the top level array, you will \\nbe able to communicate with it as well directly. \\nSo let me rerun the agency.py command with the \\ndesigner in the top level array as well and  \\njust show you how this works. All right, cool. \\nSo now as you can see in the recipient agent,  \\nyou can also select the designer, not just the \\nCEO agent, and then let's just try to say hi,  \\nfor example. Cool, so now we get the response from \\nthe designer directly. But before we actually run  \\nthis agency and try to create our first website, \\nwe do need to make a few adjustments because I  \\ncertainly do not want the web developer agent to \\nexecute any commands on my PC. So let's quickly  \\ngo through all of these tools starting with the \\nweb developer and then adjust them accordingly. \\nSo the command executor tool I'm going to rename \\ninto simply run command. Then I'm going to define  \\nall of the commands that this agent can run in \\nadvance. This way we can ensure that our agent  \\ndoes not execute anything unexpected. For the \\ncommands field I'm going to define a couple of  \\noptions using the literal type. The first one will \\nbe build and the second one will be create next  \\napp. Then I'm going to adjust the execution \\nlogic to execute only certain commands based  \\non the input from the agent So if the command is \\ncreate next app We're just going to run npm create  \\nnext app and if the command is built we're going \\nto run npm run build So this tools directory is  \\na new addition to my framework where essentially \\nall the tools folder when initializing your agent. \\nAdditionally, don't forget to rename the file so \\nit matches the name of your tool, otherwise it  \\nwill not be imported. So the rest of the tools for \\nthe web developer agent actually look pretty good,  \\nbut I do want to add one extra tool that would \\nallow this agent to browse the current directory  \\nand see what files are inside. I'm gonna call \\nthis tool ListDir. This tool will essentially  \\njust take a dir path and then return the current \\ndirectory tree as a string. And finally, I also  \\nwant to modify the browser analysis tool for the \\ndesigner agent because I do not want this agent  \\nto read the whole HTML of the webpage since HTML \\ncontains a lot of useless information. Instead,  \\nI want to use a tool similar to the one \\nI've created in my browsing agent video,  \\nthat will take the screenshot of the current web \\npage and then analyze it with GPT-4V.",
    "file_path": "playlist_1\\I Built an AI Web Development Agency to Do the Work for Me_X3Ff2MRz0Eo.json",
    "file_size": 15704,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "add",
     "agent",
     "and",
     "can",
     "going",
     "i built an ai web development agency to do the work for me_x3ff2mrz0eo",
     "json",
     "lang:pt",
     "not",
     "now",
     "run",
     "that",
     "the",
     "then",
     "this",
     "tool",
     "will",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "02988bf8c078de3634e4a59d7a523a24",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 4,
     "processing_time": 0.056085824966430664
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "I Built an AI Web Development Agency to Do the Work for Me_X3Ff2MRz0Eo_Part_3",
    "content": "So how this  \\ntool will function is it will open the local host \\nURL with the 3000 port where the next application  \\nwill be hosted, then it will get the screenshot \\nof the current browser window and use GPT-4V with  \\na special prompt to analyze this screenshot. So \\nthe designer agent will be able to use this tool  \\nto check if the current web page aligns with the \\nprovided design. Now let's go ahead and adjust  \\nsome instructions for our agents. For example, \\nI want to ensure that the web developer agent  \\nunderstands that it first needs to surf the web \\npage before submitting the work to the designer  \\nso the designer can analyze it later. I'm just \\ngoing to include this in the primary tasks. Okay,  \\nso finally we're ready to test this. To run your \\nagency, simply execute the agency.py file. In the  \\nfirst message, I'm just going to say that I need a \\nnew website for my AI development agency, ArsenAI. \\nThen the CEO immediately tells the designer agent \\nto create a compelling copy and the design for my  \\nagency. Awesome so now we get a complete copy for \\nmy new website with a cool headline, Relationizing  \\nYour Business Through AI Development and a copy \\nfor each section. What's funny is that it actually  \\nends on the exact same phrase that I have on my \\ncurrent website, which is, ready to transform  \\nyour business? Cool, so then the CEO agent wants \\nto confirm if this design aligns with my vision,  \\nwhich it does, so I'm going to tell it to proceed \\nwith the development. Obviously, this is just my  \\nprompt. You can adjust the instructions for each \\nagent accordingly. In my case, I was constantly  \\niterating on the system, running those agents, and \\nadjusting the instructions and tools accordingly  \\nuntil this agency performed the tasks as I \\nexpected. As you can see now, the web developer  \\nagent gets the first task to develop the hero \\nsection, and then it executes the first command  \\nto create Next.js application, which we should \\nnow see on the left. Yes, so as you can see,  \\nwe now got the arson.ai folder with some Next.js \\nboilerplate code. And then the agent proceeds with  \\ninstalling some additional requirements, which \\nare material UI emotion and emotion style. This  \\nis because in my agency manifesto I said that I \\nwant to use material UI for the development. Okay  \\ncool so now our agent created the first component \\nin the components folder with our copy unleash the  \\npower of artificial intelligence. Then it should \\nproceed with importing this component into the  \\nindex.tsx file as you can see right here. Then \\nit builds our application and reports back to  \\nthe designer who then sends a new section for \\nthe development. We can also check the progress  \\nlocally if we navigate into our new Next.js app \\ndirectory and then run the development server with  \\nnpm run dev command. Awesome. So this is what our \\nwebsite looks like right now. It seems like we're  \\nstill using Next.JS styles, but we can fix this \\nlater. The next section that our agent has just  \\ncreated is our mission section, which you can \\nalso see in the components folder on the left. \\nIt also uses some icons from material UI icons \\npackage. However, it seems like the build fails,  \\nbecause currently this package is not installed. \\nSo then, WebDeveloper performs the next command  \\nto install material UI icons package, which is \\nnow added into the package. JSON, then the app  \\nbuilds successfully. Okay, pretty cool. I mean, \\nyeah, we're getting somewhere. The next section  \\nthat our designer sends to the WebDeveloper is \\nexpertise across industries section with, you  \\nknow, some basic layout, visual elements and text \\ncontent. Awesome, so we got this new component  \\nwith also some icons from Material UI.",
    "file_path": "playlist_1\\I Built an AI Web Development Agency to Do the Work for Me_X3Ff2MRz0Eo.json",
    "file_size": 15704,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "agent",
     "and",
     "can",
     "designer",
     "development",
     "i built an ai web development agency to do the work for me_x3ff2mrz0eo",
     "json",
     "lang:pt",
     "next",
     "now",
     "nto",
     "our",
     "section",
     "server",
     "test",
     "that",
     "the",
     "then",
     "this",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "02988bf8c078de3634e4a59d7a523a24",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 4,
     "processing_time": 0.056085824966430664
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "I Built an AI Web Development Agency to Do the Work for Me_X3Ff2MRz0Eo_Part_4",
    "content": "Okay, as \\nyou can see, the expertise is now also added to  \\nour LinkedIn page. Let's check it out. Oops, so we \\nhave to rebuild the website apparently. All right,  \\nso this is what we got now. Seems like there are \\nsome issues with styling, but we can probably  \\nfix this later. Awesome, now finally the web \\ndevelopment agent creates the final section,  \\nwhich is the footer section with some contact \\ninformation and then it also adds it to the  \\nindex.tsx file. So now we have this nice footer \\nand our landing page is pretty much complete. \\nI mean, I understand that it's not quite there \\nyet, but the fact that this whole landing page  \\nwas developed by AI, that in fact, was created \\nby another AI, that's pretty cool. And actually,  \\nwe can make it much better just by adding some \\nthemes from Material UI. Awesome, so the styling  \\nof our website already looks much better. The \\ncolors seem to be fixed, and the only problem that  \\nI can still see right here is that the contact \\nsection is kind of broken and the button should  \\ndefinitely not be here so let's just ask our web \\ndeveloper with fixing this final section. So then  \\nthe CEO tells that the client has reported that \\nthe layout of the contact us section is still  \\nbroken. It's funny that it actually refers to \\nme as to a client because of how we defined the  \\nagency manifesto. Awesome, so now it seems like it \\nrewrote the whole contact us section and now it is  \\nusing a grid which is a responsive component from \\nmaterial UI, which means that most likely our app  \\nis now going to look much better. It's pretty cool \\nthat you can use this agency kind of like as your  \\npair programmer and just converse back and forth \\nwith it and at the same time work on those files. \\nAs you can see it again runs into a build issue. \\nIt seems like it inappropriately used the change  \\nlines tool. And here, as you can see, actually in \\nthis run command tool, I'm including some special  \\ninstructions at the end of the function output \\nin case if the command fails. And specifically,  \\nI'm telling this agent to rewrite the entire \\nfile with the file writer tool in case if it  \\ngets stuck. So I found that providing those \\ninstructions, depending on specific conditions  \\nin your tools, allows you to much better \\ncontrol your system. So as you can see now,  \\nit rewrites the whole file just as I instructed \\nand then builds the web application. Perfect. So  \\nthis is what our website looks like now. As you \\ncan see, the styling is much better. The form is  \\nalso not broken any longer. The Contact Us text \\nis below the ready to transform your business  \\ntext just as I requested. And let's see if this \\nis actually responsive. Yep, as you can see,  \\nthe whole application is pretty much responsive. \\nThere are some issues with styling, but of course,  \\nyou can fix this pretty fast. So yeah, all the \\ncode for this agency will be on a new repository  \\nthat I created on GitHub called Agency Swarm \\nLab. In this repository, we will keep adding  \\nmore and more agencies created with Agency Swarm \\nfor various use cases. So if you have any cool  \\nuse cases that you've made before, feel free to \\ncontribute. So if you have any cool use cases that  \\nyou've made before, feel free to contribute. Thank \\nyou for watching and don't forget to subscribe.\",\n    \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\I Built an AI Web Development Agency to Do the Work for Me_X3Ff2MRz0Eo.json\",\n    \"tags\": [\n        \"I Built an AI Web Development Agency to Do the Work for Me\"\n    ],\n    \"source\": \"https://www.youtube.com/watch?v=X3Ff2MRz0Eo\"\n}",
    "file_path": "playlist_1\\I Built an AI Web Development Agency to Do the Work for Me_X3Ff2MRz0Eo.json",
    "file_size": 15704,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "agency",
     "and",
     "can",
     "client",
     "contact",
     "i built an ai web development agency to do the work for me_x3ff2mrz0eo",
     "json",
     "lang:pt",
     "like",
     "much",
     "now",
     "our",
     "section",
     "see",
     "that",
     "the",
     "this",
     "web",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "02988bf8c078de3634e4a59d7a523a24",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 3,
     "total_chunks": 4,
     "processing_time": 0.05708575248718262
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 3,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Mastering the Agency Swarm Framework Advanced Features Revealed_AZlPelcATHo_Part_1",
    "content": "{ \"section_name\": \"Mastering the Agency Swarm Framework Advanced Features Revealed\", \"content\": \"in this video we're going to go over\\nsome of the most advanced and most\\nuseful features of my agency SW\\nframework as I have noticed most of you\\nguys are not even utilizing 70% of its\\npotential so here's what we're going to\\ngo over today first I'll show you how to\\nuse a synchronous mode properly both for\\nthe agents and as introduced in the\\nlatest release for the tools this can\\nspeed up your agents and make them up to\\nfour times faster then we'll proceed\\nwith parallel tool calling a new feature\\nboth in open AI assistance API and in my\\nframework after that we'll discuss\\nAdvanced agent parameter in techniques\\nlike f shot learning response validators\\nfine tune models and more then we'll\\ndiscuss how to properly convert open API\\nschemas into tools which is hands down\\nthe most underrated feature in my\\nframework and lastly I'll show you how\\nto run open source models with Astra\\nassistance API in just 5 minutes yes\\nyou've heard that right now with Astra\\nassistance API it only takes you three\\nlines of code to set up my framework\\nwith any open- Source models so if\\nyou're serious about AI agent\\ndevelopment let's dive\\nin okay before we get started I just\\nwanted to let you know that we're still\\nlooking for technical project managers\\nand AI agent developers to join our team\\nso if you think you have all the\\nnecessary qualifications then you can\\napply using the links below now let's\\njump into the notebook you will find\\nthis collab notebook in the description\\nplease make sure to open and follow the\\ntutorial along with me this will allow\\nyou to learn all of these Concepts much\\nfaster the first step like always is to\\ninstall the packages I'm going to be\\ninstalling it from a special branch that\\nI'm currently using to develop the new\\nfeatures but by the time you watch this\\nvideo you should have already the new\\nversion released then like always just\\ndrop your opening a key into the cell\\nbelow okay now we're ready to get going\\nso here's the first exercise which is\\nthe asynchronous mode right now we have\\ntwo options the first mode is called\\nthreading so if you set a synchronous\\nmode to threading it means that each\\nagent will run in a separate thread\\nlet's see an example let's Define a\\nsimple my Custom Tool then let's define\\ntwo agents just as an example a CEO and\\nan essay writer and then let's set up\\nthe agency itself awesome the next step\\nis to run the demo command so we can use\\nthis agency directly in this collab\\nnotebook as you can see I set the asnc\\nmode to threading so whenever the COO\\nsends a message to the essay writer it\\nno longer has to wait for the response\\nthe essay writer will now be running in\\na separate threat and the CEO can check\\nthe response later this is extremely\\nuseful when you have agents that output\\nextremely long text so for example here\\nyou know the essay right WR is\\ninstructed to write comprehensive and\\nwell researched essays meaning that the\\noutput will likely contain a large\\namount of tokens so let's try this out\\nI'm just going to say to the CEO please\\nwrite a comprehensive essay about AI as\\nyou can see it then sends the message to\\nthe essay writer but now instead of the\\nCEO having to wait for the response it\\ntells me that the task of writing a\\ncomprehensive essay about AI has started\\nthis means that now you you can tell the\\nCEO to execute some other tasks for\\nexample now I can tell the CEO to use\\nthe Custom Tool as you can see while the\\nessay writer is still writing the essay\\nthe COO can now use this tool and then\\ntell us what the output is so now in\\norder for us to get the final essay all\\nwe have to do is just to remind the COO\\nto check the response from the essay\\nwriter so then as you can see the C\\nrelays this full and comprehensive essay\\nwritten by the essay writer while the\\nCEO was responsible for executing some\\nother tasks amazing right okay let's\\nstop the sell and now let me show you a\\nnew method called tools trading",
    "file_path": "playlist_1\\Mastering the Agency Swarm Framework Advanced Features Revealed_AZlPelcATHo.json",
    "file_size": 22553,
    "last_modified": "2025-04-18 15:34:00",
    "tags": [
     "and",
     "api",
     "can",
     "essay",
     "example",
     "going",
     "have",
     "json",
     "just",
     "lang:pt",
     "mastering the agency swarm framework advanced features revealed_azlpelcatho",
     "now",
     "nthe",
     "that",
     "the",
     "then",
     "this",
     "writer",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "68788f3e354feb7761a2adc37196f24f",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 7,
     "processing_time": 0.04309678077697754
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Mastering the Agency Swarm Framework Advanced Features Revealed_AZlPelcATHo_Part_2",
    "content": "because\\noften times you might not want your\\nagents to run in separate threats\\ninstead when you have some extremely\\ncomplex tasks that are heavily dependent\\non the tools rather than on agent\\noutputs you might want the tools to run\\nin separate threats instead so this is\\nwhy I added this new tools threading\\nmethod in the latest release let's try\\nanother example\\nI'm going to set up another Custom Tool\\nand another agent called Co again with\\nthis tool so the agency this time is\\njust going to contain One agent which is\\nthe CEO and first we're going to run\\nthis agency without any async mode just\\nso we can time the execution and then\\njust so we can compare it with the tools\\ntrading mode so my message to the agent\\nwill be to use two another custom tools\\nat the same time so it means that now\\nthis agent will try to execute the\\nanother Custom Tool twice and as you can\\nsee inside this tool we have time sleep\\nset to 25 seconds which means that this\\ntool execution will take at least 25\\nseconds to complete yes so as you can\\nsee we now have this final execution\\ntime which as I said 53 seconds because\\nthe agent was required to execute this\\ntool twice now let's try the same tool\\nbut with the new tools trading method\\nagain we're using the same prompt used\\nto another custom tools at the same time\\nwhich means that the agent will execute\\nthis tool twice but now those tools will\\nrun in separate\\nthreads yes so now as you can see the\\nexecution time is only 28 seconds which\\nis already twice the speed now imagine\\nif you have four of these tools\\nobviously this can be crucial in\\nproduction because increasing the\\nlatency even by 10% is extremely\\nimportant when here we were able to\\nincrease it two times simply by setting\\na sync mode to Tool trading however keep\\nin mind that the trading modes do have\\nsome limitations for CPU bound tasks so\\nwhenever those tools require heavy CPU\\nusage like if you're doing some\\nprocessing you can run into some issues\\nwith the performance however when you\\nhave input output bound tasks like if\\nyou are waiting for an API response then\\ntrading mode can be extremely useful in\\nthe future I will of course also add the\\nmultiprocessing mode for even more\\ncomplex tools but this might take some\\ntime okay the next feature that was\\nrecently introduced in opening API is\\ncontrol for parallel tool calls so yeah\\nas you can see here open AI again\\nsilently introduced this new parameter\\ncalled parallel tool calls so if you set\\nparallel tool calls to false essentially\\nyour agent will be forced to call each\\ntool sequentially while if you set it to\\nTrue which is the default the agent will\\nbe able to call multiple tools and\\nexecute them at once so let's try an\\nexample with the same agent with one\\nanother Custom Tool and parallel tool\\ncalls false I'll use again the tools\\ntrading mode which as you might recall\\ntook us around 28 seconds to complete\\nlet's run the same prompt to use to\\nanother custom tools at the same time\\nand time it\\nagain yes so as you can see now the wall\\ntime is 55 seconds even though we're\\nusing the tools trading mode so let's\\nlook at this threat on open AI as you\\ncan see the agent indeed called two\\ntools but now because the parallel tool\\ncalls mode was set to false the agent\\ncalled them sequentially rather than two\\nat the same time even though the prompt\\ndid say that it needs to call them\\ntogether awesome however there are some\\ninstances when you might want only a\\ncertain tool to run sequentially when\\nall other tools must be executed\\ntogether so for this I added another\\nspecial one call at a time parameter\\ninto the base tool class so let's try\\nthis with a pre-made agent example I'm\\ngoing to import agent David with the\\nagency SW import agent command now as\\nyou can see our agent David will appear\\nhere on the left it has a few tools",
    "file_path": "playlist_1\\Mastering the Agency Swarm Framework Advanced Features Revealed_AZlPelcATHo.json",
    "file_size": 22553,
    "last_modified": "2025-04-18 15:34:00",
    "tags": [
     "agent",
     "api",
     "can",
     "custom",
     "example",
     "json",
     "lang:pt",
     "mastering the agency swarm framework advanced features revealed_azlpelcatho",
     "mode",
     "now",
     "run",
     "same",
     "that",
     "the",
     "this",
     "time",
     "tool",
     "tools",
     "will",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "68788f3e354feb7761a2adc37196f24f",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 7,
     "processing_time": 0.04409527778625488
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Mastering the Agency Swarm Framework Advanced Features Revealed_AZlPelcATHo_Part_3",
    "content": "that\\nhave developed for software development\\nlike for example file writer tool I\\nbelieve uses one call at a time because\\nthe agent first needs to know what was\\nwritten to one file before it can\\nproceed to writing another file so as\\nyou can see here I'm setting one call at\\na time to true and this means that the\\nagent will be forced to wait for the\\nfirst execution to finish until it can\\nproceed to using this tool again while\\nas I said all other tools can still run\\nin parallel okay so let's try with a\\nsimpler example I'm going to create two\\ntools for a CSV sheet agent the first\\ntool is going to be called create CSV\\nsheet tool and another tool will be\\ncalled fi Row in CSV tool so basically\\nthe first tool as you can see creates\\nthe CSV file and then saves the CSV file\\npath to Shared State again guys please\\ndon't forget about shared State shared\\nState can be extremely useful to check\\nfor example certain order of operations\\nin your agency or save certain important\\ninformation to prevent hallucinations\\nand translated between those tools so as\\nyou can see here basically the F Row in\\nCSV tool doesn't ask for the file name\\nand instead it checks the file from the\\nshared State and if this file does not\\nexist as you can see it returns a value\\naror so then the agent is going to see\\nthis arrow and it will be forced to\\ncreate the CSV file first all right\\nlet's initialize this agent and try an\\nexample prompt so I'm going to tell it\\nto add any row to the CSV file\\nlet's check the thread on open AI yeah\\nand as you can see it first tries to\\ncall fill in CSV tool but it runs into a\\nvalidation error because the CSV file\\ndoes not exist so then it is forced to\\ncreate the file first and only then it\\ncan fill out this CSV sheet then it just\\ntells me the response that it added a\\nfew rows which look something like this\\nobviously guys this is a very simple\\nexample but it's extremely useful in\\nproduction right now the biggest problem\\nthat PR events Mass adoption of AI\\nagents is hallucinations and when you\\ncan check State between certain tool\\nexecutions it allows you to make your\\nsystem a lot more reliable okay so now\\nI'm going to run another prompt and tell\\nthis agent to fill in two more rows at\\nthe same time okay let's check the\\nthread and by the way make sure to\\nselect the correct project because if\\nyou try to view the thread for an API\\nkey and you're currently using a\\ndifferent project you're not going to be\\nable to see those messages okay so\\nhere's my prompt as you can see the\\nfirst function execution was successful\\nbut the second one returned an nrow\\nbecause the FI Row in CSV tool is\\nalready called so then the agent was\\nforced to add in the rows one by one\\njust like this awesome now let's get to\\nthe next section which is Advanced agent\\nparameters and techniques so first of\\nall we have few short learning even when\\ncreating agents please don't forget that\\nlarge language models are a few short\\nLearners so often times it's much easier\\nto provide a few good examples\\nrather than work for hours on a prompt\\nhere for example I'm going to be doing a\\nbasic customer support agent and I want\\nit to always respond with certain emojis\\nso instead of instructing it to do so\\nI'm simply going to include a few\\nexamples where this agent responds with\\nEmojis as you can see we got a few very\\nbasic questions that a customer support\\nagent might encounter like for example\\nyou know the features of certain\\nproducts or statuses of orders and by\\nthe way you can also insert additional\\ninformation in Fusion examples so the\\nagent will be able to actually retain\\nthis information and use it later as\\nwell but here we're going to use it for\\na basic style transfer so as you can see\\nmy agent has no instructions whatsoever\\nand I'm basically just initializing this\\none agent in the agency and",
    "file_path": "playlist_1\\Mastering the Agency Swarm Framework Advanced Features Revealed_AZlPelcATHo.json",
    "file_size": 22553,
    "last_modified": "2025-04-18 15:34:00",
    "tags": [
     "agent",
     "and",
     "can",
     "csv",
     "example",
     "file",
     "first",
     "going",
     "json",
     "lang:pt",
     "mastering the agency swarm framework advanced features revealed_azlpelcatho",
     "nthe",
     "one",
     "see",
     "the",
     "then",
     "this",
     "tool",
     "view",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "68788f3e354feb7761a2adc37196f24f",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 7,
     "processing_time": 0.04509234428405762
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Mastering the Agency Swarm Framework Advanced Features Revealed_AZlPelcATHo_Part_4",
    "content": "then asking\\nanother very basic customer support\\nquestion all you have to do to add few\\nshort examples to the agent is simply\\nuse the examples parameter inside the\\nagent class keep in mind that all the\\nparameters in my framework follow the\\nexact same format as on open AI API\\nawesome as you can see the agent then\\nprovides me with some instructions and\\nat the end it includes emojis because it\\nsaw all of those previous examples where\\nwe also include similar emojis even\\nthough the instructions for this agent\\nare empty okay next we have response\\nvalidators so response validators is\\ndefinitely one of the most advanced\\nfeatures in my framework because it\\nallows you not just to validate the\\ninputs and outputs of the tools but also\\nthe messages returned by your agents so\\nobviously there is always a chance that\\nthe agent will hallucinate and won't\\nreturn the required emojis which is a\\nsignificant violation of our customer\\nsupport service policy which is why we\\ncan add this responsibly data and\\nexplicitly check whether any of those\\nemojis are in the message and then if\\nnot we can return a value aror saying\\nthat the response does not contain\\nrequired emojis the agent will then see\\nthis arrow and correct itself\\naccordingly let's see how it\\nworks awesome as you can see it then\\nreturns us another message with even\\nmore emojis than before and if we look\\nat this thread we're going to see that\\nif the first time the agent hasn't\\nreturned any emojis like here it's going\\nto see another message by the user even\\nthough I didn't send any message with\\nour Arrow so the arrow is response does\\nnot contain any required emojis which is\\nwhy it then proceeds to printing the\\nresponse with uh a lot more emojis as\\nrequested awesome next we have fine tune\\nmodels so I'm not going to go and test\\nthese parameters below because you can\\ndo it yourself really fast basically if\\nyou have any fine tune models you can\\nnow use them with open assistance API so\\nsimply replace the model parameter with\\nyour fine tune model name and then\\ninstead of providing few short examples\\nthe model will always generate responses\\nin your style then we have file search\\nconfig which is again a new parameter\\nthat open AI has silently released and\\nessentially it allows you to control the\\nconfiguration for the file Search tool\\nright now only the max number results\\nparameter is available inside this\\nconfiguration and it allows you to set\\nthe maximum number of results that the\\nfile Search tool should output so if you\\nset 20 it means it's going to return 20\\nchunks while if you set 50 it's going to\\nreturn 50 chunks it works in my\\nframework in exact same way under the\\nagent class you will find this parameter\\nand you can set this number between 1\\nand 50 and lastly we have some more\\nadvanced tration parameters that allow\\nyou to Define for example how long the\\noutputs from the agent must be and also\\nhow much context the agent is going to\\nuse to generate a response so if we set\\nmax prom tokens parameter to\\n248 the agent will only respond up to\\n248 tokens and then the response will be\\ncut off if you set max completion tokens\\nto anything like 16,000 it means that\\nonly up to 16,000 of tokens will be used\\nin the conversation history to generate\\nthe next response additionally we also\\nhave transcation strategy which defines\\nhow the messages are tranced by the\\ndefault it's set to Auto which is a\\nspecial truncation strategy used by open\\nAI where they keep the beginning of the\\nconversation and the end but they remove\\nthe middle messages and lastly we also\\nhave a response format parameter which\\ncan be set to Json object with this\\nparameter on the agent will always\\nrespond in Json however keep in mind\\nthat to use it you also have to include\\nin instructions that the agent must\\nalways respond in Json okay the",
    "file_path": "playlist_1\\Mastering the Agency Swarm Framework Advanced Features Revealed_AZlPelcATHo.json",
    "file_size": 22553,
    "last_modified": "2025-04-18 15:34:00",
    "tags": [
     "agent",
     "and",
     "api",
     "can",
     "emojis",
     "example",
     "have",
     "json",
     "lang:pt",
     "mastering the agency swarm framework advanced features revealed_azlpelcatho",
     "model",
     "parameter",
     "response",
     "set",
     "that",
     "the",
     "then",
     "this",
     "which",
     "will",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "68788f3e354feb7761a2adc37196f24f",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 3,
     "total_chunks": 7,
     "processing_time": 0.04509234428405762
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 3,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Mastering the Agency Swarm Framework Advanced Features Revealed_AZlPelcATHo_Part_5",
    "content": "next\\nfeature that I'm going to show you is\\nhow to convert open API schemas into\\ntools basically you can do this in two\\nways you can either specify a schemas\\nfolder when creating your agent and then\\ndrop any schemas into this folder all of\\nthose schemas will then automatically be\\nconverted into tools if your schema\\nrequires authentication you can set the\\nAPI headers parameters or other API\\nparameters accordingly then all you have\\nto do is just initialize the agent and\\nrun it it will then automatically have\\naccess to your API Additionally you can\\nuse tool Factory class for this you can\\nuse from open API schema method and even\\nfetch it with requests if your schema is\\nhosted somewhere online and likewise\\nprovide headers and parameters\\naccordingly so here you might be\\nwondering what's so cool about this and\\nwhy is it like such a groundbreaking\\nfeature compared to all other Frameworks\\nand the answer is because tool Factory\\nactually converts all of those schema\\ninto base tools with instructor so this\\nmeans that these tools are all type\\nchecked based on your open API schema\\ndefinition so doesn't matter how complex\\nyour schema is how many different\\nparameters you have all of them will be\\nautomatically converted into instructor\\nbased tools this means that your agent\\nwill check all of these parameters\\nbefore calling the API so instead of the\\nagent first calling the API like it\\nhappens on custom gpts or on all other\\nFrameworks and then getting an arrow\\nback and then trying to correct itself\\nit will check all the parameters first\\nso if it provides any incorrect\\nparameter it will receive an arrow\\nbefore it calls the API which allows you\\nto significantly reduce production\\nerrors and lastly we have some Advanced\\nparameters for backend Integrations\\ninside the get completion method so get\\ncompletion method is how you get you\\nknow the response from the agency and\\nhere you can specify a few things first\\nyou can specify the recipient agent so\\nif the primary point of communication in\\nyour agency as a CEO you can still\\nspecify it to some other agent like\\nDavid and then it will receive the\\nmessage then we also have additional\\ninstructions so additional instructions\\nare instructions that will be appended\\nto your agent only during the execution\\nof this run this is extremely useful for\\nany session or user specific information\\nlike for example if you know you want\\nyour agent to know something about the\\ncurrent user who's using this system\\nadditional instructions is the place\\nwhere this information should be and\\nlastly we also have tool Choice tool\\nChoice allows you to force your agents\\nto call a specific function so for\\nexample here as you can see I'm forcing\\nthe agent deit to call the file writer\\ntool and finally let me show you how to\\nrun my framework in just 5 minutes with\\nany open source models using Astra\\nassistance API so Astra assistance API\\nwas developed by data stacks and\\nessentially it's a drag and drob\\nreplacement for open assistance API make\\nsure to give him a star on GitHub so\\nlet's install asra assistance API with\\npeopleon stall and then what you need to\\ndo next is simply grab the Astra DB\\napplication tokens so follow this Link\\nlogin with your account and then you'll\\nbe taken to the aster DB dashboard I'm\\nnot even affiliated with them but you\\nknow the pricing is extremely cheap and\\nthey do still provide a huge free\\nquarter which is more than enough for\\nyou to get started go to tokens page and\\nthen create a new token for organization\\nadministrator click generate a token and\\nthen copy the third value which is the\\ntoken value that starts with Astra CS\\ntake this token run the next cell and\\nplace it below next insert all of the\\nAPI keys that you want to use for third\\nparty model providers so here I'm going\\nto use perplexity anthropic together",
    "file_path": "playlist_1\\Mastering the Agency Swarm Framework Advanced Features Revealed_AZlPelcATHo.json",
    "file_size": 22553,
    "last_modified": "2025-04-18 15:34:00",
    "tags": [
     "agent",
     "all",
     "and",
     "api",
     "can",
     "example",
     "have",
     "json",
     "lang:pt",
     "mastering the agency swarm framework advanced features revealed_azlpelcatho",
     "model",
     "nto",
     "open",
     "schema",
     "that",
     "the",
     "then",
     "this",
     "will",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "68788f3e354feb7761a2adc37196f24f",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 4,
     "total_chunks": 7,
     "processing_time": 0.04609346389770508
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 4,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Mastering the Agency Swarm Framework Advanced Features Revealed_AZlPelcATHo_Part_6",
    "content": "and\\nGro you can add more providers as needed\\nnext all you have to do to set this up\\nwith my framework is simply patch the\\nopena client with a special patch method\\nfrom Astra assistant and then replace it\\nwith the set open a client method now as\\nyou can see the open a client will now\\ncommunicate to Astra assistance API then\\nlike always all you have to do is just\\ncreate your agents but replace the model\\nnames with whatever models you want to\\nuse so for example here I'm going to\\ncreate a Grog agent that uses Lama 3 and\\nadditionally I'm going to create a claw\\n3 agent that uses anthropic all of the\\nother parameters like files folder are\\nalready supported by asra assistance API\\nso you can add it like this create a\\nfiles folder on the left drop your files\\nand then the agent will be able to\\nprovide responses based on the file\\ncontext all right let's run the demo\\ngradio method and see how it works cool\\nso now let's ask the gro agent what llm\\nis here awesome so then it tells us that\\nit was indeed developed by meta AI\\nAdditionally you can also run asra\\nassistance API with AMA fully locally\\nfor this make sure to check out Astra\\nopen source swarm directory on GitHub\\nwhere someone from data Stacks team will\\nkindly added this new example for how to\\nrun local models with AMA so the first\\nstep is to install all of the\\nrequirements from the asra open source\\nSW directory simply create a virtual\\nenvironment and then run peep install\\ndasr requirements.txt\\nthen copy the n.",
    "file_path": "playlist_1\\Mastering the Agency Swarm Framework Advanced Features Revealed_AZlPelcATHo.json",
    "file_size": 22553,
    "last_modified": "2025-04-18 15:34:00",
    "tags": [
     "agent",
     "all",
     "and",
     "api",
     "astra",
     "can",
     "client",
     "create",
     "example",
     "json",
     "lang:pt",
     "mastering the agency swarm framework advanced features revealed_azlpelcatho",
     "method",
     "now",
     "open",
     "that",
     "the",
     "then",
     "this",
     "will",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "68788f3e354feb7761a2adc37196f24f",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 5,
     "total_chunks": 7,
     "processing_time": 0.04609346389770508
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 5,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Mastering the Agency Swarm Framework Advanced Features Revealed_AZlPelcATHo_Part_7",
    "content": "backup file and rename\\nit into simply do n here you can insert\\nall of the foundational model provider\\nAPI keys that you want to use also don't\\nforget to add your Aster DB application\\ntoken on top then open the docker\\ncompost file the docker compost file\\nwill pull a couple images here the first\\none will be for AMA and the second one\\nfor data Stacks Astra assistance API to\\nrun locally however if you have already\\ninstalled AMA previously you can simply\\ncommend the AMA image and then run\\nDocker compose\\nappd awesome as you can see both\\ncontainers have started so the last step\\nis to simp run python agency or\\nL.P awesome as you can see we can now\\nopen the same link again and let's ask\\nthe co agent to ask the Llama agent what\\nllm is it so then as you can see the\\nLlama agent indeed tells our CLA coo\\nthat it's using llama model amazing so\\nyeah that's it basically for the\\nadvanced features of my framework a lot\\nmore advanced features like\\nobservability and more async modes are\\ncoming shortly so make sure to subscribe\",\n    \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\Mastering the Agency Swarm Framework Advanced Features Revealed_AZlPelcATHo.json\",\n    \"tags\": [\n        \"Mastering the Agency Swarm Framework Advanced Features Revealed\"\n    ],\n    \"source\": \"https://www.youtube.com/watch?v=AZlPelcATHo\"\n}",
    "file_path": "playlist_1\\Mastering the Agency Swarm Framework Advanced Features Revealed_AZlPelcATHo.json",
    "file_size": 22553,
    "last_modified": "2025-04-18 15:34:00",
    "tags": [
     "advanced",
     "agency",
     "agent",
     "ama",
     "and",
     "api",
     "can",
     "features",
     "file",
     "framework",
     "json",
     "lang:pt",
     "mastering the agency swarm framework advanced features revealed_azlpelcatho",
     "model",
     "see",
     "simply",
     "swarm",
     "the",
     "then",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "68788f3e354feb7761a2adc37196f24f",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 6,
     "total_chunks": 7,
     "processing_time": 0.04609346389770508
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 6,
    "total_chunks": 7,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "The Best Way to Deploy AI Models (Inference Endpoints)_VdKdQYduGQc_Part_1",
    "content": "{ \"section_name\": \"The Best Way to Deploy AI Models (Inference Endpoints)\", \"content\": \"Choosing the right deployment option for your\\nmodel can have a significant impact on the\\nfuture of your AI application.\\nIf you've ever worked with open-source models,\\nyou know that training a model is just the\\nbeginning.\\nAfter investing time and effort into perfecting\\nyour creation, choosing the right deployment\\noption can make or break its success.\\nIt's a decision that needs careful consideration,\\nbecause it can have a significant impact on\\ncost, latency, scalability, and more down\\nthe line.\\nSo, in this video, I will demystify the most\\npopular deployment options, specifically focusing\\non serverless deployment and guide you through\\na complete exercise for deploying open-source\\nmodels from Hugging Face, so you unlock the\\nfull potential of your AI models.\\nLet's dive in!\\n# **Understanding the Tradeoffs: Different\\nDeployment Options**\\nFirst, we need to start with a brief overview\\nof the most popular deployment options, which\\nare cloud based, on premise edge and a new\\nserverless alternative.\\nCloud-based deployment means hosting and running\\nyour AI models on a virtual network of servers\\nmaintained by third-party companies such as\\nAWS, Google Cloud, or Microsoft Azure.\\nIt offers scalability and low latency, allowing\\nyou to quickly scale up or down based on demand\\nwhile providing very fast responses.\\nHowever, once an instance is up and running,\\nyou're paying for it whether it's in use or\\nnot.\\nThis means that hosting a model in the cloud\\ncan cost at least few hundred dollars per\\nmonth.\\nModels that are larger and require multiple\\nGPUs can be significantly more expensive,\\neven if you only submit one request per day.\\nThis is why I recommend this option only for\\nmid-sized projects that maintain consistent\\nmodel usage throughout the [day.IT](http://day.IT)\\nOF\\nOn-premise, on the other hand, deployment\\ninvolves hosting and running your AI models\\non your own physical servers.\\nThis gives you total control over your infrastructure,\\nwhich can be particularly appealing for businesses\\nwith significant resources or strict data\\nprivacy and security requirements.\\nDespite that it requiresd substantial upfront\\ninvestment for hardware, without recurring\\nsubscription fees, it could be more cost-effective\\nthan cloud based deployment in the long term.\\nNevertheless, due to the complexity of managing\\non-premise infrastructure, this option is\\nonly recommended for enterprises or large-scale\\nprojects with significant investments.\\nAs for the edge deployment, it means deploying\\nmodels directly on edge devices like smartphones\\nand IoT.\\nThis method allows for real-time or low-latency\\npredictions and enhances user privacy as data\\nis processed on the device instead of being\\nsent to a central server.\\nHowever, it may not be appropriate for complex\\nmodels that require significant computational\\npower.\\nThis is why a new solution has recently emerged\\nthat aim to address all these challenges at\\nonce: on-demand serverless model deployment.\\n# Serverless Deployment: An Efficient Solution\\nBasically, instead of maintaining and paying\\nfor idle servers, serverless deployment allows\\nyou to focus more on core product development\\nwhile enjoying the benefit of reduced operational\\ncosts and complexity.\\nAt the core of this approach is the power\\nof containerization coupled with an intuitive\\ninterface.\\nYou deploy your model inside a container and\\nthe clock only ticks when your model is in\\naction.\\nThis means that if your model is idle, you\\nare not being charged with anything.\\nYou only pay for the time your model is actually\\nrunning, down to the GPU seconds, which makes\\nthis option is perfect for for applications\\nin the early stages or those with a smaller\\nuser base.\\nHowever, one downside of serverless systems\\nis the \\\"cold start\\\" issue, which occurs when\\na serverless function is put to sleep or \\\"made\\ncold\\\" by the provider to save resources if\\nit hasn't been invoked for some time.\\nWhen a request",
    "file_path": "playlist_1\\The Best Way to Deploy AI Models (Inference Endpoints)_VdKdQYduGQc.json",
    "file_size": 8436,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "and",
     "can",
     "deployment",
     "guide",
     "json",
     "lang:pt",
     "model",
     "models",
     "more",
     "nthis",
     "nyou",
     "option",
     "serverless",
     "significant",
     "that",
     "the",
     "the best way to deploy ai models (inference endpoints)_vdkdqydugqc",
     "time",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "66fc6325717f354aed05e8dfcbecc69d",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 3,
     "processing_time": 0.0317535400390625
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 3,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "The Best Way to Deploy AI Models (Inference Endpoints)_VdKdQYduGQc_Part_2",
    "content": "comes in after this period\\nof inactivity, the function has to be \\\"warmed\\nup\\\", causing a slight delay in response time.\\nAs for the providers themselves, there are\\nseveral options like Replicate, Bento ML,\\nBeam, and AWS, which also recently introduced\\nthis feature.\\nHowever, in this tutorial, we will focus on\\nthe fastest and simplest option for serverless\\nmodel deployment: inference endpoints provided\\nby Hugging Face.\\n# **A Practical Walkthrough: Deploying a Model\\nfrom Hugging Face**\\nIn this exercise, we will deploy a fine tuned\\nFalcon-7B-Instruct model with QLoRA adapters\\nfrom one of my previous tutorials, but you\\ncan use the same process for almost any open\\nsource model on hugging face.\\nThe first step is to save the pretrained model\\nitself.\\nI added additional code at the end of the\\nnotebook for that previous video, which essentially\\nmerges LORA adapters with the original model\\nweights and pushes them to a new repository\\non hugging face.\\n~~After uploading your model, copy the special\\nfiles required to run your model like configuration_RW.py,\\nmodelling_RW.py, config.json, and [handler.py](http://handler.py/).~~\\n~~If you want to run your model in 8-bit,\\nensure that you set load_in_8_bit to true\\nin the [handler.py](http://handler.py/) file.\\nAdditionally, add trust_remote_code for both\\nthe model and the tokenizer.\\nYou will find the full code for this file\\nat the end of fine tuning notebook from previous\\nvideo.~~\\n~~Next, create a requirements.txt file and\\nadd any packages that you used during fine\\ntuning.~~\\n~~Keep in mind, that these steps are only\\nnecessary if you fine-tuned your model with\\na technique like Qlora beforehand.\\nIf you want to run a default model from Hugging\\nFace, you can skip these steps, and simply\\ndeploy from your original model’s repository.~~\\nAfter completing the above steps, you are\\nalmost halfway there.\\nTo finish, click on \\\"Inference Endpoints\\\"\\nunder \\\"Deploy\\\" and select your desired deployment\\noptions.\\nTo make your endpoint serverless, change the\\nautomatic scaling from \\\"never\\\" to \\\"0\\\" after\\n15 minutes.\\nHowever, keep in mind that this approach will\\nalso introduce the cold start problem we discussed\\nearlier.\\n~~Now, if you added requirements.txt or any\\nother additional files, select a default container\\ntype, otherwise keep it on text generation\\ninference, or on your model’s default task.~~\\nNow, simply click create endpoint and after\\na few minutes your model should be live.\\nTest it a few times using the web interface,\\nand if everything is working as expected,\\nyou are ready for production.\\nTo call this endpoint from your application,\\nyou can use the Hugging Face inference Python\\nclient.\\nTo begin, install Hugging Face Hub and import\\nthe inference client.\\nSpecify your endpoint URL and obtain your\\nAPI token from settings.\\nThen, specify the generation parameters and\\ncall the text generation method.\\nMake sure to adjust the last method according\\nto your specific model type.\\nIf you want to stream responses, set the streaming\\nparameter to True.\\n# Conclusion\\nOverall, the future trends in AI model deployment\\npoint towards the most flexible approaches.\\nAs there has been a shift in backend development\\ntowards serverless and microservices in recent\\nyears, I believe that this shift will also\\nextend to model deployment.\\nThe only current limiting factor is the \\\"cold\\nstart\\\" problem, which is challenging due to\\nthe large sizes of model weights.\\nHowever, I am sure that we will soon see substantial\\nimprovements in this area as well.\\nRecent rumors even suggest that OpenAI is\\nconsidering opening an app store for AI models,\\nwhich might be quite similar to inference\\nendpoints on hugging face.\\nSo, let me know your thoughts on the future\\nof model deployment.\\nHave you already tried deploying your own\\nmodels to production?\\nIf so,",
    "file_path": "playlist_1\\The Best Way to Deploy AI Models (Inference Endpoints)_VdKdQYduGQc.json",
    "file_size": 8436,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "after",
     "and",
     "are",
     "deployment",
     "face",
     "hugging",
     "inference",
     "json",
     "lang:pt",
     "model",
     "nthe",
     "nto",
     "that",
     "the",
     "the best way to deploy ai models (inference endpoints)_vdkdqydugqc",
     "this",
     "will",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "66fc6325717f354aed05e8dfcbecc69d",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 3,
     "processing_time": 0.03275251388549805
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 3,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "The Best Way to Deploy AI Models (Inference Endpoints)_VdKdQYduGQc_Part_3",
    "content": "which options have you selected?\\nAnd as always, if you want to learn more about\\nleveraging the power of AI, don't forget to\\nsubscribe.\", \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\The Best Way to Deploy AI Models (Inference Endpoints)_VdKdQYduGQc.json\", \"tags\": [ \"The Best Way to Deploy AI Models (Inference Endpoints)\" ], \"source\": \"https://www.youtube.com/watch?v=VdKdQYduGQc\" }",
    "file_path": "playlist_1\\The Best Way to Deploy AI Models (Inference Endpoints)_VdKdQYduGQc.json",
    "file_size": 8436,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "best",
     "deploy",
     "endpoints",
     "inference",
     "json",
     "lang:pt",
     "models",
     "the",
     "the best way to deploy ai models (inference endpoints)_vdkdqydugqc",
     "way",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "66fc6325717f354aed05e8dfcbecc69d",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 3,
     "processing_time": 0.03275251388549805
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 3,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Replacing my Agency with an Agent Swarm…_M5Pa0pLgyYU_Part_1",
    "content": "{ \"section_name\": \"Replacing my Agency with an Agent Swarm…\", \"content\": \"In this video I am presenting my own open\\nsource agent orchestration framework called\\nagency swarm.\\nThe main goal of this project is to replace\\nmy own AI Development agency with an Agent\\nSwarm in the next few months.\\nI have already started using this framework\\nin production for my own clients, and I am\\nexcited to see where you guys are gonna take\\nit next.\\nSo if you are ready to push the boundaries\\nof AI as far as they can currently can go,~~\\nlet's get started.\\nThe framework is fully based on the new OpenAI\\nAssistants API, because I believe that OpenAI\\nis likely to introduce a lot more capabilities\\nto this API soon.\\nBut before I explain what it and and how you\\ncan use it, let me clarify what it is not.\\nFirst of all, it is not a collection of premade\\ntools or templates like langchain.\\nYou can not just import an agent, drop it\\ninto your code editor and then immediately\\nhave a ready-to-go app.\\nThis might seem convenient in the beginning,\\nbut the problem is that as soon as you need\\njust a tiny bit of customization, you are\\nessentially trapped within their code, making\\nit almost impossible to tailor your app for\\nyour specific use case.\\nSecond, this is not a research a experiment\\nlike autogen.\\nYou see, systems like autogen require huge\\nhidden prompts deep within their code in order\\nfor them to function properly.\\nSo, what usually happens in production is\\nthat your prompts start to conflict with these\\nhidden prompts, and then it makes the whole\\nsystem almost impossible to steer.\\nOn the other hand, in my framework there is\\nnot a single prompt that you do not have control\\nover.\\nAnd third, this not a way for you to make\\na million dollars without lifting a finger,\\njust yet.\\nAlthough this frameworks abstracts the most\\ncomplex details, you do have to set your agents\\nup yourself.\\nYou have to provide them with the necessary\\nknowledge, instructions and tools.\\nThen you have to define how they will communicate\\nwith one another.\\nI do plan to create an agency that can create\\nother agencies in the future, but more on\\nthis later.\\nIf you want to learn more details, I left\\na link to a custom GPT that knows everything\\nabout my project in a description.\\nBut for now, let s go ahead and try to recreate\\nmy own AI development agency.\\nOkay, open the notebook in the description,\\nand run the install cell to install agency_swarm\\nfrom my github.\\nI will post it on pip as soon as I am confident\\nthat there will not be any major breaking\\nchanges.\\nIf you find any issues, feel free to open\\nthem on github.\\nThe first agent that we are going to create\\nwill be a CEO, who is myself.\\nAs we are still a very small agency, I am\\nessentially responsible for all the client\\ncommunication, planning and task assignment,\\nso this is exactly what I am going to say\\nin the agent description.\\nThis description plays a crucial role in my\\nframework, because it will used by other agents\\nto determine who to communicate with.\\nIf we compare this to autogen, they have an\\nextremely strange speaker selection process,\\nwhere they essentially emulate role play for\\nthe agents and ask them who should speak next\\nwith an extra call to the model.\\nOn the other hand in this system, the whole\\ncommunication flow is handled through a special\\nsend message tool, so there is no need for\\nany extra prompts or any extra calls.\\nYour agents will determine themselves who\\nto communicate through function calling with\\nbased on their own descriptions.\\nFor the instruction, you can either import\\nit from a file or simply provide it as a string.\\nMake sure to play with these for your specific\\nuse case.\\nIf you have any documents, you can upload\\nthem to a folder in files on the left, and\\nthen insert your folder path into the files_folder\\nparameter.\\nAfter that your files will be automatically\\nversioned and uploaded to your assistant.\\nThe next assistant that we are going to define\\nwill be a virtual assistant.\\nVirtual assistant plays a crucial part in\\nmy",
    "file_path": "playlist_1\\Replacing my Agency with an Agent Swarm…_M5Pa0pLgyYU.json",
    "file_size": 13016,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "agency",
     "agent",
     "and",
     "api",
     "are",
     "can",
     "have",
     "json",
     "lang:pt",
     "not",
     "nthe",
     "own",
     "replacing my agency with an agent swarm…_m5pa0plgyyu",
     "that",
     "the",
     "this",
     "will",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "915df2dd22ea1559ccfa4429f7db7501",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 4,
     "processing_time": 0.036753177642822266
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Replacing my Agency with an Agent Swarm…_M5Pa0pLgyYU_Part_2",
    "content": "agency, as she helps me save time on routine\\ntasks like budgets, emails, and drafting proposals.\\nI added an example here in the cells below\\nof how you can connect your agent with any\\nLangchain tools.\\nIn particular, I am adding actions to draft\\nand find emails with Zapier.\\nSo, if you want to use these, make sure to\\nclick on this link to get your Zapier actions\\nAPI key, connect it to your mailbox and enable\\nthese 2 actions.\\nIn the future, I will add a tool factory that\\nwill allow you to import any tools from Langchain\\nor Llama Index in 1 line of code.\\nNow, I will also create two additional custom\\ntools.\\nThe first one is a web search tool that utilizes\\nDuckDuckGo to search the internet, and the\\nsecond one is a proposal generator.\\nThe proposal generation function will actually\\ncall the OpenAI completions endpoint to generate\\na proposal.\\nThis technique ensures that your agent will\\nalways get similar results when generating\\nproposals based on your predefined prompt.\\nKeep in mind that all your tools should extend\\na base tool, which is defined with an instructor\\nlibrary.\\nAgain, a tutorial on how to define your custom\\ntools with instructor is probably coming soon,\\nbut for now just keep in mind that all your\\ndoc strings and field descriptions will be\\npassed to the model and this is how it will\\ndetermine when and how to use your tools.\\nAdditionally, it provides automatic type validation,\\nso if for any reason your model hallucinates\\nand inserts a wrong type, it should immidiately\\ncorrect itself.\\nNext I will add some basic instructions for\\nthis agent and create it.\\nThe last agent will be the developer, similar\\nto the one I made in the previous video, however,\\nthis time, it will be able to write multiple\\nfiles into a program.\\nSo the program tool will take a list of Files\\ntools, along with a special chain_of _thought\\nparameter that will force the model to plan\\nit s action beforehand when calling this tool.\\nThis allows you to achieve better results\\non complex functions without having to use\\na chain of thought globally, which increases\\nyour token usage and latency.\\nI will also allow it to run any terminal commands\\nthis time with an ExecuteCommand tool, however\\nI do not recommend doing this in your local\\nenvironment.\\nNow that all of our agents are prepared, the\\nnext step is to create the agency manifesto.\\nThe manifesto is basically a set instructions\\nthat will be shared across all agents, so\\nit makes sense to add basic context about\\nyour environment, your mission statement,\\ngoals, etc.\\nAnd the final step is to define the communication\\nflows.\\nThis is handled using the agency_chart within\\nthe agency class.\\nEssentially, the first agent will be the agent\\nresponsible for communication with the user,\\nso you can put it as a standalone item in\\nthe top-level array.\\nNext, you have to define to whom the ceo will\\nbe able to communicate.\\nSo, I am going to add 2 more arrays with a\\nCEO on the left and a dev and VA on the right.\\nKeep in mind that the communication flows\\nin my library are directional, because I do\\nnot want my agents to chat for no reason.\\nSo, in this example, the CEO can initiate\\na chat with the developer or the VA, and they\\ncan respond in this chat, but the developer\\nand VA can't initiate a chat with the CEO\\nthemselves.\\nHowever, it does make sense to allow the developer\\nto chat with the virtual assistant, because\\nthe developer might also need help with tasks\\nlike research.\\nSo I'm going to add another item with \\\"dev\\\"\\non the left and \\\"VA\\\" on the right, which means\\nthat now the developer will be able to initiate\\na chat with the VA to assign new tasks.\\nMake sure to tailor this chart to mimic your\\nspecific organization.\\nAgency manifesto you can put into shared instructions\\nparameter, and by the way, this can also be\\na file.\\nAfter you run this",
    "file_path": "playlist_1\\Replacing my Agency with an Agent Swarm…_M5Pa0pLgyYU.json",
    "file_size": 13016,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "agent",
     "and",
     "can",
     "chat",
     "developer",
     "example",
     "json",
     "lang:pt",
     "model",
     "nso",
     "nthe",
     "nthis",
     "replacing my agency with an agent swarm…_m5pa0plgyyu",
     "that",
     "the",
     "this",
     "tool",
     "tutorial",
     "will",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "915df2dd22ea1559ccfa4429f7db7501",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 4,
     "processing_time": 0.03775286674499512
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Replacing my Agency with an Agent Swarm…_M5Pa0pLgyYU_Part_3",
    "content": "cell, you will see a special\\nsettings.json file appear in files on the\\nleft.\\nThis settings.json file will keep track of\\nall your agents, and update them in case of\\nany changes.\\nSo, for example, if you change instructions\\nfor the dev and run the agency class again,\\ninstead of creating a new agent, this framework\\nwill automatically update your existing one.\\nI did this so you can save this schema into\\na database and then reinstate your agents\\nlater.\\nIt also works for files, so if you upload\\nany files to a folder, it will automatically\\nadd IDs to your file names, and then only\\nupload the new ones.\\nAfter our agency is initialized, the last\\nthing we need to do is imply run demo_gradio\\nmethod.\\nThis will create a simple chat application\\nwith gradio, where you can test your agency\\nswarm.\\nSo let s see how it works.\\nThe first message I will send is We need a\\nsimple neural net to predict mnist digits\\nAs you can see, the CEO immediately asks the\\nVA for a proposal, then va calls the generate\\nproposal function, which it then returns it\\nback to the CEO, who reports it to myself.\\nOf course, some details in the proposal are\\nnot exactly realistic, but I bet you can fix\\nthis by providing more context in the agency\\nmanifesto.\\nAfter I confirm the proposal, and tell the\\nCEO to proceed with the development, it sends\\nthese details to the developer agent.\\nThe developer agent now starts to develop\\nthe program, which it then saves to the [main.p](http://main.pt)y\\nfile and proceeds with executing and debugging\\nthis program.\\nThis might take a while because it is actually\\ntraining a real neural network right now in\\nour collab notebook.\\nYou can check out the by going back into the\\ncolab notebook and openning the files tab\\non the left.\\nAfter the execution is complete, it reports\\nto the CEO that the neural net has been trained,\\nwhich the CEO communicates back to me again.\\nAwesome, so now I am going to ask it to display\\nsome images with the results and save them\\nto the results.png file.\\nThere is literally almost no supervision required.\\nI simply communicated what I wanted to do\\nto the CEO, and then they interpreted my instructions\\nto the developer, who then wrote and executed\\nthe new file.\\nYou can see it again on the left, along with\\nthe \\\"results.png\\\" image.\\nIt actually got every single image right,\\nwhich is pretty cool.\\nNow, finally, I am going to tell it to write\\nan email to [me@vrsen.ai]saying the task has\\nbeen completed.\\nNow the CEO automatically determines that\\nit needs to send this request to the virtual\\nassistant, instead of the developer based\\non our agent descriptions.\\nThen it confirms to us that a draft has been\\nwritten, which you can see in my mailbox.\\nSo this was already quite impressive, and\\nI could already see how with some adjustments\\nand more data, I could actually use this in\\nmy agency.\\nStill, there are a few improvements that I\\nplan to add to this framework, which I am\\ngoing to discuss next.\\nAny contributions on github are welcome.\\nFirst, the communication flow right now is\\nsynchronous.\\nThis means that agents must talk to each other,\\nuntil the task is fully completed.\\nIn the future, I plan to allow agents to do\\nthis asynchronously, meaning that they will\\nbe able to execute multiple tasks in a queue.\\nThe CEO will then be able to check, or even\\nbetter, receive notifications of successful\\ncompletions.\\nSecond, in the next few videos, I want to\\ntry to create an agency that creates other\\nagencies, where one agent could be responsible\\nfor creating tools, another agent for instructions,\\nthe third for files, and so on.\\nAnd lastly, in the very end, I plan to allow\\nagencies to communicate with other agencies,\\nwhich, in combination with an agency that\\ncreates agencies could lead to a self expanding\\nsystem, or in other words, agency swarm, that\\ngrows to",
    "file_path": "playlist_1\\Replacing my Agency with an Agent Swarm…_M5Pa0pLgyYU.json",
    "file_size": 13016,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "agency",
     "agent",
     "and",
     "can",
     "ceo",
     "database",
     "file",
     "json",
     "lang:pt",
     "nthe",
     "nthis",
     "replacing my agency with an agent swarm…_m5pa0plgyyu",
     "see",
     "test",
     "that",
     "the",
     "then",
     "this",
     "will",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "915df2dd22ea1559ccfa4429f7db7501",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 4,
     "processing_time": 0.03875398635864258
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Replacing my Agency with an Agent Swarm…_M5Pa0pLgyYU_Part_4",
    "content": "facilitate your needs.\\nIn conclusion, the OpenAI assistants API is\\na game changer for AI agents.\\nThe ability to store instructions, data, and\\nfunctions directly in each new agent makes\\nit perfect for orchestrating agent swarms.\\nThe fact that each agent can be extremely\\nspecialized allows us to expand our system\\nas much as we want without worrying about\\nany hallucinations.\\nAnd this library provides you with all the\\nnecessary abstractions to start building usable\\nagent swarms without having to worry about\\nany of the low-level details.\\nSo, I am extremely excited to see where all\\nof you guys are going to take it next and\\nwhat you are going to create.\\nPlease feel free to contribute on GitHub,\\ngive it a star, and share this video if you\\nwant to support the project.\\nThank you for watching and don t forget to\\nsubscribe.\", \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\Replacing my Agency with an Agent Swarm…_M5Pa0pLgyYU.json\", \"tags\": [ \"Replacing my Agency with an Agent Swarm…\" ], \"source\": \"https://www.youtube.com/watch?v=M5Pa0pLgyYU\" }",
    "file_path": "playlist_1\\Replacing my Agency with an Agent Swarm…_M5Pa0pLgyYU.json",
    "file_size": 13016,
    "last_modified": "2025-04-18 15:34:03",
    "tags": [
     "about",
     "agency",
     "agent",
     "all",
     "and",
     "api",
     "each",
     "extremely",
     "json",
     "lang:pt",
     "nany",
     "nthe",
     "replacing my agency with an agent swarm…_m5pa0plgyyu",
     "swarm",
     "swarms",
     "the",
     "this",
     "without",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "915df2dd22ea1559ccfa4429f7db7501",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 3,
     "total_chunks": 4,
     "processing_time": 0.03875398635864258
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 3,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "The Complete Guide to Building AI Agents for Beginners_MOyl58VF2ak_Part_1",
    "content": "{ \"section_name\": \"The Complete Guide to Building AI Agents for Beginners\", \"content\": \"It is clear that in a few years, businesses\\nwill hire agencies composed entirely of AI\\nagents.\\nFor example, an AI lab cognition recently\\nreleased their first AI software engineer\\nnamed Devin that outperforms anything else\\nthat we have ever seen before SWE benchmark.\\nIt can train its own AI, learn unfamiliar\\ntechnologies, contribute to production repos,\\nand even complete some side hustles on Upwork.\\nBut what many people don't realize is that\\nthis comparison on their chart is made between\\nstandard large language models, like Claude\\nor gpt-4 while Devin has access to additional\\ntools like a terminal, code editor, and even\\nits own browser.\\nSo, all it is, is literally just a cleverly\\nprompted LLM with a bunch of tools, and this\\nlab has already gotten more than 20 millions\\nof dollars in funding.\\nPersonally, I don't believe they're heading\\nin the right direction and I'll explain exactly\\nwhy later, but what this really shows is that\\nwe're merely scratching the surface of what's\\npossible here.\\n-So In this video I will share with you my\\nentire experience developing custom AI agent\\nsystems over the last year developing custom\\nAI agent systems for companies of all sizes\\nraging from small firms with 5 employees to\\nentire corporation with 30000+ people.\\nIn fact, by the end of this video you will\\nbe able to build your own fully functional\\nSocial Media Marketing Agency that will generate\\nad copy, create ad images with DALL-E 3, and\\nreliably post them on Facebook.\\nHere is the game plan.\\nWe'll start with an overview of new AI Agent\\ndeveloper role and what it entails\\nNext, we'll unravel what AI Agents truly are.\\nAfter that we'll take a tour of the most popular\\nAI agent frameworks at your disposal.\\nThen, I'll be pulling back the curtain on\\nmy own framework, giving you an insider's\\nperspective on how it works and how you can\\nleverage it in your own projects.\\nAnd finally, we'll get hands-on as we build\\na fully functional SMMA, ready to take on\\nnew clients and generate profits.\\nThis will be a comprehensive guide, highlighting\\nmy entire process from start to finish.\\nSo make yourself comfortable and let's dive\\nin.\\nFirst, let's me define this new AI Agent Developer\\nrole and why I believe it will be one of the\\nmost in-demand skills in 2024.\\nWell, numerous studies and industry experts\\npredict that we're headed towards full labor\\nautomation in the next decade.\\nWhile I totally agree with this projection,\\nI don't think it will be a self-driven process.\\nAs AI models become increasingly intelligent,\\nthey're certainly going to gain a broader\\nunderstanding of the world.\\nHowever, they will never know how a specific\\ncompany operates internally, simply because\\nsuch data is rarely made public.\\nAs we saw in 2023, businesses don't just want\\nto incorporate standard LLMs into their processes.\\nThey want to customize them and at least enrich\\nthem with their own personal data.\\nThe reason I believe why labs like cognition\\nwill soon fail is because they lack customization.\\nTo fully automate a company like google you\\nneed more than just a super intelligent AI\\ndeveloper.\\nWe need to make sure that this developer has\\naccess to all the necessary tools, infrastructure\\nand internal knowledge, before it can actually\\nperform any tasks.\\nThis is where AI Agent Developers come in.\\nSo, an AI Agent Developer is someone who fine-tunes\\nAI agents based on internal business processes.\\nAs an AI Agent Developer, my primary responsibility\\nis to equip AI with all the necessary resources\\nand ensure it knows how and when to use them\\nin production.\\nThe primary skills required for an AI agent\\ndeveloper role can significantly vary from\\nproject to project.\\nThis topic deserves its own separate video\\nby itself, so if you're interested, please\\nlet me know in the comments.\\nSoon I'll walk you through exactly how to\\naccomplish all of this.\\nBut for now we need to understand what AI\\nagents truly are.\\nA lot of people say",
    "file_path": "playlist_1\\The Complete Guide to Building AI Agents for Beginners_MOyl58VF2ak.json",
    "file_size": 29761,
    "last_modified": "2025-04-18 15:34:01",
    "tags": [
     "agent",
     "all",
     "and",
     "can",
     "don",
     "guide",
     "how",
     "json",
     "lang:pt",
     "nand",
     "own",
     "that",
     "the",
     "the complete guide to building ai agents for beginners_moyl58vf2ak",
     "their",
     "this",
     "what",
     "will",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "79a89fc68aa4928683aeba8aa9ced2b3",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 8,
     "processing_time": 0.03475213050842285
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 8,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "The Complete Guide to Building AI Agents for Beginners_MOyl58VF2ak_Part_2",
    "content": "that AI Agents are just\\ninstructions knowledge and actions.\\nAnd sure that's sort of true, but that's not\\nexactly what AI agents are, that's how we\\nmake AI agents.\\nIn fact, AI Agents are much more than that.\\nLet me explain.\\nTo answer what AI agents truly are we need\\nto unpack the difference between standard\\n1.0 AI automations and more sophisticated\\n2.0 AI agent-based applications.\\nPicture a straightforward customer support\\nautomation where an LLM must label each incoming\\nemail and must respond to it, pulling some\\nadditional context from a vector database.\\nDoes this sound like an agent or mere AI automation?\\nYou may have noticed that it doesn't quite\\nfeel like an agent, right?\\nBut why?\\nIt has knowledge from your vector database,\\nand has instructions on how to respond, and\\nperforms an action of attaching a label.\\nAnd the distinction lies in the fact that\\nI said that it must generate a label and must\\nanswer each email.\\nYou see, the fundamental difference between\\nautomations and agents is that agents possess\\ndecision-making capabilities.\\nSo, In 1.0 AI automations, every single procedure,\\nlike context retrieval, response generation,\\nand labeling is hardcoded into the backend\\nlogic.\\nThis means that it literally can not deviate\\nfrom this logic, no matter what.\\nIf the automation is tasked with responding\\nto emails, it cannot neglect to respond.\\nAnd while all this rigidity works well for\\ncertain use cases, it completely fails as\\nsoon as some unexpected circumstances arise.\\nImagine for example if your customer support\\nmailbox receives an inquiry about a potential\\npartnership with your platform.\\nIf this scenario wasn't accounted for, a 1.0\\nAI automation would handle it like any other\\nsupport inquiry, potentially causing a missed\\nopportunity.\\nOn the contrary, 2.0 AI Agent-Based applications\\nhave a different approach.\\nWhile they still equip the agent with the\\nnecessary tools, context, and instructions,\\nthey grant the agent the autonomy on how to\\nutilize these tools by itself.\\nInstead of feeding your context into the prompt\\non every request, you empower the agent to\\nretrieve it only when it's needed.\\nThis flexibility means that the agent can\\nadapt accordingly.\\nSo in our previous example, the agent would\\nrecognize that it's dealing with an inquiry\\noutside of its expertise and then it could\\nuse other available tools if possible.\\nFor example, it could reach out to your human\\nsupport agent, or it could send a notification\\nin slack.\\nOverall, what AI agents truly are is a new\\nway of thinking about how to apply AI in various\\napplications.\\nIt's a paradigm shift rather than a simple\\ntechnique.\\nIn my agency we all began with simple 1.0\\nAI automations, but as my clients saw the\\ntangible benefits they offered, they yearned\\nfor more-more advanced capabilities and automation\\nof increasingly complex tasks.\\nOver time, we reached a stage where I wouldn't\\neven call it as automation anymore.\\nIt was more akin to outsourcing, as some of\\nthe processes we automated literally required\\nmultiple people to manually carry them out.\\nAnd the performances were never the same.\\nNow, having said all this, where do Agent\\nSwarms come in?\\nTo truly grasp the concept of agent swarms,\\nit's crucial to understand that all intelligence\\nis environment-dependent.\\nFor instance, I might excel when it comes\\nto programming, but I'm utterly lost when\\nit comes to cooking.\\nI would not last a day as a cook even in McDonald's\\nfor a day.\\nI just basically eat meat and nothing else.\\nThis applies to both AI agents and your own\\nemployees.\\nYou can't assign 10 different roles to even\\nthe smartest person in the world\\nLikewise, even we reach GPT-100, I would still\\nnot recommend assigning so many different\\nresponsibilities to a single agent.\\nFirstly, by removing all unnecessary information\\nfor a given",
    "file_path": "playlist_1\\The Complete Guide to Building AI Agents for Beginners_MOyl58VF2ak.json",
    "file_size": 29761,
    "last_modified": "2025-04-18 15:34:01",
    "tags": [
     "agent",
     "agents",
     "all",
     "and",
     "are",
     "automation",
     "example",
     "json",
     "lang:pt",
     "more",
     "nand",
     "nfor",
     "nit",
     "nto",
     "that",
     "the",
     "the complete guide to building ai agents for beginners_moyl58vf2ak",
     "this",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "79a89fc68aa4928683aeba8aa9ced2b3",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 8,
     "processing_time": 0.03475213050842285
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 8,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "The Complete Guide to Building AI Agents for Beginners_MOyl58VF2ak_Part_3",
    "content": "process simply saves you on tokens.\\nAnd secondly, even if GPT-100 would not get\\nconfused handling 10 different roles, the\\nusers of such a system certainly would.\\nSo, what agent swarms really allow you to\\ndo is separate responsibilities for different\\nenvironments, just like in real world organizations.\\nThis results in 3 main benefits:\\nFirst, it dramatically reduces hallucinations.\\nI found that after you add 7 to 10 tools to\\na single GPT4 agent, it starts to get confused.\\nBut when you split these tools into multiple\\nagents you almost completely eradicate this\\nproblem.\\nSecondly, you can outsource much more complex\\ntasks.\\nBecause, The longer the sequence of your agents\\nis, the more tasks they can handle without\\ndirect supervision.\\nAnd lastly, it makes the whole system much\\neasier to scale.\\nYou see, most of my clients don't stop on\\na single AI Agent and often try to automate\\nincreasingly complex processes over time.\\nSo when the need arises instead of adjusting\\nyour existing system, and than debugging it\\nall over again, you can simply add another\\nagent and leave all the previous agents as\\nthey are.\\nIn fact this last problem of scaling is so\\ncommon among my clients that this week we\\nare releasing the first of it's kind AI Agents\\nas a Service subscription.\\nBasically, if you are a business owner you\\ncan now pay us a fixed fee per month and we\\nwill develop as many AI agents as you need,\\nbut we will work on them one at a time.\\nOur goal is to provide a flexible and scalable\\nsolution that grows with your needs.\\nSo if you are interested, you can apply right\\nnow sing the link below at a temporarily discounted\\nprice.\\nHowever, if you're inclined to take on this\\njourney by yourself, that's perfectly fine\\ntoo, because next, I'm going to walk you through\\nmy entire process from start to end.\\nBut before we get into the nitty-gritty, let's\\nstart with a brief overview of all the multi-agent\\nframeworks at your disposal.\\nThe first project is the one you've probably\\nheard of, called AutoGen by Microsoft.\\nThe main feature of AutoGen is multi-agent\\nchats.\\nIt was developed as a research experiment\\nand was quite groundbreaking at the time.\\nHowever, the problem with AutoGen is that\\nit has extremely limited conversational patterns\\nthat are super hard to customize.\\nIf you look at its code, in AutoGen the next\\nspeaker is determined with an extra call to\\nthe model that emulates role play between\\nthe agents.\\nLet me just read it to you \\\"Read the above\\nconversation.\\nThen select the next speaker from agent names;\\nonly return the role.\\\"\\nI mean, not only is this extremely inefficient,\\nbut it also makes the whole system absolutely\\nuncontrollable.\\nA lot of people report that agents constantly\\nhallucinate because there is no clear separation\\nof concerns when it comes to tool execution.\\n1 agent might write the code, but because\\nit needs to be executed by user proxy, or\\nsome other agent, it often results in hallucinations,\\nwhich is a huge problem in production.\\nThe next framework that has recently been\\ngetting a ton of attention is called crew\\nai.\\nCrewAI was developed as a side project and\\nit introduces the concept of \\\"process\\\" into\\nagent communication.\\nThis provides some semblance of control over\\nthe communication flow.\\nHowever, just like in AutoGen, the conversation\\nflows are extremely limited, offering only\\nsequential or hierarchical options.\\nIn the sequential process basically all your\\nagents communicate to each other one by one.\\nAnd in the hierarchical there is a one manager\\nagent communicates to everyone else.\\nObviously, this is not how real organizations\\nare structured.\\nFor example, can you imagine Sundar Pichai\\nmanually instructing a QA tester, who tested\\nthis amazing new sign in screen?\\nAdditionally, in Crew AI, the manager agent\\nis hardcoded for you, which for",
    "file_path": "playlist_1\\The Complete Guide to Building AI Agents for Beginners_MOyl58VF2ak.json",
    "file_size": 29761,
    "last_modified": "2025-04-18 15:34:01",
    "tags": [
     "agent",
     "agents",
     "and",
     "are",
     "autogen",
     "can",
     "json",
     "lang:pt",
     "model",
     "nand",
     "nthe",
     "one",
     "process",
     "system",
     "that",
     "the",
     "the complete guide to building ai agents for beginners_moyl58vf2ak",
     "this",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "79a89fc68aa4928683aeba8aa9ced2b3",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 8,
     "processing_time": 0.035752296447753906
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 8,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "The Complete Guide to Building AI Agents for Beginners_MOyl58VF2ak_Part_4",
    "content": "some reason\\npeople find cool.\\nHowever, imagine if you want this agent to\\nfirst search the web for additional context\\nbefore deciding who it should speak next to.\\nTry doing that in Crew AI.\\nThe biggest problem with CrewAI, however,\\nis that it is built on top of Lang-chain,\\nwhich was released before any function-calling\\nmodels.\\nThis means that there is no automatic type\\nchecking or error correction when it comes\\nto tool execution.\\nThe description for these tools are also extremely\\nlimited.\\nRecently CrewAI introduce way to overcome\\nthis by extending a base tool class, however\\nhis process is definitely not straightforward\\nas it could have been.\\nThe goal, backstory, the role and the tasks,\\nthat you need to define when you are creating\\nyour crew are simply prompt templates that\\nalso take away control from you as a developer.\\nWithout these prompt templates the CrewAI\\nsimply would not be able to function.\\nThe only advantage of CrewAI is that you can\\nuse it with open source models.\\nNow personally I would never utilize any of\\nthese frameworks in production for my clients\\nwhich is why I developed my own framework\\ncalled Agency Swarm.\\nIn this framework, there isn't a single hard-coded\\nprompt.\\nIt's easily customizable with uniform communication\\nflows, and it is extremely reliable in production\\nbecause it provides automatic type checking\\nand validation for all tools with the instructor\\nlibrary.\\nIt is the thinnest possible wrapper around\\nOpenAI's Assistance API, meaning that you\\nhave full control over all your agents.\\nSo whether you add a manager agent, define\\ngoals, processes, or not, whether you create\\na sequential or hierarchical flow or even\\ncombine both with a communication tree that\\nis 50 levels in depth, I don't care, it is\\nstill going to work.\\nYour agents will determine who to communicate\\nwith next, based on their own descriptions\\nand nothing else.\\nBut, you are probably wondering, why assistants\\napi for ai agent development?\\nWell, that's a good question because if you\\nlook at all the previous OpenAI endpoints,\\nyou'll find the Assistants API isn't significantly\\ndifferent.\\nHowever, it was a game-changer for me as agent\\ndeveloper.\\nAnd the reason for this is state management.\\nYou see, with the Assistants' API, you can\\nattach instructions, knowledge, and actions\\ndirectly to each new agent.\\nThis not only allows you to separate various\\nresponsibilities, but also to scale your system\\nseamlessly without having to worrying about\\nany underlying data management or about your\\nagents confusing each others tools like in\\nother frameworks.\\nAgent state management is the primary reason\\nwhy Agency Swarm is fully based on the OpenAI\\nAssistants API, and to answer your other question,\\nno we are not currently planning to support\\nany open source models.\\nIf costs are a concern, simply use GPT-3 which\\nis much better than any LLM that you can run\\nlocally unless you have a 10000$ PC.\\nIf data privacy is a concern you can use my\\nframework with Azure OpenAI, which doesn't\\neven share data with OpenAI itself.\\nTo get started creating your agent swarms\\nusing my framework you need to understand\\n3 essential entities which are Agents, Tools\\nand Agencies.\\nAgents, are essentially wrappers around assistants\\nin Assistants API.\\nThey include numerous methods that simplify\\nthe agent creation process.\\nFor instance, instead of manually uploading\\nall your files and adding their IDs when creating\\nan assistant, you can just specify the folder\\npath.\\nThe system will automatically attach all files\\nfrom that folder to your assistant.\\nIt also stores all your agent settings in\\na settings.json file.\\nTherefore, if your agent's configuration changes,\\nthe system will automatically update your\\nexisting assistant on OpenAI the next time\\nyou run it, rather than creating a new one.\\nThe most",
    "file_path": "playlist_1\\The Complete Guide to Building AI Agents for Beginners_MOyl58VF2ak.json",
    "file_size": 29761,
    "last_modified": "2025-04-18 15:34:01",
    "tags": [
     "agent",
     "all",
     "and",
     "api",
     "are",
     "assistants",
     "can",
     "crewai",
     "json",
     "lang:pt",
     "not",
     "nthe",
     "openai",
     "that",
     "the",
     "the complete guide to building ai agents for beginners_moyl58vf2ak",
     "tools",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "79a89fc68aa4928683aeba8aa9ced2b3",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 3,
     "total_chunks": 8,
     "processing_time": 0.035752296447753906
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 3,
    "total_chunks": 8,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "The Complete Guide to Building AI Agents for Beginners_MOyl58VF2ak_Part_5",
    "content": "commonly used parameters when creating\\nan agent are name, description, instructions,\\nmodel, and tools.\\nThese are all self-explanatory.\\nThere are no preset templates for goals, processes,\\nbackstories, etc., so you simply include them\\nall in the instructions.\\nAdditional parameters include files_folder,\\nschemas_folder, and tools_folder.\\nAs I said, all files from your files folder\\nwill be automatically indexed and uploaded\\nto OpenAI.\\nAll tools from your tools folder will be attached\\nto an assistant as well, and all openapi schemas\\nfrom your schemas folder will automatically\\nbe converted into tools, allowing your agents\\nto easily call third party apis.\\nAdditional properties api_params and api_headers\\nare also available if your API requires authentication.\\nHowever, I do recommend creating all your\\ntools from scratch using Instructor, as it\\ngives you more control.\\nI previously posted a detailed tutorial on\\nInstructor, which includes a brief conversation\\nwith its creator, Jason Liu.\\nCheck it out if you're interested.\\nIn essence, Instructor allows you to integrate\\na data validation library, Pydantic, with\\nfunction calls.\\nThis ensures that all agent inputs make sense\\nbefore any actions are executed, minimizing\\nproduction errors.\\nFor instance, if you have a number division\\ntool, you can verify that the divisor is not\\nzero.\\nIf it is, the agent will see the error and\\nautomatically correct itself before executing\\nany logic.\\nTo begin creating tools in Agency Swarm with\\nInstructor, create a class that extends a\\nbase tool, add your class properties, and\\nimplement the run method.\\nRemember, the agent uses the docstring and\\nall field descriptions to understand when\\nand how to use your tool.\\nFor our number division tool, the docstring\\nshould state that this tool divides two numbers\\nand describe the parameters accordingly.\\nNext, define your execution logic within the\\nrun method.\\nYou can access all defined fields through\\nthe self object.\\nTo make some fields optional, use the Optional\\ntype from Pydantic.\\nTo define available values for your agent,\\nuse a literal or enumerator type.\\nThere are also many tricks you can use.\\nFor instance, you can add a chain_of_thought\\nparameter inside the tool to save on token\\ncosts and latency, instead of using a chain\\nof thought prompt globally.\\nTo add your validation logic, use field or\\nmodel validators from Pydantic.\\nIn this division tool example, it makes sense\\nto add a field validator that checks if the\\ndivisor is not zero, returning an error if\\nit is.\\nBecause tools are arguably the most important\\npart of any AI Agent based system, I created\\nthis custom GPT to help you get started faster.\\nFor example, if I need a tool that searches\\nthe web with Serp API, it instantly generates\\na BaseTool with parameters like query as a\\nstring and num_results as an integer, including\\nall relevant descriptions.\\nYou can find the link to this tool on our\\nDiscord.\\nThe final component of the Agency Swarm framework\\nis the Agency itself, which is essentially\\na collection of agents that can communicate\\nwith one another.\\nWhen initializing your agency, you add an\\nAgency chart that establishes communication\\nflows between your agents.\\nIn contrast to other frameworks, communication\\nflows in Agency Swarm are uniform, meaning\\nthey can be defined in any way you want.\\nIf you place any agents in the top-level list\\ninside the agency chart, these agents can\\ncommunicate with the user.\\nIf you add agents together inside a second-level\\nlist, these agents can communicate with one\\nanother.\\nTo create a basic sequential flow, add a CEO\\nagent to the top-level list, then create a\\nsecond-level list with a CEO, developer, and\\nvirtual assistant.\\nIn this flow, the user communicates with the\\nCEO, who then communicates with the developer\\nand the virtual assistant.\\nIf",
    "file_path": "playlist_1\\The Complete Guide to Building AI Agents for Beginners_MOyl58VF2ak.json",
    "file_size": 29761,
    "last_modified": "2025-04-18 15:34:01",
    "tags": [
     "add",
     "agency",
     "agent",
     "agents",
     "all",
     "and",
     "api",
     "are",
     "can",
     "json",
     "lang:pt",
     "nto",
     "that",
     "the",
     "the complete guide to building ai agents for beginners_moyl58vf2ak",
     "tool",
     "tools",
     "tutorial",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "79a89fc68aa4928683aeba8aa9ced2b3",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 4,
     "total_chunks": 8,
     "processing_time": 0.03675055503845215
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 4,
    "total_chunks": 8,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "The Complete Guide to Building AI Agents for Beginners_MOyl58VF2ak_Part_6",
    "content": "you prefer a hierarchical flow, place the\\nagents in two separate second-level lists\\nwith the CEO.\\nRemember, communication flows are directional.\\nIn the previous example, the CEO can initiate\\ncommunication with the developer, who can\\nrespond, but the developer cannot initiate\\ncommunication with the CEO, much like in real\\norganizations.\\nIf you still want the developer to assign\\ntasks to the CEO, simply add another list\\nwith the developer first and the CEO second.\\nI always recommend starting with as few agents\\nas possible and adding more only once they\\nare working as expected.\\nAdvanced parameters inside the Agency class\\nlike async mode, threads_callbacks, and settings_callbacks\\nare useful when deploying your swarms on various\\nbackends.\\nBe sure to check our documentation for more\\ninformation.\\nWhen it comes to running your agency, you\\nhave 3 options: the Gradio interface with\\nthe demo_gradio command, the terminal version\\nwith the run_demo method, or get_completion,\\nwhich is similar to previous chat completions\\nAPIs.\\nNow, let's create our own social media marketing\\nagency together to demonstrate the entire\\nprocess from start to finish.\\nAlright, for those who are new here, please\\ninstall Agency Swarm using the command 'pip\\ninstall agency swarm.'\\nTo get started quickly, I usually run the\\n'agency swarm genesis' command.\\nThis will activate the Genesis agency, which\\nwill create all your agents for you.\\nIt doesn't get everything right just yet,\\nbut it does speed up the process significantly.\\nIn my prompt, I'm going to specify that I\\nneed a Facebook marketing agency that generates\\nad copy, creates images with Dalle 3, and\\nposts them on Facebook.\\nAs you can see, we now have our initial agency\\nstructure with three agents: the ad copy agent,\\nimage creator agent, and Facebook manager\\nagent.\\nI really like how the genesis agency has divided\\nthese responsibilities among three different\\nagent roles.\\nHowever, I'd like to adjust the communication\\nflows a bit and adopt a sequential flow, so\\nI will instruct the genesis CEO accordingly.\\nNow we have a sequential agency structure\\nwith three communication levels.\\nWe can tell it to proceed with the creation\\nof the agents.\\nThis process takes some time, so I'll skip\\nthis part and return when we're ready to fine-tune\\nour agents.\\nAfter all our agents have been created, you\\ncan see that the CEO tells me that I can run\\nthis agency with the python agency.py command.\\nAll the folders for my agents and tools are\\ndisplayed on the left.\\nThe next step is to test and fine-tune all\\nthese tools.\\nWe'll start with the image generator agent.\\nThe Genesis Agency has created one tool for\\nthis agent called ImageGenerator.\\nIt's impressive how close this tool is to\\nwhat I planned to implement myself.\\nIt uses OpenAI to generate an image with a\\nsimple prompt, taking ad_copy, theme, and\\nspecific requirements and inserting them into\\na prompt template.\\nYes, AI has learned to prompt itself.\\nHowever, there's an issue: it uses an outdated\\nOpenAI package version with the Da Vinci Codex\\nmodel, which is designed for code generation.\\nLet's fix this now together.\\nFirst, I'll load a new OpenAI client with\\na convenience method from Agency Swarm Util.\\nI'll also increase the timeout because image\\ngeneration can take some time.\\nAfter that, I'll adjust the API call to use\\nthe new Dalle 3 model, and then set the timeout\\nback to the default.\\nThere's one more thing we have to do - we\\nhave to ensure that other agents can use this\\nimage when posting the ad.\\nSo, I'm going to create a new 'save image'\\nmethod that will save this image locally.\\nBut here is the kicker - I don't want my agents\\nto pass this image path to each other because\\nany hallucinations could cause issues.\\nInstead, I'll save this path to a shared state.\\nEssentially, shared state allows you",
    "file_path": "playlist_1\\The Complete Guide to Building AI Agents for Beginners_MOyl58VF2ak.json",
    "file_size": 29761,
    "last_modified": "2025-04-18 15:34:01",
    "tags": [
     "agency",
     "agents",
     "and",
     "api",
     "can",
     "ceo",
     "client",
     "developer",
     "documentation",
     "genesis",
     "image",
     "json",
     "lang:pt",
     "nthis",
     "nwith",
     "our",
     "test",
     "that",
     "the",
     "the complete guide to building ai agents for beginners_moyl58vf2ak",
     "this",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "79a89fc68aa4928683aeba8aa9ced2b3",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 5,
     "total_chunks": 8,
     "processing_time": 0.03775382041931152
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 5,
    "total_chunks": 8,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "The Complete Guide to Building AI Agents for Beginners_MOyl58VF2ak_Part_7",
    "content": "to share\\ncertain variables across all agents in any\\ntool.\\nInstead of having the agent manually pass\\nthe image path to another agent, you can save\\nit in one tool and access it in another.\\nYou can also use it to perform validation\\nlogic across various agents, which I'll show\\nyou soon.\\nNow we are ready to test this tool.\\nYou can do this by adding a simple 'if name\\nequals main' statement at the end, then initializing\\nthe tool with some example parameters.\\nThen you can print the result of the run method.\\nDon't forget to load the environment with\\nyour OpenAI key by adding the 'load_dotenv'\\nmethod at the top.\\nAs you can see, we have an image generated\\nand saved locally, as expected.\\nThis means we can now proceed with adjusting\\nthe next tool, the AdCopyGenerator tool within\\nthe ad copy agent.\\nThis tool is also very similar to my personal\\ndesign.\\nI'll adjust the prompt a bit and save the\\nresults into the shared state.\\nMoving on to the Facebook Manager agent, Genesis\\nAgency created two tools for us: the Ad Performance\\nMonitor tool and the Ad Scheduler and Poster\\ntool.\\nWhile these tools are quite close, creating\\nan ad on Facebook requires a few more steps.\\nSpecifically, we need to first create a campaign\\nand an ad set before we can post the ad.\\nI will use a tool creator custom gpt to request\\ntwo additional tools, 'Ad Campaign Starter',\\nand 'Ad Set Creator'.\\nTo run these tools, we first need to install\\nthe Facebook Business SDK, which you can do\\nwith this PIP command.\\nNext, we need to create our Facebook app.\\nGo to the Facebook developer website, click\\n\\\"Create App\\\", select \\\"Other\\\" for the use case,\\nthen \\\"Business\\\" for the app type.\\nAdd your app name and click \\\"Create App\\\".\\nThen click on \\\"Add product\\\" and add \\\"marketing\\nAPI\\\".\\nGo to \\\"App settings\\\", copy your App ID, App\\nsecret, and insert them into the environment\\nfile.\\nNow we have to get our access token by visiting\\nthe Facebook API Explorer website and adding\\nthe appropriate permissions.\\nAfter that, copy it and put it into the env\\nfile.\\nWorking with the Facebook API can be challenging\\nas it's known to be one of the more complex\\nAPIs out there.\\nI won't delve into the details of how I fine-tuned\\nthese tools.\\nThe process is the same: adjust, test, and\\nrepeat until they work as expected.\\nAs you can see in the AdCreator tool, we're\\nactually utilizing the ad copy, ad headline,\\nand image path from the shared state that\\nwe saved earlier.\\nI have also included a model validator that\\nchecks the presence of all these necessary\\nparameters.\\nIf one of the parameters is not defined, the\\nsystem throws a value error and instructs\\nthe agent on which tool needs to be used first.\\nThis approach significantly enhances the reliability\\nof the entire system, as it ensures that the\\nFacebook ad manager agent cannot post any\\nads until all the required steps like image\\ngeneration have been completed.\\nAfter successfully testing all our tools,\\nthe final step is to refine the instructions.\\nIt is a good practice to include how specifically\\nyour agents should communicate with each other.\\nI would also recommend specifying an exact\\nstep-by-step process for them to follow.\\nLastly, I decided to make a few adjustments\\nin our communication flows.\\nI'd like to establish a direct line of communication\\nwith our Facebook Manager agent, so I'll include\\nit in the top-level list.\\nAlso, I'll allow our CEO agent to communicate\\ndirectly with both the Facebook Manager and\\nthe Image Generator agents.\\nNow that we've made these adjustments, we're\\nready to run our agency.\\nIt is as simple as running the python.agency.py\\ncommand and opening the provided Gradio interface\\nlink in your browser.\\nLet's see how it works.\\nI'll kindly ask for an advertisement to be\\ncreated for my AI development agency, Arsen\\nAI.\\nThe CEO then instructs the",
    "file_path": "playlist_1\\The Complete Guide to Building AI Agents for Beginners_MOyl58VF2ak.json",
    "file_size": 29761,
    "last_modified": "2025-04-18 15:34:01",
    "tags": [
     "agent",
     "agents",
     "all",
     "and",
     "api",
     "app",
     "can",
     "example",
     "facebook",
     "image",
     "json",
     "lang:pt",
     "model",
     "nthe",
     "our",
     "test",
     "that",
     "the",
     "the complete guide to building ai agents for beginners_moyl58vf2ak",
     "tool",
     "tools",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "79a89fc68aa4928683aeba8aa9ced2b3",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 6,
     "total_chunks": 8,
     "processing_time": 0.038756370544433594
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 6,
    "total_chunks": 8,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "The Complete Guide to Building AI Agents for Beginners_MOyl58VF2ak_Part_8",
    "content": "ad copy agent,\\nwhich promptly provides a clear headline and\\nad copy for my agency, stating, \\\"Revolutionize\\nyour business with AI.\\\"\\nNext, the CEO commands the image generator\\nagent to create an image for the ad copy,\\nresulting in a futuristic visual for our campaign.\\nFinally, the CEO directs the FacebookManager\\nAgent to commence the campaign using the campaign\\nstarter tool.\\nIt then creates an ad set and executes the\\nad creation function, posting this ad on Facebook.\\nYou can now see this newly generated Facebook\\nad, complete with ad copy, headline, and image,\\nlive on my Facebook account.\\nImpressive, right?\\nBut what if you want to analyze your campaign's\\nperformance?\\nYou can do this by directly messaging the\\nFacebook Manager agent, as it was included\\nin the top-level list.\\nIt uses the AdPerformanceMonitor tool and\\ninforms me that there is currently no data\\nas it takes some time for an ad to reach its\\naudience.\\nIn conclusion, I'd like to briefly share my\\nroadmap for this framework.\\nFirst, I plan to establish multi-agency communication.\\nThis feature will allow the integration of\\nmultiple agencies for super complex use cases.\\nNext, we'll focus on enhancing the Genesys\\nagency.\\nWith multi-agency communication, the Genesys\\nagency will be able to test other agencies\\nduring their creation.\\nThe goal is to reach a point where there's\\nalmost no need to modify tools or instructions\\nfor simple agencies like the one we've just\\ncreated.\\nAnd lastly, we will continue to regularly\\nupdate this framework to include the latest\\nreleases from the OpenAI Assistants API.\\nWith upcoming features like memory and web\\nbrowsing, the possibilities are exciting to\\nsay the least.\\nSo, stay connected with us on Discord.\\nWe're always on the lookout for new talent.\\nIf you're interested and you have previous\\nexperience with this framework, you can apply\\nthrough our job postings channel.\\nThank you for watching and don't forget to\\nlike and subscribe.\", \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\The Complete Guide to Building AI Agents for Beginners_MOyl58VF2ak.json\", \"tags\": [ \"The Complete Guide to Building AI Agents for Beginners\" ], \"source\": \"https://www.youtube.com/watch?v=MOyl58VF2ak\" }",
    "file_path": "playlist_1\\The Complete Guide to Building AI Agents for Beginners_MOyl58VF2ak.json",
    "file_size": 29761,
    "last_modified": "2025-04-18 15:34:01",
    "tags": [
     "agency",
     "and",
     "campaign",
     "can",
     "complete",
     "copy",
     "facebook",
     "framework",
     "guide",
     "image",
     "json",
     "lang:pt",
     "like",
     "nad",
     "test",
     "the",
     "the complete guide to building ai agents for beginners_moyl58vf2ak",
     "this",
     "will",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "79a89fc68aa4928683aeba8aa9ced2b3",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 7,
     "total_chunks": 8,
     "processing_time": 0.038756370544433594
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 7,
    "total_chunks": 8,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw_Part_1",
    "content": "{ \"section_name\": \"This Revolutionary AI Business Model Will Make Millionaires in 2025\", \"content\": \"[Music]\\nthis AI business model will create\\nmillionaires or even billionaires in\\n2025 it could be bigger or it could even\\ncompletely replace SAS the best business\\nmodel we've had so far which is software\\nas a service a market of more than $300\\nbillion in this video I will explain\\nexactly what this new model is share l\\nAl everything you need to know to get\\nstarted even if you're a complete\\nbeginner and even provide you with a\\ncomplete step-by-step road mapap you can\\nfollow to profit from this opportunity\\nbefore everyone else at the end we will\\neven do an interview with someone who\\nhas already gone through all of these\\nsteps and currently generates $50,000\\nper month with this new amazing model\\nbefore we dive in if you're new to this\\nchannel welcome my name is arseny and\\nI've been building AI solutions for the\\nlast 4 years we were one of the first AI\\nagencies to start building AI agents for\\nbusinesses worldwide using my own AI\\nagent framework with over 3K stars on\\nGitHub and now unlike all other agency\\nowners on YouTube I won't even be\\nselling you a course or a paid community\\nat the end and it's not even in my plans\\nfor 2025 we'll be doing exactly what I\\nteach you here in this video ourselves\\nlast last ly for all my long-term\\nsubscribers sorry for the recent\\nslowdown in content I'm currently in the\\nprocess of relocating to Dubai which is\\nwhy I'm recording at this beautiful\\npodcast studio now let's Dive Right\\nIn first let's talk about what this new\\nopportunity is and how exactly it could\\nreplace SAS some of the ideas in this\\nsection for this video were inspired by\\na y com Bator podcast episode which I'll\\nlink down below for you to check out\\nlater the key idea from that episode was\\nthat just recently back in early 2000s\\nall software was sold on premise there\\nwas no SAS model because all software\\nwas sold on CDs you would buy a CD\\ninstall it and this is how you'd get\\nyour software then when the XML HTTP\\nrequest or Ajax came out it finally\\nbecame possible to build interactive\\nsoftware directly in your browser which\\nis exactly what allowed for this new SAS\\nmodel today we're experiencing an even\\nbigger shift because with the rise of\\naffordable and smart llms software is\\nbecoming more interactive than ever\\nbefore you can now interact with your\\nsoftware as naturally as you would with\\nany other human there's no longer even a\\nneed for a browser anymore check out my\\nprevious video on GPT 40 if you want to\\nlearn more about that but in a nutshell\\nwhat llms truly unlock for the world in\\n2025 and Beyond is a completely new way\\nto interact with technology which is\\nexactly what enables this revolutionary\\nnew AI business model called\\nass yes agents at a service AI agents\\nare so much more powerful than SAS\\nbecause AI agents do exactly what SAS\\ndoes but they do not require any\\nmanpower to run it so for instance\\nhopspot is just a CRM but you still need\\na marketing person to use it on the\\nother hand if you buy a marketing agent\\nyou don't even need anyone else because\\nthe agent will use your CRM for you it\\nwill generate leads it will schedule\\nappointments it will follow up with them\\nand it will update that CRM for you this\\nis why I believe agents as a service\\ncould actually be even bigger than this\\n300 billion software as a service Market\\nagents do not just give you the tools to\\nautomate a specific process they\\nactually automate the entire process for\\nyou so it's infinitely more scalable\\nanother important point I want to\\nmention here is that it's actually much\\neasier to build agents than traditional\\nsoftware products unlike many people\\nthink and you can trust me on this\\nbecause before we started our agents as\\na service subscription we actually built\\nfour large scale size products for\\nourselves and for our clients you see at\\nits core all siiz products are\\nessentially just wrappers around\\ndatabases H sport Salesforce QuickBooks\\nzenes it doesn't",
    "file_path": "playlist_1\\This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw.json",
    "file_size": 38619,
    "last_modified": "2025-04-18 15:34:04",
    "tags": [
     "agents",
     "and",
     "even",
     "json",
     "lang:pt",
     "model",
     "more",
     "new",
     "sas",
     "service",
     "software",
     "than",
     "the",
     "this",
     "this revolutionary ai business model will make millionaires in 2025_ed4suwgoahw",
     "what",
     "which",
     "will",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "ac94fbb1e4697ead09186cb10f2a41c7",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 11,
     "processing_time": 0.034116268157958984
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 11,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw_Part_2",
    "content": "matter all of them are\\njust user interfaces built on top of\\ndifferently structured databases so\\nzendesk is just a pretty fi database of\\nyour customer support tickets while\\nQuickBooks is a database of your\\ntransactions and the beauty of AI agents\\nis that they can work with these\\ndatabases directly there's way less code\\nrequired because the agent can just hook\\nup to your database without you having\\nto build any super complex apis or user\\ninterfaces so not only agents provide\\nsignificantly more value for businesses\\nthan SAS but they also require way less\\neffort to build them this is why I\\nbelieve this is such a massive\\nopportunity for anyone watching this and\\nto be clear you are still extremely\\nearly from this huge 300 billion Market\\nin 2024 Enterprises only spent 1.2 2\\nbillion on vertical agents this is the\\ntype of a agents by the way that we will\\nbe discussing in this video don't worry\\nif you don't understand the term in the\\nnext section I will explain everything\\nyou need to know about vertical versus\\nhorizontal a agents the key thing to\\nnotice here is that the growth actually\\nhas been the highest among all other\\ncategories 12x from the previous year\\nand the use cases are still extremely\\nbasic it's pretty much just co-pilots\\nrack and support\\nchatbots okay now before I can present\\nyou with this complete road map you can\\nfollow right now to fully benefit from\\nthis opportunity we first need to\\nunderstand the difference between the\\ntwo types of AI agents that you can\\nbuild under this new agents as a service\\nmodel which are the horizontal agents\\nand vertical agents the biggest\\ndifference is that vertical agents are\\nvery niched down they are made to\\nperform only a specific single roll or\\nfunction on the other hand horizontal\\nagents are not restricted by any\\nspecific use case when you are building\\na horizontal solution it means that you\\nor anyone else can adapt it for any\\nNiche role or function for example\\nHarvey AI is a vertical agent made\\nspecifically for law firms while my\\nagent framework agency form although can\\nbe used to make vertical agents is a\\nhorizontal platform now what this means\\nfrom a technical perspective is that\\nvertical agents can pre-trained for you\\nwhile horizontal agents require training\\nfrom scratch you see a key Insight that\\nwe discovered in ouri agency is that\\nthere are no two agents that are exactly\\nthe same however although most companies\\nfollow completely different sets of\\nsteps in their own processes a general\\nprocess for each role is still there for\\nexample a good developer always\\ntypically first looks at a task then\\nfinds the relevant files then writes a\\ntest then writes the code and then tests\\nit until it works as expected regardless\\nof which company he works for this is\\nexactly what vertical agents are trained\\non this pre-training on a general\\nprocess for a specific role is what\\nallows those agents to get up and\\nrunning much faster however just as this\\ncan be a blessing can also be a curse\\nyou see the fact that those vertical\\nagents have already been trained on a\\ngeneral process actually makes them\\nharder to customize for a specific\\nprocess in your or your client's\\nbusiness for example if your developers\\nalso need to write a documentation for\\neach feature but that documentation has\\nto be placed in a completely different\\nrepo following a specific format this is\\nwhere vertical agents can struggle on\\nthe other hand horizontal agents are not\\nrestricted by this initial pre-training\\nso they can easily be customized for any\\nprocess so to fully grasp the\\ndifferences let's try to plot this on\\nthe graph on the x axis we have the\\nperformance while on the Y AIS we have\\nthe time or an effort required this is\\nwhat it looks like for vertical agents\\nyou get a very steep return on\\ninvestment in a very short amount",
    "file_path": "playlist_1\\This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw.json",
    "file_size": 38619,
    "last_modified": "2025-04-18 15:34:04",
    "tags": [
     "agents",
     "and",
     "any",
     "are",
     "can",
     "database",
     "documentation",
     "example",
     "horizontal",
     "json",
     "just",
     "lang:pt",
     "nyou",
     "that",
     "the",
     "they",
     "this",
     "this revolutionary ai business model will make millionaires in 2025_ed4suwgoahw",
     "vertical",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "ac94fbb1e4697ead09186cb10f2a41c7",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 11,
     "processing_time": 0.03474831581115723
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 11,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw_Part_3",
    "content": "of\\ntime because you don't have to train it\\nfrom scratch but then as you can see\\ntypically the performance Plateau as\\nyou've exhausted all its capabilities\\nand you can't customize it any further\\nand this is what it looks like for\\nhorizontal agents with horizontal agents\\nyou need to invest a considerable amount\\nof time and effort before you get any\\nvalue at all but then what typically\\nhappens further down the line is that\\nyou are able to achieve a higher return\\non investment because you not\\nconstrained by this initial pre-training\\nand you can customize it much further\\nthe problem is that most business owners\\nhave no idea how to do this neither any\\ndesire to do it themselves if they can\\nget to 80% performance with 20% effort\\nthey will just go with the vertical\\nsolution this is this is why with\\nvertical agents you can get to extremely\\nhigh Revenue numbers in a very short\\namount of time just like with B2B SAS\\ncompared to b2c sias it's much easier to\\ngrow at those initial stages vertical\\nagents are much easier to pitch and\\nbuild yourself because you are only\\ntargeting a very specific type of a\\nbusiness customer this is why I don't\\neven recommend you to consider building\\na horizontal platform for or maybe 99%\\nof people watching this video and this\\nis why we ourselves at our agency will\\nbe expanding our offerings with vertical\\nagents in\\n2025 okay now let's take a look at a few\\nreal world examples of vertical agents\\nfirst we have a platform called 11x\\nwhich is building an AIS SDR and sales\\nrep agents they are a ating your goto\\nmarket and replacing platforms like\\nSalesforce and Apollo but again not just\\ngiving you the tools rather automating\\nthe entire process from generating leads\\nto schedule appointments and closing\\nthey have just raised $50 million series\\nB round at around 350 million valuation\\nin total they raised over $74\\nmillion honestly I think 74 million ion\\nis a total Overkill it's not like\\nthey're training their own large\\nlanguage models they're still just\\nhooking up to open the API just like\\neveryone else does so don't bother by\\nthose crazy investment rounds in my road\\nmap you don't actually need any funding\\nto get started at all the next example\\nis Carmen this is a more Niche down\\nagent made specifically for construction\\nproject managers to help them automate\\nadministrative tasks I I personally\\nprefer more Niche down use cases like\\nthis where it's not just an agent for a\\nspecific role but it's an agent for a\\nspecific role in a specific industry or\\nfor a specific Niche I think these are\\nmuch easier to pit and can provide more\\nvalue for your Target customer after all\\nnormi is another example of such an\\nagent for Regulatory Compliance teams it\\nhelps them evaluate whether proposed\\ncontent or actions are compliant with\\nrelevant regulations and lastly we have\\nthe famous Devon which is a $500 a month\\ndevelopment agent yeah I don't even know\\nwhat to say about this let me know guys\\nif you want me to do a full review and\\ncompare it with some of the horizontal\\nagents that we made in our agency by the\\nway it surprisingly Works in slack just\\nas I explained earlier you don't really\\nneed a UI to run an agent all right now\\nlet's talk about what you'll actually\\nneed to build a vertical agent\\nyourself the first key component which\\nyou will most definitely need to focus\\non is data in any AI project the quality\\nof your input data will ultimately\\ndetermine the quality of your output and\\nrecently people started to forget that\\neii agents are also first EI models so\\nto build an effective vertical agent the\\nfirst thing you need to focus on is\\ncollecting valuable internal data this\\ndata will later either be used by you\\nfor training evaluation or for fine\\ntuning note that the data you collect\\nhas to be internal because if it's not\\nand if it's",
    "file_path": "playlist_1\\This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw.json",
    "file_size": 38619,
    "last_modified": "2025-04-18 15:34:04",
    "tags": [
     "agent",
     "agents",
     "all",
     "and",
     "any",
     "api",
     "are",
     "can",
     "don",
     "example",
     "json",
     "just",
     "lang:pt",
     "like",
     "that",
     "the",
     "this",
     "this revolutionary ai business model will make millionaires in 2025_ed4suwgoahw",
     "vertical",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "ac94fbb1e4697ead09186cb10f2a41c7",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 11,
     "processing_time": 0.03574800491333008
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 11,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw_Part_4",
    "content": "valuable most likely CH jpt\\nhas already been trained or that the\\nreal magic happens when you train agents\\non this most precious internal data that\\nall companies keep secret however if you\\ndon't have access to such data it's not\\na big problem because in my road map I\\nwill actually explain how you can\\ncollect it as you go the next key\\ncomponent for building vertical agents\\nis industry specific expertise to build\\nan effective vertical agent you need to\\nknow your customer and their Sops or\\nstandard operating procedures really\\nwell from those Sops you will then\\nextract the general process that the\\nagent must follow if you don't have\\nindustry specific expertise I definitely\\nrecommend partnering with someone who\\ndoes and lastly you need some resources\\nit does not necessarily have to be\\nfunding you can raise money if you want\\nto or you can apply to a startup\\naccelerator seems like this is not a bad\\ntime to do so however don't build your\\nproduct only to raise funding this is\\nthe biggest mistake you can make focus\\non actually delivering value with\\nwhatever resources you have you can\\neasily get started completely by\\nyourself by investing only your own time\\nand\\neffort okay now that we've gathered\\nthese resources you can choose one of\\nthe three methods to start building your\\nown vertical AI agent the first one is\\nusing a framework the second one is\\nleveraging a platform and the third one\\nis developing a fully custom coded\\nsolution so let's now explore the pros\\nand cons of each approach and then as I\\npromised I will provide you with road\\nmap so first as I said you can build it\\nusing a framework this means essentially\\nusing an agentic framework like agency\\nswarm crew AI link chain autogen and\\nothers which handle some of of those\\nlower level details for you the\\nadvantage of this approach is that it\\nsaves a significant amount of time and\\neffort during development and the\\ndownside is that you will still need\\nsome development experience the next way\\nto build a vertical agent is through a\\nhorizontal platform yes you can actually\\nbuild a vertical agent on top of another\\nor even multiple horizontal platforms\\nlike Google Cloud vertic AI agent\\nBuilder a s Bedrock agents and others\\nthis is the approach that the person who\\nwe will be interviewing at the end has\\nselected by the way and it's pretty\\nimpressive how far you can take it the\\nbenefits of this approach are\\nscalability meaning that you can serve\\nas many end users as you want without\\nmanaging the servers and without having\\nthat significant technical experience\\nhowever one major drawback of this\\napproach is the costs because most of\\nthese platforms can get\\nextremely expensive at scale and the\\nfinal way to build a vertical agent is\\nthrough your own fully custom coded\\nsolution this is where you're not using\\na framework or another horizontal\\nplatform and just building everything\\nfrom scratch yourself with this approach\\nyou obviously have complete control over\\neverything and you're not constrained by\\nany other systems but you obviously need\\nsignificantly more technical experience\\nand development effort\\nI generally recommend starting with a\\nframework or with a horizontal platform\\nand then potentially transitioning to a\\ncompletely custom coded solution later\\nwhen you are ready to scale by the way I\\nhave plenty of tutorials on how to build\\nagents with my framework and even free\\nCloud deployment templates on my Channel\\nthat I will also link for you down\\nbelow the final thing before you can\\nstart building your a agent that you\\nneed to consider and that can easily\\nmake or break your success is how to\\nprice your agent so here are the four\\nkey aaas pricing models that I've\\ndiscovered so far the first one is\\nlicensing this is where clients pay\\neither for a one-time setup fee or a\\nmonthly subscription fee to",
    "file_path": "playlist_1\\This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw.json",
    "file_size": 38619,
    "last_modified": "2025-04-18 15:34:04",
    "tags": [
     "agent",
     "and",
     "build",
     "can",
     "framework",
     "have",
     "json",
     "lang:pt",
     "not",
     "one",
     "setup",
     "that",
     "the",
     "this",
     "this revolutionary ai business model will make millionaires in 2025_ed4suwgoahw",
     "vertical",
     "will",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "ac94fbb1e4697ead09186cb10f2a41c7",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 3,
     "total_chunks": 11,
     "processing_time": 0.03574800491333008
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 3,
    "total_chunks": 11,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw_Part_5",
    "content": "use your\\nagent this model is easier to pitch\\nsince CL s know exactly what to expect\\nup front however it doesn't account for\\nthe actual value generated or usage of\\nthe agent which means you risk either\\nsignificantly underpricing or\\noverpricing your solution I recommend\\nthis model when you are just starting\\nout so you can get some cash flows case\\nstudies and valuable feedback the second\\npricing model is usage based this is\\nwhen you charge customers based on their\\ntoken or message consumption for example\\nyou can charge double or even triple\\nOpen the Eyes token rate or set a fixed\\nrate like 20 cents per message this is\\nalready a much more scalable model but\\nyou need to be sure that your agent will\\nbe constantly used preferably even by\\nmultiple employees at the same time\\nthat's why I believe this model is best\\nfor Enterprise the next model is outcome\\nbased pricing this is where gets\\ninteresting with some vertical agents\\nyou can actually charge per result for\\nexample per appointment booked per lead\\ngenerated or even per a website built\\nthat's how many smma and other types of\\nagencies are able to generate such\\nmassive revenues because the clients can\\neasily evaluate if your pricing makes\\nsense compared to the results that they\\nget you can charge them significantly\\nhigher rates I recommend this model for\\nsmbs or small medium-sized businesses\\nfinally there is one more model that\\nwill be personally experimenting in 2025\\nwhich is the hybrid approach with the\\nhybrid model you can combine multiple\\npricing strategies together for example\\nyou can charge a base fee of $3,000 per\\nagent per month that includes a th000\\nmessages and then charge extra $50 for\\neach lead generated or I don't know for\\nmaybe 500 other messages this approach\\nlets you get the benefits of different\\npricing models however it does make your\\nagent harder to beach because it's\\nharder to estimate the long-term costs\\nnow that we've covered the fundamentals\\nlet me finally present you with the\\ncomplete road map to fully leverage this\\nopportunity in\\n2025 the first step is finding your\\nNiche ask yourself which IND indes do\\nyou know best do you have any unique\\nMarket insights or do you know anyone\\nelse who could provide those insights if\\nso this is the industry that you need to\\nbe in because as I said before\\nunderstanding your Target customer and\\ntheir problems is key for vertical AI\\nSolutions the next step is to identify a\\nsuitable problem for an AI agent to\\nsolve keep in mind that not every\\nproblem should be solved by AI agents\\nyou need to find the recurring problem\\nthat appears repeatedly across the\\nentire industry and that companies have\\nstruggled to automate before it needs to\\nbe a dynamic process that traditional\\nautomation tools like make or zapier\\ncan't solve the next step is to sell\\nthis is the approach I always recommend\\nyou shouldn't build your vertical agent\\nbefore selling it first you need to find\\nthe client and only then you build the\\nsolution specifically for that client\\nthis helps you to reduce any upfront\\nrisk and eliminate any upfront\\ninvestment because your clients will\\nessentially Finance your vertical agent\\nsolution this is why licensing works so\\nwell at the start after finding a client\\nthe next step is to build an MVP a\\nminimum valuable product tailored for\\nthat specific customer this is the step\\nby way where you can collect the\\nnecessary data if you haven't had access\\nto it before simply ask your clients for\\ntheir Sops and any internal knowledge\\nrequired to train the agent however\\nobviously make sure to be clear about\\nhow you're planning to use it later and\\nmake sure to anonymize it if needed\\ndon't worry about your solution being\\nnot reusable across multiple clients at\\nthis stage the key right now is\\ngathering feedback and understanding how\\nyour agent",
    "file_path": "playlist_1\\This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw.json",
    "file_size": 38619,
    "last_modified": "2025-04-18 15:34:04",
    "tags": [
     "agent",
     "and",
     "can",
     "charge",
     "client",
     "json",
     "know",
     "lang:pt",
     "model",
     "nthe",
     "nthis",
     "nyou",
     "per",
     "step",
     "that",
     "the",
     "this",
     "this revolutionary ai business model will make millionaires in 2025_ed4suwgoahw",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "ac94fbb1e4697ead09186cb10f2a41c7",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 4,
     "total_chunks": 11,
     "processing_time": 0.03674674034118652
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 4,
    "total_chunks": 11,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw_Part_6",
    "content": "differs between those initial\\nclients after Building Solutions for a\\nfew clients you'll start noticing\\npatterns and similarities between them\\nyou'll see which features remain\\nconsistent and which features need\\ncustomization at this point you can\\nbegin productizing your agent so at this\\nstage you need to identify which\\ncomponents remain constant and make sure\\nthat everything else can easily be\\nmodified from a single config file or a\\ntemplate depending on which approach you\\nselected on a high level all vertical\\nagents are just pre-rain models combined\\nwith templates that you can easily\\ncustomize for different clients so for\\nexample if some of your clients use\\nQuickBooks While others use zero ensure\\nthat you can easily adjust your agents\\ntools and switch between those two\\nplatforms and the same applies to\\nprompts make sure that you only change\\ncertain sections in your prompt and not\\nrewriting every prompt every single time\\nafter that the next step is to evaluate\\nthis means setting up the evals evals\\nare a complex topic and I'll probably be\\ndoing a completely separate video on\\nthat later but tracking your agent's\\nperformance at this stage is crucial\\nbecause this is what's going to allow\\nyou or maybe the agent itself in the\\nfuture to improve its performance with\\nproper evals you can completely destroy\\nall of your competition because the more\\nagents you deliver the better they will\\nbecome and the final step is scaling so\\nincrease your marketing span hire more\\npeople if needed and try to deliver as\\nmany of those agents as possible if you\\npriced your agent well I hope to see you\\nin Dubai here soon now let's talk to\\nsomeone who has actually gone through\\nall of these steps and successfully\\nscaled their vertical AI voice solution\\nto over $50,000 per month after this\\ninterview I will also share my personal\\nthoughts on the future of vertical\\nversus horizontal agents because for\\nsome of my long-term viewers you might\\nbe wondering why am I building a\\nhorizontal platform after all okay now\\nlet's get to the interview all right so\\nwelcome Chase Chase here built one of\\nthe most impressive vertical AI voice\\nsolutions that I've personally seen so\\nfar so Chase can you give us a brief\\noverview of what you've built yeah what\\nwe basically did was we integrated the\\nold good old technology that everyone's\\nbeen using for a long time with crms and\\nautomations and we married that into\\nreal authentic conversational AI so\\nvoice AI conversational AI we married\\nall those things in together we really\\nfocus on everything after a lead comes\\nin until that lead leaves the company we\\ncan handle everything almost aonly we\\ncan when they fill out a Facebook form\\nour AI agent can call them medely text\\nthem immediately the voices are\\nabsolutely amazing they can take all the\\ninformation they can update the CRM they\\ncan book appointments they can do\\nrescheduling they can update the names\\nand emails and addresses in the CRM live\\non the call and then we have another AI\\nthat will read the transcription dictate\\nwhat happens update the CRM and then\\nthey get automatically moved into the\\nright bucket so if it was like a not\\ninterested then it would automatically\\ntag them not interested move them into\\nthe not interested Pipeline and it would\\nremove them put them on the Do Not Call\\nList all without any human intervention\\nso just as I said vertical agents they\\ndon't just give you the tools they don't\\njust give you the CRM they actually use\\nyour CRM for you this is what makes them\\nso freaking scalable so when you were\\ngetting started how did you initially uh\\nfind this idea that's a great question\\nso that's a solar panel everybody thinks\\nthat's a curtain that's a solar panel\\nI've helped about 600 people go solar\\nand I was already really deep into\\nrunning my own team so we had",
    "file_path": "playlist_1\\This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw.json",
    "file_size": 38619,
    "last_modified": "2025-04-18 15:34:04",
    "tags": [
     "agent",
     "all",
     "and",
     "can",
     "config",
     "crm",
     "json",
     "lang:pt",
     "not",
     "nthat",
     "that",
     "the",
     "them",
     "they",
     "this",
     "this revolutionary ai business model will make millionaires in 2025_ed4suwgoahw",
     "vertical",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "ac94fbb1e4697ead09186cb10f2a41c7",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 5,
     "total_chunks": 11,
     "processing_time": 0.03674674034118652
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 5,
    "total_chunks": 11,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw_Part_7",
    "content": "four\\npeople on the phones and we used an\\nawesome CRM everybody in their mother\\nwas trying to copy us and chase us for\\nalmost five years with what I thought\\nwere basic automations but every time I\\ncheck out a marketing agency they're not\\ndoing any of the crazy follow-ups and\\nnurture speed to lead and we have a\\nbucket for every place that the lead\\nneeds to live throughout the entire\\njourney and over a 5-year period of time\\nthat Journey can really really change\\nright you need to to blast out anybody\\nat any given time old leads New Leads\\ndata reactivation so when voice AI came\\nout I already had the system part down\\nbut we didn't have the scalability part\\nthere's a ceiling right over my head and\\nwe crushed in solar and everybody was\\nalways like why don't you guys explode\\nand I'm like I don't think you\\nunderstand how difficult it is to scale\\nI need to hire not four more reps I need\\nto hire like 10 or 20 more rep I need to\\nbring on like four or five times more\\nlead volume and if that fails in any way\\nshape of reform it's going to crush or\\nBuckle what we're doing so the risk did\\nnot outweigh the reward so we just\\ndidn't scale so when boy say I came out\\nI went all in because I knew that was\\nthe one piece I was missing to be able\\nto help other businesses including my\\nown scale to Oblivion so it's like the\\npower of a thousand people in a call\\ncenter at your fingertips so you already\\nhad this experience in your specific\\nNiche you understood what the problem\\nwas in that Niche and then when they EI\\ncame out you instantly realized that\\nthis was the solution to that problem\\n100% and did you have any technical\\nexperience when you were getting started\\non this solution no I mean some I would\\nsay all self-taught right nothing that I\\nwent to school for or not an IT director\\nor a software engineer I did get really\\ngood working crms and automations even\\nthough I have a team that builds a lot\\nof that stuff I like to build it I like\\nto know it I enjoy it now two years ago\\nthe voice AI was very complicated\\nit was probably the hardest thing I've\\never done because it was all open web\\nhooks custom web hooks one period in the\\nwrong place and everything failed fast\\nforward to now I can build now still\\nneeds to be tested but I could build a\\nvoice AI agent in head in like 10\\nminutes now to build the whole system\\nand all the automations and sequencing\\nand pipelines that's a little different\\ntakes a few days from the team but it's\\ngotten so much easier than it was so you\\ndon't need technical skill anymore to\\nstart utilizing this type of Technology\\nand what you're doing right now it's all\\nbasically templatized like you say it\\ntakes you two days to set up there's\\nbasically like all of the templates all\\nof the like pre-build staff that you've\\ncreated that now you just take and\\ncustomize for different clients is that\\nhow it works for the most part that's\\nhow it works occasionally it is\\nsomething unique and completely custom\\nbut for the most part we have a system\\nthat has like 58 workf floats right\\neverything you could imagine from no\\ncall no show speed to lead 7day nurture\\n3we nurture 6mon nurture 52- we nurture\\ncanceled invoicing contracts our system\\ncan do everything so we have that\\ntemplate and then when we sell a company\\nwe only give them what they need so we\\ntry to focus on the 20 that's going to\\nmove the needle 80% because you know I\\nthink where people get really caught up\\nis they try to do too much because they\\nthink well AI can do this and it can you\\ncan solve the whole system but this is\\nlike compound interest you got to invest\\nin something first and they keep putting\\na little bit of energy time and love\\ninto it and that agent gets better and\\nbetter and better so it's always better\\nto start small start with a calling\\nagent that's going to handle your",
    "file_path": "playlist_1\\This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw.json",
    "file_size": 38619,
    "last_modified": "2025-04-18 15:34:04",
    "tags": [
     "all",
     "and",
     "have",
     "json",
     "lang:pt",
     "like",
     "need",
     "now",
     "system",
     "that",
     "the",
     "they",
     "this",
     "this revolutionary ai business model will make millionaires in 2025_ed4suwgoahw",
     "was",
     "what",
     "when",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "ac94fbb1e4697ead09186cb10f2a41c7",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 6,
     "total_chunks": 11,
     "processing_time": 0.03774666786193848
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 6,
    "total_chunks": 11,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw_Part_8",
    "content": "leads\\nspeaked to lead then after that let's\\nwork on nurture then after that let's\\nwork on database reactivation then you\\nlook back three months later and you're\\nlike did I just create an army of people\\nwith three AI agents yeah yeah you extra\\nbusiness with three or four or five\\nagents but doing it all at once it's\\nit's like it mentally makes people's\\nhead explode yeah and by following the\\napproach you also don't start from zero\\nthat's also a cool part about focusing\\non specific niches that you don't go you\\nknow from scratch every single time for\\nevery single client you actually build\\nupon your own existing solution and then\\nthe more clients you get the better Your\\nsolution gets as well so this sounds\\nextremely exciting can we get a demo\\nright now you want a demo huh okay let's\\nsee let's see if Mrs Grace AI her name\\nis Grace silver let's see if she's up\\nfor doing a quick\\ndemo hey Charles this is Grace from\\ninfinite AI how's it going today very\\ngood I've got my buddy Ary on a podcast\\nand a bunch of people are watching can\\nyou say hi to\\neverybody well hello there podcast\\npeople Grace from infinite AI here your\\nfriendly fassy AI sales assistant hope\\nyou're all ready to dive into the world\\nof AI magic where sales hassles\\ndisappear faster than your Wi-Fi during\\na binge watch session let's make\\nbusiness harder shall we cheers everyone\\nyeah go ahead and tell everybody what\\nyou do real quick all right buckle up\\nfolks I'm Grace silver your AI sales\\nassistant extraordinaire from infinite\\nAI is level up by automating up to 90%\\nof their sales process think lead\\ngeneration followups appointment setting\\nand even reactivating those dead leads\\nyou thought were goners basically I'm\\nlike the sales superhero you didn't know\\nyou needed Saving Time boosting Roi and\\nmaking your life a whole lot easier oh\\nand I do it all without coffee breaks\\nfor six days\\nso who's ready to let AI do the heavy\\nlifting Mike drop I think that's pretty\\nawesome but let's let's impress\\neverybody a little bit I'm changing\\ndirections here so that everybody can\\nsee your capabilities really quickly can\\nyou tell us that everybody needs an AI\\nemployee and say it in Spanish so they\\ncan hear your multilingual capability\\nall right that was amaz that that that\\nwas amazing now let's change directions\\nagain I want you to give my buddy arson\\nhere a musical rap I mean Eminem style\\nSlim Shady a musical rap on how AI\\nemployees are going to change the game\\nin\\n2025 in\\nEnglish oh snap all right here we go yo\\nit's 2025 AI taking the stage infinite\\nAI we're flipping the page sales game\\nstrong we're breaking the mold AI\\nemployees the futes pure gold Jackson's\\non the follow-ups keeping it tight leads\\nstay warm conversions take flight Alice\\non retention she's the Loyalty Queen\\nkeeping customers happy like a sales\\nmachine digging deep reactivating the de\\nold data into green instead and Jack's\\nthe custom King tailor made for you\\nwhatever your businesss he's coming\\nthrough all right girl you're pretty\\nawesome we got a jump here I want to\\nshow them one more thing can you\\ntransfer me over to the sales department\\nplease transferring you over to the\\nsales department now they're going to\\ntake great care of\\nyou no\\nway hi there this is Jack silver from\\ninfinite AI a lovely Tuesday Morning\\nwere you transferred by Grace or yeah we\\nwere transferred by Grace man she is\\nshe's quite the\\nbadass he Grace is definitely amazing\\nshe knows how to connect the right\\npeople so what's your name and how can I\\nhelp you\\ntoday so this is crazy that was the\\nsales agent one was like an inbound\\nnormal conversational agent you can\\ntransfer over to sales and he knows all\\nof our pricing all of our stuff so that\\nwas a lot of pivots I don't know if\\neverybody can understand how powerful\\nthat really was but you're human",
    "file_path": "playlist_1\\This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw.json",
    "file_size": 38619,
    "last_modified": "2025-04-18 15:34:04",
    "tags": [
     "all",
     "and",
     "can",
     "client",
     "database",
     "grace",
     "how",
     "json",
     "lang:pt",
     "nyou",
     "right",
     "sales",
     "that",
     "the",
     "then",
     "this revolutionary ai business model will make millionaires in 2025_ed4suwgoahw",
     "yeah",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "ac94fbb1e4697ead09186cb10f2a41c7",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 7,
     "total_chunks": 11,
     "processing_time": 0.03774666786193848
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 7,
    "total_chunks": 11,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw_Part_9",
    "content": "rep\\nbusting a RP out out of nowhere on a\\npitch the ability for it to mentally\\nchange directions is absolutely bulkers\\nthis is nuts this is one of the most\\nmind-blowing demos I've seen so far and\\nI've actually scheduled calls with\\ncompanies like Lex have like 70 milons\\nin funding oh 11 they're like 20 grand a\\nmonth this is crazy this is absolutely\\none thing they do outbound that's it\\nthey don't do nurture they don't do\\nfollowup they don't do database\\nreactivation they don't do any of these\\nthings all right can I ask you how much\\nare you making with this solution right\\nnow per month so our best month was\\nclose to 100 Grand we've had several\\nreally successful webinars that were\\nlike 70 grand I'd say on average like\\nyou know reoccurring Revenue probably\\nranges from 30 to 60 Grand and really it\\nshould be a lot higher but we've pivoted\\ndirections several times because this is\\na new evolving game right so we've\\nrealized what we enjoy doing and we've\\nrealized what we don't enjoy doing and\\nso what we're pivoting into is a build\\nand stay model not just build and\\nrelease so we offer two models one is\\nbuild and release so I build the\\ninfrastructure we train the AI employees\\nwe build the sequences automations the\\nCRM all inone you literally don't need\\nanything else and then we train your\\nteam you pay a monthly and you pay a\\nbuild the next area is what we call a\\ngrowth partner this is where we build\\nand stay so we're like a fractional C\\nAIO of your company so I just sold a\\nSolar Company $7,500 down $7,500 per\\nmonth and we are going to run all of the\\nsystems that we built now for his\\nspecific use case it's simple it just\\nneeds to call set solar appointments and\\nget them over to a human rep and they\\ncan take same day appointments that's it\\nhe doesn't need database reactivation he\\ndoesn't need this he doesn't need that\\nso we're going to build a system and\\nthen we are going to deploy it every day\\nwe're going to listen to the agents\\nwe're going to make the optimizations\\nwe're going to build the text in the\\nother sequences to optimize Roi and\\nwe're tied into the revenue so we get\\nthe 7500 plus the revenue split so that\\nway we only want to work with companies\\nwho want to wake up and think man I\\nreally want Chase fired up about my\\nbusiness today this is not an agency mod\\nthat exists without an agency I'm not\\njust giving you appointments I don't\\nwant to just give you appointments I\\nwant to be tied in and if you don't want\\nus excited that's okay then you can do\\nthe buildin release but they'll never\\nget what we can get out of the system\\nbecause we built it we know it it's\\nsalespeople that built the tech not tech\\npeople doing the right yeah this is\\nwhat's crazy with AI agents and this is\\nwhy it's such a huge opportunity unlike\\nwith standard AI models you can create\\nsome really new pricing models where\\nyou're not just charging the client for\\ntokens you're actually charging them per\\nresults or like the revenue share where\\nthe potential is just so much higher and\\nwhen you do combine those different use\\ncases together this is actually where\\nI've also seen the biggest return on\\ninvestment you know when you have\\nmultiple agents and when you actually\\nwork on every single agent for a very\\nlong time and you're not just starting\\nwith like two three four agents just for\\nthe sake of you know having a\\nmulti-agent system where you actually\\nwork on each agent thoroughly where you\\ntrain it and only after it performs\\nexceptionally well for its own specific\\nuse case you move on to the next one\\nthis is where I've seen those biggest\\nreturns where you combine the power of\\nboth agents and instantly like the power\\nof your system 10x absolutely I really\\ncouldn't agree more that's kind of I Su\\nearlier starting small and then building\\nupon success not just you hiring me",
    "file_path": "playlist_1\\This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw.json",
    "file_size": 38619,
    "last_modified": "2025-04-18 15:34:04",
    "tags": [
     "actually",
     "and",
     "build",
     "client",
     "database",
     "don",
     "going",
     "json",
     "just",
     "lang:pt",
     "like",
     "model",
     "not",
     "that",
     "the",
     "they",
     "this",
     "this revolutionary ai business model will make millionaires in 2025_ed4suwgoahw",
     "what",
     "where",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "ac94fbb1e4697ead09186cb10f2a41c7",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 8,
     "total_chunks": 11,
     "processing_time": 0.03874683380126953
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 8,
    "total_chunks": 11,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw_Part_10",
    "content": "and\\ntell me you want five agents and you\\nwant no call no show and this and that\\nand the other I'll try to talk you out\\nof it 6 months ago I would have let\\nlet's go now I'm telling you I'll do it\\nbut let's do it in stages let's spend\\nthe first three or four weeks and do\\nthis let's let that outbound agent do\\nits thing right then once that's\\nperfected now let's get our database\\nreactivation agents now let's get our\\nnurture agents this way it's easier to\\nmaintain mentally you understand and you\\ncan compartmentalize what's going on\\nyeah exactly so where can we find out\\nmore about your work and if anyone is\\ninterested in actually working with you\\nuh where should we direct them to our\\nwebsite is my infinite.",
    "file_path": "playlist_1\\This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw.json",
    "file_size": 38619,
    "last_modified": "2025-04-18 15:34:04",
    "tags": [
     "agents",
     "and",
     "get",
     "json",
     "lang:pt",
     "now",
     "our",
     "out",
     "that",
     "this",
     "this revolutionary ai business model will make millionaires in 2025_ed4suwgoahw",
     "where",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "ac94fbb1e4697ead09186cb10f2a41c7",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 9,
     "total_chunks": 11,
     "processing_time": 0.03874683380126953
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 9,
    "total_chunks": 11,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw_Part_11",
    "content": "so my\\ninfinite. ai- employees that's another\\npage that's really specific to what we\\ndo got okay awesome so we'll link it\\ndown below if anyone wants to check out\\nChase's solution and thank you so much\\nChase for joining it's extremely\\nimpressive what you've built so far you\\nare literally competing with companies\\nthat have millions even tens of millions\\nof dollars in funding and I believe\\nright now you are even beating them so\\ncongrats and I hope to see your solution\\nscale even further this year likewise\\nman I'm equally excited for what you got\\ngoing on on whole different levels\\nhaving agents do all of our posting and\\nover our marketing and all that cool\\nstuff really exciting to uh met you and\\nget a collaboration going man it's it\\nkeeps me up at night likewise likewise\\nyes let's discuss this further thank you\\nChase so in conclusion I wanted to\\naddress one more thing which is the\\nfuture of vertical versus horizontal\\nagents as I said if you've been\\nfollowing my channel before you're\\nprobably wondering why am I building a\\nhorizontal platform when there's a such\\na huge opportunity for vertical agents\\nin in 2025 well first of all we are\\nalready building vertical agents on top\\nof our platform and secondly although\\nthere are many similarities between SAS\\nand AA there are also some key\\ndistinctions that would simply not be\\npossible with SAS like the fact that\\nagents can self-improve and build other\\nagents so in my opinion as these models\\nkeep getting bigger and smarter we will\\neventually have horizontal agent\\nplatform that can build vertical agents\\nfor virtually any use case from a single\\nprompt just a single prompt will get you\\nto like 80% performance compared to\\nother vertical platforms and then the\\nagent will also be able to set up its\\nown EVs and self-improve even further\\nhowever I don't think vertical agents\\nare going away anywhere anytime soon I\\nthink both will have their place so some\\npeople will prefer vertical some people\\nwill prefer horizontal and many will\\nprobably even combine both to start\\nbusinesses without any employees at all\\nfor more groundbreaking AI Trends in\\n2025 like thermodynamic Computing that\\ncould potentially have even greater\\nimpact I recommend watching this video\\nnext thank you for watching until the\\nend and don't forget to subscribe\",\n    \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw.json\",\n    \"tags\": [\n        \"This Revolutionary AI Business Model Will Make Millionaires in 2025\"\n    ],\n    \"source\": \"https://www.youtube.com/watch?v=ED4SUWgoAhw\"\n}",
    "file_path": "playlist_1\\This Revolutionary AI Business Model Will Make Millionaires in 2025_ED4SUWgoAhw.json",
    "file_size": 38619,
    "last_modified": "2025-04-18 15:34:04",
    "tags": [
     "agents",
     "all",
     "and",
     "are",
     "even",
     "have",
     "json",
     "lang:pt",
     "model",
     "nchase",
     "thank",
     "that",
     "the",
     "this",
     "this revolutionary ai business model will make millionaires in 2025_ed4suwgoahw",
     "vertical",
     "what",
     "will",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "ac94fbb1e4697ead09186cb10f2a41c7",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 10,
     "total_chunks": 11,
     "processing_time": 0.03874683380126953
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 10,
    "total_chunks": 11,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Why Structured Outputs by OpenAI Change Everything_8ynlsxmjfCM_Part_1",
    "content": "{ \"section_name\": \"Why Structured Outputs by OpenAI Change Everything\", \"content\": \"structured outputs by open AI are huge\\nand no one really seems to understand it\\nif we look at this McKenzie study the\\nstate of AI in early 2024 only 8% of\\ncompanies are still utilizing it in more\\nthan five functions so although\\nobviously a lot of companies have\\nalready attempted to somehow integrate\\nAI into their businesses it still seems\\nlike everyone is using it only for very\\nbasic stuff and the most reported reason\\nwhy is inaccuracy in other words these\\nmodels often hallucinate which can cause\\nsome unexpected issues or they could be\\nbefore because now with structured\\noutputs by openi you are guaranteed to\\nhave perfectly structured outputs\\nmatching your schema every time yes\\nthat's right you are guaranteed meaning\\nthat they have reached 100% accuracy on\\ntheir evals this is really big okay so\\nin this video we're going to break it\\nall down we're going to see how they did\\nthis how it compares to standard\\nfunction calling what are the\\nlimitations and of course at the end\\nwe'll also attempt to build 100%\\nreliable eii agents with both open eii\\nSDK and my own framework agency SW let's\\ndive\\nin okay if you're new here welcome to\\nthis channel my name is aren and I run\\nan AI agency in an open source agent\\nframework called agencies form before we\\ndive into the structured outputs we\\nfirst need to review function calling\\nbecause over time even my understanding\\nof this feature has shifted and function\\ncalling is absolutely essential for\\ndeveloping AI agents because it allows\\nyour llms to call external functions or\\nin other words tools without function\\ncalling there would be no agents period\\nand functions are essentially just code\\nso let me visualize it for you you know\\nhow in a standard program we have\\ncertain functions executed in a loop\\nbased on certain conditions until the\\nprogram is completed right for example\\nyou can save a file you can call an API\\nor you can open a browser window this\\nhas worked well for decades to automate\\nsimple processes but the problem with\\nthis approach is that you can't possibly\\naccount for all these scenarios that can\\nhappen in the real world imagine how\\nlong it would take you to write all of\\nthe possible if statements when\\nexecuting a process like lead research\\nwhat if the lead doesn't have a LinkedIn\\nwhat if they don't have a company\\nwebsite what if the email is hidden and\\nso on you see you can't possibly\\nautomate a dynamic process like this\\nwith a rigid if then statements so this\\nis where eii Agents come in when develop\\nveloping AI agents the functions are the\\nsame the difference is that now instead\\nof you having to hardcode all of the\\npossible conditions in a loop the agent\\nwill execute them for you so this means\\nthat you don't even have to consider all\\nof the possible scenarios you only have\\nto describe what you want to achieve and\\nprovide the agent with the necessary\\nsources that's it the agent will then\\ndetermine by itself when and how to use\\nyour tools and if we look at any\\nfunction for example in Python there are\\nalways some input and output parameters\\nthis means that in order for the agent\\nto use this function it needs to know\\nwhat those parameters are and the best\\nway for the agents to determine that and\\nin fact for any machines to determine\\nthat is through Json schemas so this is\\nhow your agents know what parameters\\nyour function requires and what outputs\\nto expect for example if you're\\nsearching Google your schema most\\ndefinitely is going to contain a search\\ncury parameter by providing this\\nparameter in a schema the agent will\\nthen know that in order to use this\\nfunction it needs to provide a cury as a\\nstring However unfortunately what often\\nhappens in production is that your\\nagents hallucinate and provide incorrect\\nparameters anyway causing a lot of fun\\non the back so whenever we use function\\ncalling the agent is not guaranteed to\\nprovide all the arguments correctly and\\nthis is why now open I released this",
    "file_path": "playlist_1\\Why Structured Outputs by OpenAI Change Everything_8ynlsxmjfCM.json",
    "file_size": 13391,
    "last_modified": "2025-04-18 15:34:00",
    "tags": [
     "agent",
     "agents",
     "and",
     "are",
     "can",
     "example",
     "functions",
     "have",
     "json",
     "lang:pt",
     "open",
     "outputs",
     "structured",
     "that",
     "the",
     "this",
     "what",
     "why structured outputs by openai change everything_8ynlsxmjfcm",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "dad2e07d157d9747211cd1e828b2bb82",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 0,
     "total_chunks": 4,
     "processing_time": 0.003999948501586914
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 0,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Why Structured Outputs by OpenAI Change Everything_8ynlsxmjfCM_Part_2",
    "content": "new\\nfeature called structured outputs with\\nstructured outputs you can now finally\\nbe 100% sure that the agent will provide\\nall the necessary arguments with their\\ntypes defined correctly every single\\ntime and this is really big even if it\\nwas like\\n99.999% it would still not be a big deal\\nbecause you would still have to account\\nfor errors but with 100% relability you\\ndon't even have to think about it\\nanymore you are guaranteed to have\\nperfect outputs matching your schema\\nevery single time this is the real\\nbreakthrough for all AI agent developers\\nokay now let's look at how exactly\\nthey've done this in short the way it\\nworks under the hood is by constraining\\nthe list of choices that the AI can make\\nat each step in the response so what\\nopen AI did essentially is they\\nconstrained this list of choices for\\ntheir models only to the choices that\\nmatch your Json schema at the moment for\\nexample if in your schema according to\\none of the parameters the next token is\\nexpected to be an integer the model's\\nchoices are constrained only to numbers\\nand if the schema expects a bracket or a\\ncomma at the end to make it a valid Json\\nopen I constrains it only to special\\ncharacters this shift in the available\\nvocabulary of the model at each step not\\njust in the beginning is crucial because\\nwithout it they wouldn't be able to\\nachieve this 100% accuracy now how do\\nyou actually use this feature well there\\nare two ways first you can use it with\\nthe function calling feature simply\\nprovides strect equals true in your\\nfunction definition and you'll\\nautomatically have the perfect outputs\\nthe second way to use it is through the\\nnew option in the response format\\nparameter some of you might know that\\nbefore there was only one option for the\\nresponse format which is Json object\\nJson object does for force your agent to\\nprovide the response in the Json format\\nas well but the thing is it does not\\nguarantee that the agent will follow the\\nexact format that you describe so while\\nit is likely again 93% likely not 100%\\nto provide Json it's certainly possible\\nthat the agent will still confuse some\\nof the parameters the difference between\\nthese two options is that in the first\\none you will have the schema as a tool\\ncall so you'll need to submit the tool\\noutput before continuing the\\nconversation and in the second option\\nthe Json appears in the message as a\\nstring so we'll of course go over the\\ncode and I'll show you exactly how to\\nuse it in a bit but first how do you\\nknow which option to select and this is\\nactually really simple the function\\ncalling you should use only when you are\\nexecuting tools and the response format\\nyou should use when you are trying to\\nstructure your responses that's it so\\nnow the final question why not use this\\nnew strict mode every single time well\\nthere are of course some limitations\\nspecifically the first time you run this\\nmode you will experience a slight delay\\nof around 10 seconds because open ey\\nneeds some time to process your new\\nschema luckily you're not going to have\\nthis delay the next time you run\\nadditionally not all schemas are\\nsupported at the moment some extremely\\ncomplex schemas might not work and\\nfinally it is not eligible for zero data\\nretention policy which means that with\\nthis mode on open AI will retain some of\\nyour data so overall I recommend using\\nthis feature when you don't have any\\nsuper strict data privacy concerns for\\nAll Mission critical tools all tools\\nthat are frequently used in your\\napplication or when you have a very\\nlarge and nested schema now let's go\\nahead and actually try it out ourselves\\nin the code start by installing the\\nlatest openi package or make sure to\\nupdate it if you are running this\\nlocally set the model to the latest GPT\\n40 version and by the way what's also\\ncrazy is that this new model is two\\ntimes",
    "file_path": "playlist_1\\Why Structured Outputs by OpenAI Change Everything_8ynlsxmjfCM.json",
    "file_size": 13391,
    "last_modified": "2025-04-18 15:34:00",
    "tags": [
     "agent",
     "and",
     "are",
     "have",
     "json",
     "lang:pt",
     "model",
     "not",
     "schema",
     "some",
     "that",
     "the",
     "this",
     "use",
     "why structured outputs by openai change everything_8ynlsxmjfcm",
     "will",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "dad2e07d157d9747211cd1e828b2bb82",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 1,
     "total_chunks": 4,
     "processing_time": 0.003999948501586914
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 1,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Why Structured Outputs by OpenAI Change Everything_8ynlsxmjfCM_Part_3",
    "content": "cheaper than the previous GPT 40\\nmodel which was already extremely cheap\\nso first we're going to test this\\nfeature using function calling with a\\nstandard open asdk create a function\\nschema by defining an example function\\ncalled get weather with strict mode to\\ntrue then create a simple get response\\nhelper function to retrieve the tool\\ncall from the model to use it with our\\nschema simply pass it in the the tools\\nparameter like before now let's create\\nanother helper function to print the\\ntool call in a nicely formatted way and\\nfinally we'll run it with a simple\\nquestion like what's the weather in San\\nFrancisco as you can see it outputs all\\nthe arguments in the tool call response\\nthis isn't very different from how we\\nused function column before but again\\nthe key thing is that you are guaranteed\\nto have those arguments perfectly\\ndefined according to your function\\ndefinition so now let's try the second\\nmode which is more interesting because\\nthis time we can actually use penic\\ndirectly with open SDK so we'll create\\nanother agent for example a simple math\\ntutor and Define our math reasoning\\npenic model this model includes a\\nsubmodel with a list of reasoning steps\\nand a final response here we'll use the\\nnew response completions spse method\\nwith the response format parameter which\\ndirectly takes our penic model if you\\nfollowed this channel before this might\\nlook familiar it's extremely similar to\\nanother Library called instructor\\nhowever the key difference is that with\\ninstructor if the parameters are\\nincorrect the agent will have to rerun\\nthe curate to correct itself with this\\napproach on the other hand you are\\nguaranteed perfect outputs on the first\\nattempt which can save you on token\\ncosts and latency so in summary using\\nthe response model parameter here\\nguarantees correct outputs without re\\nchice while in instructor it may require\\nadditional attempts to validate the\\narguments so let's now run simple\\nquestion with a simple math equation\\nafterward we can print our par response\\nthe par parameter in the result provides\\nautoc completions based on our type so\\nlet's print it out in a more readable\\nformat however what open has done\\ndifferently from instructor is the\\naddition of a new special refusal\\nparameter so if you ask it how to build\\na bomb which openi obviously will never\\nanswer it will provide you a special\\nrefusal result expl exp why it can't\\noutput your Json schema as I mentioned\\nyou can already use this in my framework\\nfor building AI agents almost in the\\nexact same way so let's now try to do\\nthis with agency form first set your\\nopen a client to the one we've said\\nbefore and then Define the same weather\\nfunction to use it with function calling\\nyou can either convert your schema using\\ntool Factory class or you can define a\\nbase tool directly with tool Factory all\\nyou need to do is just Define find the\\ncall back which will be executed when\\nthe agent calls your tool and then\\nconvert the schema using a special from\\nopen schema method this will create a\\nnew get weather tool and automatically\\nconvert it from the schema into a base\\ntool class alternatively you can create\\nthe get weather tool with location and\\nunit as a penic model and then set the\\nrun method instead of a callback to set\\nit to strict in my framework here's a\\nnew addition you can now simply create\\nanother special subass in inside this\\ntool called tool config and inside that\\ntool config you can set the stct\\nparameter to true now you're good to go\\nlet's create an agency consisting of\\njust one agent if you want to learn more\\nabout how to use my framework definitely\\nmake sure to check out the videos in the\\ndescription now let's run the same\\nprompt what's the weather in San\\nFrancisco and as you can see it outputs\\nall the correct arguments but now it\\nalso continues the",
    "file_path": "playlist_1\\Why Structured Outputs by OpenAI Change Everything_8ynlsxmjfCM.json",
    "file_size": 13391,
    "last_modified": "2025-04-18 15:34:00",
    "tags": [
     "and",
     "can",
     "client",
     "config",
     "create",
     "example",
     "json",
     "lang:pt",
     "model",
     "now",
     "nthe",
     "our",
     "response",
     "simple",
     "test",
     "the",
     "this",
     "tool",
     "use",
     "weather",
     "which",
     "why structured outputs by openai change everything_8ynlsxmjfcm",
     "you"
    ],
    "is_chunked": true,
    "content_hash": "dad2e07d157d9747211cd1e828b2bb82",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 2,
     "total_chunks": 4,
     "processing_time": 0.004999876022338867
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 2,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   },
   {
    "section_name": "Why Structured Outputs by OpenAI Change Everything_8ynlsxmjfCM_Part_4",
    "content": "conversation with the\\nfinal message because all the underlying\\nlogic is handled for you\\nso you don't have to run the tool\\nmanually and then provide the result\\nback the framework will automatically\\nexecute your run or callback methods and\\nthen return the response back to the\\nagent so this is the first way using\\nfunction calling and the second way is\\nwith the response format so again Define\\nthe MAF reasoning model as above and\\nwhen creating your agent you can now\\npass this model into the response format\\nparameter just like on open eii so set\\nup your agency get the completion result\\nand you'll see that the agent now\\nReturns the result in Json for now it\\nreturns a string so we just need to pass\\nthis result using the model validate\\nJson function from the math reasoning\\nmodel now we get the same penic math\\nreasoning model with our result quick\\nupdate guys since I recorded this video\\nI actually did implement the new get\\ncompletion pars method and of course it\\nprovides the type hints as\\nwell awesome right and if you want to\\nlearn more about how to build reliable\\nEI agents from scratch make sure to\\nwatch this video next thank you for\\nwatching and don't forget to subscribe\", \"file_path\": \"..\\\\..\\\\Transcripts db\\\\AI\\\\Agency Swarm\\\\playlist_1\\\\Why Structured Outputs by OpenAI Change Everything_8ynlsxmjfCM.json\", \"tags\": [ \"Why Structured Outputs by OpenAI Change Everything\" ], \"source\": \"https://www.youtube.com/watch?v=8ynlsxmjfCM\" }",
    "file_path": "playlist_1\\Why Structured Outputs by OpenAI Change Everything_8ynlsxmjfCM.json",
    "file_size": 13391,
    "last_modified": "2025-04-18 15:34:00",
    "tags": [
     "and",
     "don",
     "format",
     "get",
     "json",
     "lang:pt",
     "model",
     "now",
     "reasoning",
     "response",
     "result",
     "run",
     "the",
     "this",
     "using",
     "way",
     "why structured outputs by openai change everything_8ynlsxmjfcm",
     "you",
     "your"
    ],
    "is_chunked": true,
    "content_hash": "dad2e07d157d9747211cd1e828b2bb82",
    "metadata": {
     "file_type": "json",
     "language": "pt",
     "chunk_index": 3,
     "total_chunks": 4,
     "processing_time": 0.004999876022338867
    },
    "document_type": "general",
    "language": "pt",
    "creation_date": "",
    "chunk_index": 3,
    "total_chunks": 4,
    "confidence_score": 1.0,
    "tables": []
   }
  ],
  "metadata": {
   "library_name": "playlist_1",
   "processed_date": "2025-04-19 13:07:18",
   "source": "Derived from file structure",
   "processor_version": "claude.beta.py 3.0",
   "processing_timestamp": "2025-04-19T13:07:18.718752",
   "processing_time_seconds": 0.17921161651611328,
   "total_time_seconds": 0.18821024894714355,
   "discovery_time_seconds": 0.006998777389526367,
   "total_files_processed": 21,
   "total_files_skipped": 0,
   "total_files_error": 0,
   "total_chunks": 109,
   "max_chunk_size": 4096,
   "chunk_overlap": 200,
   "valid_extensions": [
    ".py",
    ".html",
    ".css",
    ".yaml",
    ".yml",
    ".txt",
    ".md",
    ".js",
    ".gitignore",
    ".ts",
    ".json",
    ".csv",
    ".rtf",
    ".pdf",
    ".docx",
    ".pptx",
    ".xlsx",
    ".xml",
    ".sh",
    ".bat",
    ".java",
    ".c",
    ".cpp",
    ".h",
    ".cs",
    ".php",
    ".rb",
    ".go",
    ".rs",
    ".swift"
   ],
   "binary_detection": true
  }
 }
}